{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ILI activiy prediction from Lat, Long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "\n",
    "import math, time\n",
    "from math import sqrt\n",
    "\n",
    "import itertools\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals.joblib import Memory\n",
    "memory = Memory(cachedir='/tmp', verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = '../data/raw.csv'\n",
    "seq_len = 22\n",
    "d = 0.2 #decay\n",
    "shape = [3, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download data and normalize it\n",
    "Data since 2010 to 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO DO : create a function to preprocess the data\n",
    "@memory.cache\n",
    "def get_ili_data(data, normalize=True):\n",
    "    \n",
    "    df = read_csv(data, index_col=3)\n",
    "    \n",
    "    # manually specify column names\n",
    "    df.columns = ['statename','activity_level','activity_level_label','season','weeknumber','Latitude','Longitude']\n",
    "    df.index.name = 'date'\n",
    "    \n",
    "    # convert index to datetime\n",
    "    df.index = pd.to_datetime(df.index, format='%b-%d-%Y')\n",
    "    \n",
    "    # manually remove the feature we don;t want to evaluate \n",
    "    df.drop(['statename', 'season', 'weeknumber','activity_level_label'], axis=1, inplace=True)\n",
    "    \n",
    "    if normalize:        \n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        df['activity_level'] = min_max_scaler.fit_transform(df.activity_level.values.reshape(-1,1))\n",
    "        df['Latitude'] = min_max_scaler.fit_transform(df.Latitude.values.reshape(-1,1))\n",
    "        df['Longitude'] = min_max_scaler.fit_transform(df.Longitude.values.reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            activity_level  Latitude  Longitude\n",
      "date                                           \n",
      "2016-10-01             0.1  0.290799    0.80243\n",
      "2016-09-24             0.1  0.290799    0.80243\n",
      "2016-09-17             0.1  0.290799    0.80243\n",
      "2016-09-10             0.1  0.290799    0.80243\n",
      "2016-09-03             0.1  0.290799    0.80243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "df = get_ili_data(data, normalize=True)\n",
    "# summarize first 5 rows\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot out the ILI activity level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def plot_ili(data):\n",
    "    df = get_ili_data(data, normalize=True)\n",
    "    print(df.head())\n",
    "    plt.plot(df['activity_level'].values, color='red', label='ILI activity')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_ili_group(data):\n",
    "    df = get_ili_data(data, normalize=False)\n",
    "    print(df.head())\n",
    "    values = df.values\n",
    "    # specify columns to plot\n",
    "    groups = [0,1,2]\n",
    "    i = 1\n",
    "    # plot each column\n",
    "    plt.figure()\n",
    "    for group in groups:\n",
    "        plt.subplot(len(groups), 1, i)\n",
    "        plt.plot(values[:, group])\n",
    "        plt.title(df.columns[group], y=0.5, loc='right')\n",
    "        plt.legend(loc='best')\n",
    "        i += 1\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            activity_level  Latitude  Longitude\n",
      "date                                           \n",
      "2016-10-01             0.1  0.290799    0.80243\n",
      "2016-09-24             0.1  0.290799    0.80243\n",
      "2016-09-17             0.1  0.290799    0.80243\n",
      "2016-09-10             0.1  0.290799    0.80243\n",
      "2016-09-03             0.1  0.290799    0.80243\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124334e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ili(data)\n",
    "# plot_ili_group(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set last day Adjusted Close as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def load_data(ili_data, seq_len):\n",
    "    amount_of_features = len(ili_data.columns)\n",
    "    data = ili_data.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    \n",
    "    train = result[:int(row), :] # 90% date\n",
    "    X_train = train[:, :-1] # all data until day m\n",
    "    y_train = train[:, -1][:,-1] # day m + 1 adjusted close price\n",
    "    \n",
    "    X_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1][:,-1] \n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14319, 22, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_train.shape[1], X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14319"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Buidling neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def build_model2(layers, neurons, d):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 22, 128)           67584     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,329\n",
      "Trainable params: 203,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.lock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8d7918e67027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# layers = [3, 22, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m                           \u001b[0;34m'directory %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persist_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m_persist_output\u001b[0;34m(self, output, dir)\u001b[0m\n\u001b[1;32m    762\u001b[0m             write_func = functools.partial(numpy_pickle.dump,\n\u001b[1;32m    763\u001b[0m                                            compress=self.compress)\n\u001b[0;32m--> 764\u001b[0;31m             \u001b[0mconcurrency_safe_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Persisting in %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36mconcurrency_safe_write\u001b[0;34m(to_write, filename, write_func)\u001b[0m\n\u001b[1;32m    209\u001b[0m     temporary_filename = '{}.thread-{}-pid-{}'.format(\n\u001b[1;32m    210\u001b[0m         filename, thread_id, os.getpid())\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mwrite_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_write\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemporary_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mconcurrency_safe_rename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemporary_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.lock objects"
     ]
    }
   ],
   "source": [
    "model = build_model2(shape, neurons, d)\n",
    "# layers = [3, 22, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-4d5419ecfbca>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-4d5419ecfbca>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model.fit(\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@memory.cache\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Result on training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00025 MSE (0.02 RMSE)\n",
      "Test Score: 0.00031 MSE (0.02 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00024660477642904745, 0.00030625113549688526)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Prediction vs Real results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = percentage_difference(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Plot out prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize(data, normalized_value):\n",
    "    start = datetime.datetime(2000, 1, 1)\n",
    "    end = datetime.date.today()\n",
    "    df = read_csv(data, index_col=3)\n",
    "    \n",
    "    df = df['activity_level'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_result(data, normalized_value_p, normalized_value_y_test):\n",
    "    newp = denormalize(data, normalized_value_p)\n",
    "    newy_test = denormalize(data, normalized_value_y_test)\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format('ILI activity'))\n",
    "    plt2.xlabel('Days')\n",
    "    plt2.ylabel('Activity_level')\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-65cfa5f70715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-1e74c6c03a20>\u001b[0m in \u001b[0;36mplot_result\u001b[0;34m(data, normalized_value_p, normalized_value_y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnewp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnewy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewy_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-e8bf44b2c81e>\u001b[0m in \u001b[0;36mdenormalize\u001b[0;34m(data, normalized_value)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'datetime'"
     ]
    }
   ],
   "source": [
    "plot_result(data, p, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Save for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('LSTM_Stock_prediction-20170429.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Fine tune model\n",
    "# 11. Function to load data, train model and see score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_measure(stock_name, seq_len, d, shape, neurons, epochs):\n",
    "    df = get_stock_data(stock_name)\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model2(shape, neurons, d)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "    # model.save('LSTM_Stock_prediction-20170429.h5')\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Fine tune hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.1 Optimial Dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+000\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1804e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5058e-04 - acc: 0.0000e+00 - val_loss: 5.7324e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6854e-04 - acc: 0.0000e+00 - val_loss: 3.3299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3460e-04 - acc: 0.0000e+00 - val_loss: 2.6412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4755e-04 - acc: 0.0000e+00 - val_loss: 3.4630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4434e-04 - acc: 0.0000e+00 - val_loss: 2.6879e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3127e-04 - acc: 0.0000e+00 - val_loss: 2.3772e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2684e-04 - acc: 0.0000e+00 - val_loss: 3.5324e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2834e-04 - acc: 0.0000e+00 - val_loss: 2.5947e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2607e-04 - acc: 0.0000e+00 - val_loss: 2.4281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1852e-04 - acc: 0.0000e+00 - val_loss: 3.0913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2246e-04 - acc: 0.0000e+00 - val_loss: 3.9577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2297e-04 - acc: 0.0000e+00 - val_loss: 2.1565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1701e-04 - acc: 0.0000e+00 - val_loss: 3.2281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1031e-04 - acc: 0.0000e+00 - val_loss: 2.1198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0591e-04 - acc: 0.0000e+00 - val_loss: 2.7185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1723e-04 - acc: 0.0000e+00 - val_loss: 4.2473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0234e-04 - acc: 0.0000e+00 - val_loss: 2.0022e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1399e-04 - acc: 0.0000e+00 - val_loss: 3.9876e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2373e-04 - acc: 0.0000e+00 - val_loss: 2.4653e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1187e-04 - acc: 0.0000e+00 - val_loss: 4.2809e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3623e-04 - acc: 0.0000e+00 - val_loss: 2.3799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0914e-04 - acc: 0.0000e+00 - val_loss: 2.4966e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0163e-04 - acc: 0.0000e+00 - val_loss: 1.7917e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0467e-04 - acc: 0.0000e+00 - val_loss: 2.2979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0334e-04 - acc: 0.0000e+00 - val_loss: 1.7885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0457e-04 - acc: 0.0000e+00 - val_loss: 1.8090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0538e-04 - acc: 0.0000e+00 - val_loss: 1.7517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1634e-04 - acc: 0.0000e+00 - val_loss: 1.8726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0294e-04 - acc: 0.0000e+00 - val_loss: 1.7027e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2477e-05 - acc: 0.0000e+00 - val_loss: 2.0702e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0008e-04 - acc: 0.0000e+00 - val_loss: 2.7150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1197e-04 - acc: 0.0000e+00 - val_loss: 2.9585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9549e-05 - acc: 0.0000e+00 - val_loss: 3.1780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1413e-04 - acc: 0.0000e+00 - val_loss: 3.9311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4315e-05 - acc: 0.0000e+00 - val_loss: 1.6544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3231e-05 - acc: 0.0000e+00 - val_loss: 1.9984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7269e-05 - acc: 0.0000e+00 - val_loss: 2.7382e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2887e-04 - acc: 0.0000e+00 - val_loss: 2.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1389e-04 - acc: 0.0000e+00 - val_loss: 4.4738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3520e-05 - acc: 0.0000e+00 - val_loss: 2.5505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1500e-05 - acc: 0.0000e+00 - val_loss: 1.7357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1550e-05 - acc: 0.0000e+00 - val_loss: 1.4911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8440e-05 - acc: 0.0000e+00 - val_loss: 1.9152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1258e-05 - acc: 0.0000e+00 - val_loss: 1.6780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9805e-05 - acc: 0.0000e+00 - val_loss: 2.6091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2405e-05 - acc: 0.0000e+00 - val_loss: 2.0304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1249e-05 - acc: 0.0000e+00 - val_loss: 1.6803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1792e-05 - acc: 0.0000e+00 - val_loss: 4.1523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8591e-05 - acc: 0.0000e+00 - val_loss: 1.4510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0371e-04 - acc: 0.0000e+00 - val_loss: 1.5422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6938e-05 - acc: 0.0000e+00 - val_loss: 2.7897e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1394e-05 - acc: 0.0000e+00 - val_loss: 1.8889e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7931e-05 - acc: 0.0000e+00 - val_loss: 1.3869e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0916e-05 - acc: 0.0000e+00 - val_loss: 1.3568e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3131e-05 - acc: 0.0000e+00 - val_loss: 1.4042e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3213e-05 - acc: 0.0000e+00 - val_loss: 1.4419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7929e-05 - acc: 0.0000e+00 - val_loss: 1.3178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9790e-05 - acc: 0.0000e+00 - val_loss: 1.7678e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9061e-05 - acc: 0.0000e+00 - val_loss: 1.3136e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4272e-05 - acc: 0.0000e+00 - val_loss: 1.3351e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8430e-05 - acc: 0.0000e+00 - val_loss: 1.3938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3179e-05 - acc: 0.0000e+00 - val_loss: 1.3191e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0624e-05 - acc: 0.0000e+00 - val_loss: 1.6184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5314e-05 - acc: 0.0000e+00 - val_loss: 1.2594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9620e-05 - acc: 0.0000e+00 - val_loss: 4.9358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1658e-05 - acc: 0.0000e+00 - val_loss: 1.2793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9868e-05 - acc: 0.0000e+00 - val_loss: 1.7053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0058e-05 - acc: 0.0000e+00 - val_loss: 2.7771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6162e-05 - acc: 0.0000e+00 - val_loss: 1.5282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0946e-05 - acc: 0.0000e+00 - val_loss: 1.4062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5089e-05 - acc: 0.0000e+00 - val_loss: 1.2988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4359e-05 - acc: 0.0000e+00 - val_loss: 2.0560e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4188e-05 - acc: 0.0000e+00 - val_loss: 1.6070e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0277e-05 - acc: 0.0000e+00 - val_loss: 1.5223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8316e-05 - acc: 0.0000e+00 - val_loss: 1.2364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5891e-05 - acc: 0.0000e+00 - val_loss: 1.9934e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6773e-05 - acc: 0.0000e+00 - val_loss: 1.1844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7297e-05 - acc: 0.0000e+00 - val_loss: 1.1918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1163e-05 - acc: 0.0000e+00 - val_loss: 1.5928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8433e-05 - acc: 0.0000e+00 - val_loss: 2.8398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9775e-05 - acc: 0.0000e+00 - val_loss: 1.7573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0252e-05 - acc: 0.0000e+00 - val_loss: 1.1541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7584e-05 - acc: 0.0000e+00 - val_loss: 1.1207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8474e-05 - acc: 0.0000e+00 - val_loss: 1.1507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1574e-05 - acc: 0.0000e+00 - val_loss: 1.3375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9767e-05 - acc: 0.0000e+00 - val_loss: 4.0851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2278e-05 - acc: 0.0000e+00 - val_loss: 1.1002e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7948e-05 - acc: 0.0000e+00 - val_loss: 1.7005e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4060e-05 - acc: 0.0000e+00 - val_loss: 1.0776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5775e-05 - acc: 0.0000e+00 - val_loss: 5.0202e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5600e-05 - acc: 0.0000e+00 - val_loss: 1.0738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3064e-05 - acc: 0.0000e+00 - val_loss: 1.1468e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4515e-05 - acc: 0.0000e+00 - val_loss: 1.0644e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1642e-05 - acc: 0.0000e+00 - val_loss: 1.2517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4470e-05 - acc: 0.0000e+00 - val_loss: 3.9936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4401e-05 - acc: 0.0000e+00 - val_loss: 1.2387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0160e-05 - acc: 0.0000e+00 - val_loss: 1.1937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6937e-05 - acc: 0.0000e+00 - val_loss: 1.2306e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7407e-05 - acc: 0.0000e+00 - val_loss: 1.2269e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8668e-05 - acc: 0.0000e+00 - val_loss: 1.0703e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4473e-05 - acc: 0.0000e+00 - val_loss: 1.0153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3955e-05 - acc: 0.0000e+00 - val_loss: 9.8830e-05 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1786e-05 - acc: 0.0000e+00 - val_loss: 2.3667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4980e-05 - acc: 0.0000e+00 - val_loss: 1.2261e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8195e-05 - acc: 0.0000e+00 - val_loss: 1.3106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2237e-05 - acc: 0.0000e+00 - val_loss: 1.2377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1468e-05 - acc: 0.0000e+00 - val_loss: 1.0991e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7530e-05 - acc: 0.0000e+00 - val_loss: 1.1433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1319e-05 - acc: 0.0000e+00 - val_loss: 9.6058e-05 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2212e-05 - acc: 0.0000e+00 - val_loss: 9.4320e-05 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5771e-05 - acc: 0.0000e+00 - val_loss: 1.6074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8031e-05 - acc: 0.0000e+00 - val_loss: 1.2573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1193e-05 - acc: 0.0000e+00 - val_loss: 9.4208e-05 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7699e-05 - acc: 0.0000e+00 - val_loss: 2.1584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7743e-05 - acc: 0.0000e+00 - val_loss: 9.3458e-05 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4026e-05 - acc: 0.0000e+00 - val_loss: 1.2577e-04 - val_acc: 0.0000e+000\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8184e-05 - acc: 0.0000e+00 - val_loss: 9.8625e-05 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1009e-05 - acc: 0.0000e+00 - val_loss: 9.4831e-05 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1501e-05 - acc: 0.0000e+00 - val_loss: 1.4569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2453e-05 - acc: 0.0000e+00 - val_loss: 1.1958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8398e-05 - acc: 0.0000e+00 - val_loss: 2.0335e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5667e-05 - acc: 0.0000e+00 - val_loss: 9.9490e-05 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8007e-05 - acc: 0.0000e+00 - val_loss: 2.0423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2200e-05 - acc: 0.0000e+00 - val_loss: 9.0454e-05 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4705e-05 - acc: 0.0000e+00 - val_loss: 8.8123e-05 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5682e-05 - acc: 0.0000e+00 - val_loss: 8.8921e-05 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7765e-05 - acc: 0.0000e+00 - val_loss: 1.0062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5074e-05 - acc: 0.0000e+00 - val_loss: 1.4419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6703e-05 - acc: 0.0000e+00 - val_loss: 1.0327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0477e-05 - acc: 0.0000e+00 - val_loss: 1.2665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3568e-05 - acc: 0.0000e+00 - val_loss: 1.2759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8359e-05 - acc: 0.0000e+00 - val_loss: 1.2939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7925e-05 - acc: 0.0000e+00 - val_loss: 8.4155e-05 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3628e-05 - acc: 0.0000e+00 - val_loss: 8.6437e-05 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6880e-05 - acc: 0.0000e+00 - val_loss: 9.7719e-05 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5505e-05 - acc: 0.0000e+00 - val_loss: 1.7345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3116e-05 - acc: 0.0000e+00 - val_loss: 1.1106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6271e-05 - acc: 0.0000e+00 - val_loss: 2.3537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9915e-05 - acc: 0.0000e+00 - val_loss: 8.6074e-05 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2216e-05 - acc: 0.0000e+00 - val_loss: 9.3876e-05 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6524e-05 - acc: 0.0000e+00 - val_loss: 8.8528e-05 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4530e-05 - acc: 0.0000e+00 - val_loss: 8.6354e-05 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4430e-05 - acc: 0.0000e+00 - val_loss: 8.5768e-05 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8469e-05 - acc: 0.0000e+00 - val_loss: 8.1132e-05 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1446e-05 - acc: 0.0000e+00 - val_loss: 8.1386e-05 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8661e-05 - acc: 0.0000e+00 - val_loss: 3.1817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3277e-05 - acc: 0.0000e+00 - val_loss: 1.0148e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9854e-05 - acc: 0.0000e+00 - val_loss: 1.3226e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2323e-05 - acc: 0.0000e+00 - val_loss: 8.9075e-05 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2540e-05 - acc: 0.0000e+00 - val_loss: 2.1459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8624e-05 - acc: 0.0000e+00 - val_loss: 1.1674e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7031e-05 - acc: 0.0000e+00 - val_loss: 1.0599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3968e-05 - acc: 0.0000e+00 - val_loss: 1.1632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9123e-05 - acc: 0.0000e+00 - val_loss: 2.2355e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7779e-05 - acc: 0.0000e+00 - val_loss: 7.7570e-05 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4991e-05 - acc: 0.0000e+00 - val_loss: 9.6279e-05 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5642e-05 - acc: 0.0000e+00 - val_loss: 1.3818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8025e-05 - acc: 0.0000e+00 - val_loss: 1.0016e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3952e-05 - acc: 0.0000e+00 - val_loss: 8.8537e-05 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4084e-05 - acc: 0.0000e+00 - val_loss: 9.0497e-05 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0225e-05 - acc: 0.0000e+00 - val_loss: 8.4298e-05 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6301e-05 - acc: 0.0000e+00 - val_loss: 1.5655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1345e-05 - acc: 0.0000e+00 - val_loss: 8.2517e-05 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9469e-05 - acc: 0.0000e+00 - val_loss: 1.1771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0253e-05 - acc: 0.0000e+00 - val_loss: 7.3709e-05 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3160e-05 - acc: 0.0000e+00 - val_loss: 1.1318e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0338e-05 - acc: 0.0000e+00 - val_loss: 7.5163e-05 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5219e-05 - acc: 0.0000e+00 - val_loss: 7.6992e-05 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7646e-05 - acc: 0.0000e+00 - val_loss: 1.3472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1729e-05 - acc: 0.0000e+00 - val_loss: 1.4647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5697e-05 - acc: 0.0000e+00 - val_loss: 1.0430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9417e-05 - acc: 0.0000e+00 - val_loss: 1.0401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3279e-05 - acc: 0.0000e+00 - val_loss: 7.7741e-05 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3057e-05 - acc: 0.0000e+00 - val_loss: 2.2752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3651e-05 - acc: 0.0000e+00 - val_loss: 8.5790e-05 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4848e-05 - acc: 0.0000e+00 - val_loss: 8.4086e-05 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2553e-05 - acc: 0.0000e+00 - val_loss: 7.3760e-05 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0531e-05 - acc: 0.0000e+00 - val_loss: 8.0072e-05 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5025e-05 - acc: 0.0000e+00 - val_loss: 7.7309e-05 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1298e-05 - acc: 0.0000e+00 - val_loss: 1.4066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2260e-05 - acc: 0.0000e+00 - val_loss: 8.5297e-05 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1828e-05 - acc: 0.0000e+00 - val_loss: 8.2775e-05 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2156e-05 - acc: 0.0000e+00 - val_loss: 7.7451e-05 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6815e-05 - acc: 0.0000e+00 - val_loss: 7.2587e-05 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2749e-05 - acc: 0.0000e+00 - val_loss: 8.9476e-05 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5322e-05 - acc: 0.0000e+00 - val_loss: 9.5393e-05 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3667e-05 - acc: 0.0000e+00 - val_loss: 7.1974e-05 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3043e-05 - acc: 0.0000e+00 - val_loss: 8.0163e-05 - val_acc: 0.0000e+000\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0775e-05 - acc: 0.0000e+00 - val_loss: 7.2108e-05 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1936e-05 - acc: 0.0000e+00 - val_loss: 8.0526e-05 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9858e-05 - acc: 0.0000e+00 - val_loss: 7.6074e-05 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0554e-05 - acc: 0.0000e+00 - val_loss: 7.5793e-05 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0123e-05 - acc: 0.0000e+00 - val_loss: 1.4093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1319e-05 - acc: 0.0000e+00 - val_loss: 7.1386e-05 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8639e-05 - acc: 0.0000e+00 - val_loss: 8.0636e-05 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7618e-05 - acc: 0.0000e+00 - val_loss: 9.2821e-05 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3011e-05 - acc: 0.0000e+00 - val_loss: 7.5260e-05 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0749e-05 - acc: 0.0000e+00 - val_loss: 8.2678e-05 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3301e-05 - acc: 0.0000e+00 - val_loss: 1.2248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1240e-05 - acc: 0.0000e+00 - val_loss: 8.5474e-05 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0708e-05 - acc: 0.0000e+00 - val_loss: 1.0901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8734e-05 - acc: 0.0000e+00 - val_loss: 1.3232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0359e-05 - acc: 0.0000e+00 - val_loss: 7.5599e-05 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1969e-05 - acc: 0.0000e+00 - val_loss: 7.0787e-05 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0159e-05 - acc: 0.0000e+00 - val_loss: 7.3812e-05 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6949e-05 - acc: 0.0000e+00 - val_loss: 9.3191e-05 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0511e-05 - acc: 0.0000e+00 - val_loss: 8.2620e-05 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0671e-05 - acc: 0.0000e+00 - val_loss: 8.2122e-05 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7721e-05 - acc: 0.0000e+00 - val_loss: 8.8690e-05 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6845e-05 - acc: 0.0000e+00 - val_loss: 1.0747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7450e-05 - acc: 0.0000e+00 - val_loss: 1.1586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9962e-05 - acc: 0.0000e+00 - val_loss: 1.3950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0234e-05 - acc: 0.0000e+00 - val_loss: 8.8173e-05 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5143e-05 - acc: 0.0000e+00 - val_loss: 7.4419e-05 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9481e-05 - acc: 0.0000e+00 - val_loss: 8.4440e-05 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7271e-05 - acc: 0.0000e+00 - val_loss: 7.6987e-05 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8756e-05 - acc: 0.0000e+00 - val_loss: 7.4955e-05 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6757e-05 - acc: 0.0000e+00 - val_loss: 7.2061e-05 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7897e-05 - acc: 0.0000e+00 - val_loss: 8.6368e-05 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0011e-05 - acc: 0.0000e+00 - val_loss: 6.7412e-05 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6490e-05 - acc: 0.0000e+00 - val_loss: 1.0807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1692e-05 - acc: 0.0000e+00 - val_loss: 1.4258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2036e-05 - acc: 0.0000e+00 - val_loss: 1.8816e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0426e-05 - acc: 0.0000e+00 - val_loss: 7.8484e-05 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6608e-05 - acc: 0.0000e+00 - val_loss: 9.1184e-05 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1540e-05 - acc: 0.0000e+00 - val_loss: 8.1842e-05 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1842e-05 - acc: 0.0000e+00 - val_loss: 1.1252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6730e-05 - acc: 0.0000e+00 - val_loss: 7.4458e-05 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5798e-05 - acc: 0.0000e+00 - val_loss: 7.8105e-05 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7380e-05 - acc: 0.0000e+00 - val_loss: 6.7593e-05 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8452e-05 - acc: 0.0000e+00 - val_loss: 7.6469e-05 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7764e-05 - acc: 0.0000e+00 - val_loss: 1.2494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7386e-05 - acc: 0.0000e+00 - val_loss: 7.5680e-05 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4086e-05 - acc: 0.0000e+00 - val_loss: 1.2589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0590e-05 - acc: 0.0000e+00 - val_loss: 8.1866e-05 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0282e-05 - acc: 0.0000e+00 - val_loss: 7.8637e-05 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7946e-05 - acc: 0.0000e+00 - val_loss: 1.2135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6448e-05 - acc: 0.0000e+00 - val_loss: 1.0066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7334e-05 - acc: 0.0000e+00 - val_loss: 6.7278e-05 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5057e-05 - acc: 0.0000e+00 - val_loss: 6.4258e-05 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3849e-05 - acc: 0.0000e+00 - val_loss: 6.7222e-05 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9607e-05 - acc: 0.0000e+00 - val_loss: 8.1532e-05 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7583e-05 - acc: 0.0000e+00 - val_loss: 6.4113e-05 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7323e-05 - acc: 0.0000e+00 - val_loss: 6.3504e-05 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7508e-05 - acc: 0.0000e+00 - val_loss: 7.6140e-05 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0294e-05 - acc: 0.0000e+00 - val_loss: 1.5945e-04 - val_acc: 0.0000e+000\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8781e-05 - acc: 0.0000e+00 - val_loss: 1.3159e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4642e-05 - acc: 0.0000e+00 - val_loss: 6.6366e-05 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5554e-05 - acc: 0.0000e+00 - val_loss: 8.8685e-05 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3626e-05 - acc: 0.0000e+00 - val_loss: 8.5942e-05 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3702e-05 - acc: 0.0000e+00 - val_loss: 6.8794e-05 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4759e-05 - acc: 0.0000e+00 - val_loss: 8.6218e-05 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6676e-05 - acc: 0.0000e+00 - val_loss: 7.7165e-05 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7643e-05 - acc: 0.0000e+00 - val_loss: 1.2712e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9754e-05 - acc: 0.0000e+00 - val_loss: 1.0928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7634e-05 - acc: 0.0000e+00 - val_loss: 6.2637e-05 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4605e-05 - acc: 0.0000e+00 - val_loss: 8.5917e-05 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4135e-05 - acc: 0.0000e+00 - val_loss: 1.0912e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0075e-05 - acc: 0.0000e+00 - val_loss: 1.3387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0382e-05 - acc: 0.0000e+00 - val_loss: 6.0703e-05 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4520e-05 - acc: 0.0000e+00 - val_loss: 6.2738e-05 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4062e-05 - acc: 0.0000e+00 - val_loss: 6.8128e-05 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5214e-05 - acc: 0.0000e+00 - val_loss: 1.0929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3945e-05 - acc: 0.0000e+00 - val_loss: 6.0944e-05 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4340e-05 - acc: 0.0000e+00 - val_loss: 9.2843e-05 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5414e-05 - acc: 0.0000e+00 - val_loss: 9.1970e-05 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5919e-05 - acc: 0.0000e+00 - val_loss: 6.6458e-05 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4528e-05 - acc: 0.0000e+00 - val_loss: 1.1939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2757e-05 - acc: 0.0000e+00 - val_loss: 6.1442e-05 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2306e-05 - acc: 0.0000e+00 - val_loss: 8.4997e-05 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4690e-05 - acc: 0.0000e+00 - val_loss: 6.1618e-05 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1589e-05 - acc: 0.0000e+00 - val_loss: 6.4427e-05 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5297e-05 - acc: 0.0000e+00 - val_loss: 5.9463e-05 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1783e-05 - acc: 0.0000e+00 - val_loss: 7.4361e-05 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4933e-05 - acc: 0.0000e+00 - val_loss: 9.4194e-05 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2558e-05 - acc: 0.0000e+00 - val_loss: 6.1318e-05 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8294e-05 - acc: 0.0000e+00 - val_loss: 8.8355e-05 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3186e-05 - acc: 0.0000e+00 - val_loss: 5.9376e-05 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3565e-05 - acc: 0.0000e+00 - val_loss: 6.9707e-05 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3402e-05 - acc: 0.0000e+00 - val_loss: 9.9120e-05 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2211e-05 - acc: 0.0000e+00 - val_loss: 8.1142e-05 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5021e-05 - acc: 0.0000e+00 - val_loss: 1.0247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7491e-05 - acc: 0.0000e+00 - val_loss: 9.0636e-05 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5320e-05 - acc: 0.0000e+00 - val_loss: 1.1155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4860e-05 - acc: 0.0000e+00 - val_loss: 6.0941e-05 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3913e-05 - acc: 0.0000e+00 - val_loss: 6.2435e-05 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3048e-05 - acc: 0.0000e+00 - val_loss: 6.6532e-05 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2583e-05 - acc: 0.0000e+00 - val_loss: 6.3181e-05 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0371e-05 - acc: 0.0000e+00 - val_loss: 6.9182e-05 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7278e-05 - acc: 0.0000e+00 - val_loss: 5.7825e-05 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7501e-05 - acc: 0.0000e+00 - val_loss: 6.0554e-05 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5414e-05 - acc: 0.0000e+00 - val_loss: 6.7766e-05 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3548e-05 - acc: 0.0000e+00 - val_loss: 1.3253e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4441e-05 - acc: 0.0000e+00 - val_loss: 2.0411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8004e-05 - acc: 0.0000e+00 - val_loss: 6.6944e-05 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1322e-05 - acc: 0.0000e+00 - val_loss: 8.6315e-05 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7320e-05 - acc: 0.0000e+00 - val_loss: 1.9673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2219e-05 - acc: 0.0000e+00 - val_loss: 8.7802e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00009 MSE (0.01 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9329e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1191e-04 - acc: 0.0000e+00 - val_loss: 7.3650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2691e-04 - acc: 0.0000e+00 - val_loss: 3.9015e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1393e-04 - acc: 0.0000e+00 - val_loss: 3.4606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9696e-04 - acc: 0.0000e+00 - val_loss: 3.3240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0872e-04 - acc: 0.0000e+00 - val_loss: 6.2244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8165e-04 - acc: 0.0000e+00 - val_loss: 4.1681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8759e-04 - acc: 0.0000e+00 - val_loss: 2.3860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8010e-04 - acc: 0.0000e+00 - val_loss: 2.9187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6749e-04 - acc: 0.0000e+00 - val_loss: 2.2259e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6794e-04 - acc: 0.0000e+00 - val_loss: 2.7659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7119e-04 - acc: 0.0000e+00 - val_loss: 3.4938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7055e-04 - acc: 0.0000e+00 - val_loss: 2.5959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6964e-04 - acc: 0.0000e+00 - val_loss: 2.1851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7247e-04 - acc: 0.0000e+00 - val_loss: 2.7470e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8090e-04 - acc: 0.0000e+00 - val_loss: 2.5204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6944e-04 - acc: 0.0000e+00 - val_loss: 3.0941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6486e-04 - acc: 0.0000e+00 - val_loss: 2.9131e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5562e-04 - acc: 0.0000e+00 - val_loss: 6.4125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6698e-04 - acc: 0.0000e+00 - val_loss: 3.1872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7413e-04 - acc: 0.0000e+00 - val_loss: 3.2942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4956e-04 - acc: 0.0000e+00 - val_loss: 2.0891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5216e-04 - acc: 0.0000e+00 - val_loss: 5.3458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4924e-04 - acc: 0.0000e+00 - val_loss: 1.9061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5519e-04 - acc: 0.0000e+00 - val_loss: 3.3778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5656e-04 - acc: 0.0000e+00 - val_loss: 1.9585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4528e-04 - acc: 0.0000e+00 - val_loss: 2.6235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4306e-04 - acc: 0.0000e+00 - val_loss: 2.9175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5168e-04 - acc: 0.0000e+00 - val_loss: 4.3717e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6246e-04 - acc: 0.0000e+00 - val_loss: 2.1126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3043e-04 - acc: 0.0000e+00 - val_loss: 1.9429e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4148e-04 - acc: 0.0000e+00 - val_loss: 8.9457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6039e-04 - acc: 0.0000e+00 - val_loss: 2.5770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4683e-04 - acc: 0.0000e+00 - val_loss: 2.3320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4566e-04 - acc: 0.0000e+00 - val_loss: 1.9916e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4164e-04 - acc: 0.0000e+00 - val_loss: 1.7462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3509e-04 - acc: 0.0000e+00 - val_loss: 8.0245e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4891e-04 - acc: 0.0000e+00 - val_loss: 1.8696e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3936e-04 - acc: 0.0000e+00 - val_loss: 2.0472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2747e-04 - acc: 0.0000e+00 - val_loss: 2.3549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3513e-04 - acc: 0.0000e+00 - val_loss: 2.0077e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1995e-04 - acc: 0.0000e+00 - val_loss: 1.8170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2854e-04 - acc: 0.0000e+00 - val_loss: 1.7043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2401e-04 - acc: 0.0000e+00 - val_loss: 1.6290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3657e-04 - acc: 0.0000e+00 - val_loss: 2.6007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2806e-04 - acc: 0.0000e+00 - val_loss: 2.5595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2807e-04 - acc: 0.0000e+00 - val_loss: 1.6139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3190e-04 - acc: 0.0000e+00 - val_loss: 5.6456e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4592e-04 - acc: 0.0000e+00 - val_loss: 6.4682e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2683e-04 - acc: 0.0000e+00 - val_loss: 1.7727e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1944e-04 - acc: 0.0000e+00 - val_loss: 3.9883e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1767e-04 - acc: 0.0000e+00 - val_loss: 1.6873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1247e-04 - acc: 0.0000e+00 - val_loss: 2.7337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2147e-04 - acc: 0.0000e+00 - val_loss: 1.9300e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3180e-04 - acc: 0.0000e+00 - val_loss: 3.2518e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1381e-04 - acc: 0.0000e+00 - val_loss: 1.6086e-04 - val_acc: 0.0000e+000\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0861e-04 - acc: 0.0000e+00 - val_loss: 2.3723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1677e-04 - acc: 0.0000e+00 - val_loss: 2.9337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2100e-04 - acc: 0.0000e+00 - val_loss: 2.2275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0981e-04 - acc: 0.0000e+00 - val_loss: 1.4173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0934e-04 - acc: 0.0000e+00 - val_loss: 1.5673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0645e-04 - acc: 0.0000e+00 - val_loss: 4.4192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3360e-04 - acc: 0.0000e+00 - val_loss: 3.0335e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0373e-04 - acc: 0.0000e+00 - val_loss: 1.4227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8791e-05 - acc: 0.0000e+00 - val_loss: 1.3383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0771e-04 - acc: 0.0000e+00 - val_loss: 1.3564e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0725e-04 - acc: 0.0000e+00 - val_loss: 1.3180e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0281e-04 - acc: 0.0000e+00 - val_loss: 2.4815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1194e-04 - acc: 0.0000e+00 - val_loss: 1.6667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0393e-04 - acc: 0.0000e+00 - val_loss: 1.3261e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0219e-04 - acc: 0.0000e+00 - val_loss: 1.2947e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0024e-04 - acc: 0.0000e+00 - val_loss: 1.2918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0023e-04 - acc: 0.0000e+00 - val_loss: 2.9635e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0363e-04 - acc: 0.0000e+00 - val_loss: 1.8837e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9489e-05 - acc: 0.0000e+00 - val_loss: 1.5120e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4651e-05 - acc: 0.0000e+00 - val_loss: 1.7162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6063e-05 - acc: 0.0000e+00 - val_loss: 1.5722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0355e-04 - acc: 0.0000e+00 - val_loss: 1.2651e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6740e-05 - acc: 0.0000e+00 - val_loss: 1.9936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6821e-05 - acc: 0.0000e+00 - val_loss: 3.3484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0375e-04 - acc: 0.0000e+00 - val_loss: 1.2630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0363e-04 - acc: 0.0000e+00 - val_loss: 1.4048e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0136e-04 - acc: 0.0000e+00 - val_loss: 1.3304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2367e-05 - acc: 0.0000e+00 - val_loss: 1.5024e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1556e-05 - acc: 0.0000e+00 - val_loss: 1.9688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4373e-05 - acc: 0.0000e+00 - val_loss: 1.3368e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3195e-05 - acc: 0.0000e+00 - val_loss: 1.3044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8044e-05 - acc: 0.0000e+00 - val_loss: 1.7294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9616e-05 - acc: 0.0000e+00 - val_loss: 1.2766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0064e-04 - acc: 0.0000e+00 - val_loss: 2.7610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0367e-04 - acc: 0.0000e+00 - val_loss: 1.1928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4559e-05 - acc: 0.0000e+00 - val_loss: 2.3508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7259e-05 - acc: 0.0000e+00 - val_loss: 1.1885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1769e-05 - acc: 0.0000e+00 - val_loss: 1.1800e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3196e-05 - acc: 0.0000e+00 - val_loss: 1.2475e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2697e-05 - acc: 0.0000e+00 - val_loss: 1.3474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5655e-05 - acc: 0.0000e+00 - val_loss: 1.2235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8750e-05 - acc: 0.0000e+00 - val_loss: 1.3564e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8939e-05 - acc: 0.0000e+00 - val_loss: 1.1622e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9343e-05 - acc: 0.0000e+00 - val_loss: 1.2561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5494e-05 - acc: 0.0000e+00 - val_loss: 1.1863e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0968e-05 - acc: 0.0000e+00 - val_loss: 1.2094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9299e-05 - acc: 0.0000e+00 - val_loss: 2.6767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1161e-05 - acc: 0.0000e+00 - val_loss: 1.5001e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3458e-05 - acc: 0.0000e+00 - val_loss: 1.2214e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1224e-05 - acc: 0.0000e+00 - val_loss: 2.9244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7165e-05 - acc: 0.0000e+00 - val_loss: 1.1771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8073e-05 - acc: 0.0000e+00 - val_loss: 1.2206e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4322e-05 - acc: 0.0000e+00 - val_loss: 1.1852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6335e-05 - acc: 0.0000e+00 - val_loss: 1.4050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0061e-05 - acc: 0.0000e+00 - val_loss: 2.0121e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5407e-05 - acc: 0.0000e+00 - val_loss: 1.6877e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5449e-05 - acc: 0.0000e+00 - val_loss: 2.5030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6449e-05 - acc: 0.0000e+00 - val_loss: 1.7870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0849e-05 - acc: 0.0000e+00 - val_loss: 2.3038e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0409e-05 - acc: 0.0000e+00 - val_loss: 2.4584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5467e-05 - acc: 0.0000e+00 - val_loss: 2.5907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0237e-05 - acc: 0.0000e+00 - val_loss: 1.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0812e-05 - acc: 0.0000e+00 - val_loss: 1.1094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6055e-05 - acc: 0.0000e+00 - val_loss: 1.1444e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7686e-05 - acc: 0.0000e+00 - val_loss: 2.2315e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1818e-05 - acc: 0.0000e+00 - val_loss: 1.6184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9144e-05 - acc: 0.0000e+00 - val_loss: 1.4485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1295e-05 - acc: 0.0000e+00 - val_loss: 2.8457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7553e-05 - acc: 0.0000e+00 - val_loss: 2.1662e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4941e-05 - acc: 0.0000e+00 - val_loss: 1.4468e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1972e-05 - acc: 0.0000e+00 - val_loss: 1.6068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0898e-05 - acc: 0.0000e+00 - val_loss: 1.5473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3745e-05 - acc: 0.0000e+00 - val_loss: 1.0981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4579e-05 - acc: 0.0000e+00 - val_loss: 1.0658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3433e-05 - acc: 0.0000e+00 - val_loss: 2.7105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4739e-05 - acc: 0.0000e+00 - val_loss: 2.7288e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7838e-05 - acc: 0.0000e+00 - val_loss: 1.0321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9862e-05 - acc: 0.0000e+00 - val_loss: 1.3938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9317e-05 - acc: 0.0000e+00 - val_loss: 1.3731e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0154e-05 - acc: 0.0000e+00 - val_loss: 1.9247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4486e-05 - acc: 0.0000e+00 - val_loss: 1.5125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1072e-05 - acc: 0.0000e+00 - val_loss: 1.0958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9677e-05 - acc: 0.0000e+00 - val_loss: 1.0424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7725e-05 - acc: 0.0000e+00 - val_loss: 1.7454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2214e-05 - acc: 0.0000e+00 - val_loss: 1.4798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0318e-05 - acc: 0.0000e+00 - val_loss: 1.1087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4102e-05 - acc: 0.0000e+00 - val_loss: 1.1551e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9907e-05 - acc: 0.0000e+00 - val_loss: 1.0189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9387e-05 - acc: 0.0000e+00 - val_loss: 1.5805e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3418e-05 - acc: 0.0000e+00 - val_loss: 1.0517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0501e-05 - acc: 0.0000e+00 - val_loss: 1.2135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2552e-05 - acc: 0.0000e+00 - val_loss: 1.0421e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6797e-05 - acc: 0.0000e+00 - val_loss: 3.8725e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0978e-05 - acc: 0.0000e+00 - val_loss: 2.2032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9420e-05 - acc: 0.0000e+00 - val_loss: 1.1117e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1105e-05 - acc: 0.0000e+00 - val_loss: 1.1714e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2313e-05 - acc: 0.0000e+00 - val_loss: 9.8602e-05 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3480e-05 - acc: 0.0000e+00 - val_loss: 2.6229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3138e-05 - acc: 0.0000e+00 - val_loss: 1.3430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3961e-05 - acc: 0.0000e+00 - val_loss: 1.1436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2608e-05 - acc: 0.0000e+00 - val_loss: 1.6103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9241e-05 - acc: 0.0000e+00 - val_loss: 1.1385e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2693e-05 - acc: 0.0000e+00 - val_loss: 1.1039e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9654e-05 - acc: 0.0000e+00 - val_loss: 1.4374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8400e-05 - acc: 0.0000e+00 - val_loss: 3.0981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0255e-05 - acc: 0.0000e+00 - val_loss: 2.3080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6711e-05 - acc: 0.0000e+00 - val_loss: 2.1065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2729e-05 - acc: 0.0000e+00 - val_loss: 7.7048e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7525e-05 - acc: 0.0000e+00 - val_loss: 1.0705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2871e-05 - acc: 0.0000e+00 - val_loss: 3.4541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6869e-05 - acc: 0.0000e+00 - val_loss: 2.8644e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8582e-05 - acc: 0.0000e+00 - val_loss: 9.7128e-05 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4799e-05 - acc: 0.0000e+00 - val_loss: 9.4729e-05 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3059e-05 - acc: 0.0000e+00 - val_loss: 1.2937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5151e-05 - acc: 0.0000e+00 - val_loss: 9.5984e-05 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4372e-05 - acc: 0.0000e+00 - val_loss: 2.1266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2838e-05 - acc: 0.0000e+00 - val_loss: 2.1060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0908e-05 - acc: 0.0000e+00 - val_loss: 1.3188e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3162e-05 - acc: 0.0000e+00 - val_loss: 8.8861e-05 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1070e-05 - acc: 0.0000e+00 - val_loss: 1.3267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3744e-05 - acc: 0.0000e+00 - val_loss: 1.2478e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0087e-05 - acc: 0.0000e+00 - val_loss: 1.1719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5939e-05 - acc: 0.0000e+00 - val_loss: 2.2297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2949e-05 - acc: 0.0000e+00 - val_loss: 1.5936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5697e-05 - acc: 0.0000e+00 - val_loss: 4.1625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6044e-05 - acc: 0.0000e+00 - val_loss: 1.4011e-04 - val_acc: 0.0000e+00- loss: 5.6600e-05 - acc: 0.0000e+\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5740e-05 - acc: 0.0000e+00 - val_loss: 9.5011e-05 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1277e-05 - acc: 0.0000e+00 - val_loss: 1.2430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7618e-05 - acc: 0.0000e+00 - val_loss: 1.6166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0599e-05 - acc: 0.0000e+00 - val_loss: 1.2909e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0851e-05 - acc: 0.0000e+00 - val_loss: 1.1446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2853e-05 - acc: 0.0000e+00 - val_loss: 1.2426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9944e-05 - acc: 0.0000e+00 - val_loss: 1.5018e-04 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1618e-05 - acc: 0.0000e+00 - val_loss: 1.7918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4237e-05 - acc: 0.0000e+00 - val_loss: 1.4274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6970e-05 - acc: 0.0000e+00 - val_loss: 1.9071e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9245e-05 - acc: 0.0000e+00 - val_loss: 5.2862e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7839e-05 - acc: 0.0000e+00 - val_loss: 4.4721e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9013e-05 - acc: 0.0000e+00 - val_loss: 2.6655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6635e-05 - acc: 0.0000e+00 - val_loss: 1.5327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0156e-05 - acc: 0.0000e+00 - val_loss: 3.9753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6178e-05 - acc: 0.0000e+00 - val_loss: 1.4531e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0364e-05 - acc: 0.0000e+00 - val_loss: 2.2693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0929e-05 - acc: 0.0000e+00 - val_loss: 2.5645e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5530e-05 - acc: 0.0000e+00 - val_loss: 2.2211e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1057e-05 - acc: 0.0000e+00 - val_loss: 2.2898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3156e-05 - acc: 0.0000e+00 - val_loss: 4.0469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6560e-05 - acc: 0.0000e+00 - val_loss: 3.1460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2696e-05 - acc: 0.0000e+00 - val_loss: 3.0310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4534e-05 - acc: 0.0000e+00 - val_loss: 2.4806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3620e-05 - acc: 0.0000e+00 - val_loss: 2.6803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8282e-05 - acc: 0.0000e+00 - val_loss: 4.5365e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9243e-05 - acc: 0.0000e+00 - val_loss: 2.9860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9562e-05 - acc: 0.0000e+00 - val_loss: 3.7185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4081e-05 - acc: 0.0000e+00 - val_loss: 1.9620e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5634e-05 - acc: 0.0000e+00 - val_loss: 3.7626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3095e-05 - acc: 0.0000e+00 - val_loss: 4.4241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8171e-05 - acc: 0.0000e+00 - val_loss: 1.5349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9549e-05 - acc: 0.0000e+00 - val_loss: 3.5179e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4267e-05 - acc: 0.0000e+00 - val_loss: 3.2184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8565e-05 - acc: 0.0000e+00 - val_loss: 4.6950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3311e-05 - acc: 0.0000e+00 - val_loss: 7.0130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4961e-05 - acc: 0.0000e+00 - val_loss: 5.7976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9112e-05 - acc: 0.0000e+00 - val_loss: 6.3798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5547e-05 - acc: 0.0000e+00 - val_loss: 3.8607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0416e-05 - acc: 0.0000e+00 - val_loss: 4.5483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5231e-05 - acc: 0.0000e+00 - val_loss: 3.7021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7328e-05 - acc: 0.0000e+00 - val_loss: 2.9372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2335e-05 - acc: 0.0000e+00 - val_loss: 5.3925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0794e-05 - acc: 0.0000e+00 - val_loss: 3.1190e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6578e-05 - acc: 0.0000e+00 - val_loss: 4.9661e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7412e-05 - acc: 0.0000e+00 - val_loss: 5.9925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6688e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6717e-05 - acc: 0.0000e+00 - val_loss: 4.9957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9908e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3331e-05 - acc: 0.0000e+00 - val_loss: 6.7110e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9649e-05 - acc: 0.0000e+00 - val_loss: 3.8010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9112e-05 - acc: 0.0000e+00 - val_loss: 6.3234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0891e-05 - acc: 0.0000e+00 - val_loss: 3.3754e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2709e-05 - acc: 0.0000e+00 - val_loss: 8.6715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6157e-05 - acc: 0.0000e+00 - val_loss: 5.4450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9385e-05 - acc: 0.0000e+00 - val_loss: 4.4275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7859e-05 - acc: 0.0000e+00 - val_loss: 6.4428e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2141e-05 - acc: 0.0000e+00 - val_loss: 8.1975e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5560e-05 - acc: 0.0000e+00 - val_loss: 3.4242e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9698e-05 - acc: 0.0000e+00 - val_loss: 8.6679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0289e-05 - acc: 0.0000e+00 - val_loss: 6.7704e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5648e-05 - acc: 0.0000e+00 - val_loss: 5.4294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4502e-05 - acc: 0.0000e+00 - val_loss: 3.3888e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0186e-05 - acc: 0.0000e+00 - val_loss: 3.5092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7147e-05 - acc: 0.0000e+00 - val_loss: 4.3610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8760e-05 - acc: 0.0000e+00 - val_loss: 6.7867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8832e-05 - acc: 0.0000e+00 - val_loss: 3.6523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0648e-05 - acc: 0.0000e+00 - val_loss: 9.3012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4399e-05 - acc: 0.0000e+00 - val_loss: 3.8663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3185e-05 - acc: 0.0000e+00 - val_loss: 4.9197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3924e-05 - acc: 0.0000e+00 - val_loss: 3.2221e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2961e-05 - acc: 0.0000e+00 - val_loss: 5.6797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7599e-05 - acc: 0.0000e+00 - val_loss: 6.2306e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8016e-05 - acc: 0.0000e+00 - val_loss: 6.2173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0209e-05 - acc: 0.0000e+00 - val_loss: 2.8032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7063e-05 - acc: 0.0000e+00 - val_loss: 4.6994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2735e-05 - acc: 0.0000e+00 - val_loss: 4.1736e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6282e-05 - acc: 0.0000e+00 - val_loss: 6.3793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1539e-05 - acc: 0.0000e+00 - val_loss: 7.4030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3086e-05 - acc: 0.0000e+00 - val_loss: 5.2698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0219e-05 - acc: 0.0000e+00 - val_loss: 5.7726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8289e-05 - acc: 0.0000e+00 - val_loss: 5.5163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7492e-05 - acc: 0.0000e+00 - val_loss: 6.1641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7846e-05 - acc: 0.0000e+00 - val_loss: 3.1007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8842e-05 - acc: 0.0000e+00 - val_loss: 6.1031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7726e-05 - acc: 0.0000e+00 - val_loss: 9.9901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0212e-05 - acc: 0.0000e+00 - val_loss: 8.2007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8043e-05 - acc: 0.0000e+00 - val_loss: 8.5960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2605e-05 - acc: 0.0000e+00 - val_loss: 4.3719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0478e-05 - acc: 0.0000e+00 - val_loss: 4.2340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9580e-05 - acc: 0.0000e+00 - val_loss: 3.7551e-04 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5733e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9769e-05 - acc: 0.0000e+00 - val_loss: 7.1827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9066e-05 - acc: 0.0000e+00 - val_loss: 3.3978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6380e-05 - acc: 0.0000e+00 - val_loss: 8.5174e-04 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6578e-05 - acc: 0.0000e+00 - val_loss: 5.6161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6997e-05 - acc: 0.0000e+00 - val_loss: 7.0406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4575e-05 - acc: 0.0000e+00 - val_loss: 6.2905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9156e-05 - acc: 0.0000e+00 - val_loss: 7.7921e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6416e-05 - acc: 0.0000e+00 - val_loss: 7.2014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8637e-05 - acc: 0.0000e+00 - val_loss: 9.1494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8647e-05 - acc: 0.0000e+00 - val_loss: 6.2667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5288e-05 - acc: 0.0000e+00 - val_loss: 4.4665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4588e-05 - acc: 0.0000e+00 - val_loss: 5.2453e-04 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6369e-05 - acc: 0.0000e+00 - val_loss: 7.8817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8175e-05 - acc: 0.0000e+00 - val_loss: 6.7251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5433e-05 - acc: 0.0000e+00 - val_loss: 8.0439e-04 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7328e-05 - acc: 0.0000e+00 - val_loss: 6.3759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9048e-05 - acc: 0.0000e+00 - val_loss: 4.4872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5619e-05 - acc: 0.0000e+00 - val_loss: 8.6864e-04 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6799e-05 - acc: 0.0000e+00 - val_loss: 7.3828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6257e-05 - acc: 0.0000e+00 - val_loss: 8.0887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3260e-05 - acc: 0.0000e+00 - val_loss: 5.9632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2596e-05 - acc: 0.0000e+00 - val_loss: 7.2372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1466e-05 - acc: 0.0000e+00 - val_loss: 5.2079e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6802e-05 - acc: 0.0000e+00 - val_loss: 8.9757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4732e-05 - acc: 0.0000e+00 - val_loss: 6.4950e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00013 MSE (0.01 RMSE)\n",
      "Test Score: 0.00223 MSE (0.05 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+0000\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9394e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5072e-04 - acc: 0.0000e+00 - val_loss: 5.8474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3459e-04 - acc: 0.0000e+00 - val_loss: 3.7061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9244e-04 - acc: 0.0000e+00 - val_loss: 2.9118e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7466e-04 - acc: 0.0000e+00 - val_loss: 2.5825e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5256e-04 - acc: 0.0000e+00 - val_loss: 5.3940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5238e-04 - acc: 0.0000e+00 - val_loss: 2.4065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3486e-04 - acc: 0.0000e+00 - val_loss: 5.0852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5004e-04 - acc: 0.0000e+00 - val_loss: 6.2537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4572e-04 - acc: 0.0000e+00 - val_loss: 2.3107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3060e-04 - acc: 0.0000e+00 - val_loss: 2.8896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5588e-04 - acc: 0.0000e+00 - val_loss: 8.0898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2104e-04 - acc: 0.0000e+00 - val_loss: 2.1620e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3444e-04 - acc: 0.0000e+00 - val_loss: 5.0109e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1459e-04 - acc: 0.0000e+00 - val_loss: 2.1089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2692e-04 - acc: 0.0000e+00 - val_loss: 2.3349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9929e-04 - acc: 0.0000e+00 - val_loss: 2.3987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0766e-04 - acc: 0.0000e+00 - val_loss: 2.0840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0740e-04 - acc: 0.0000e+00 - val_loss: 2.0594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1705e-04 - acc: 0.0000e+00 - val_loss: 2.4459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0874e-04 - acc: 0.0000e+00 - val_loss: 2.0697e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9554e-04 - acc: 0.0000e+00 - val_loss: 4.6310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1650e-04 - acc: 0.0000e+00 - val_loss: 2.1705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1688e-04 - acc: 0.0000e+00 - val_loss: 2.9588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9864e-04 - acc: 0.0000e+00 - val_loss: 2.3274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0670e-04 - acc: 0.0000e+00 - val_loss: 2.3590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1198e-04 - acc: 0.0000e+00 - val_loss: 2.2135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9162e-04 - acc: 0.0000e+00 - val_loss: 2.1607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8902e-04 - acc: 0.0000e+00 - val_loss: 4.6749e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9698e-04 - acc: 0.0000e+00 - val_loss: 2.5019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8899e-04 - acc: 0.0000e+00 - val_loss: 1.8822e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9212e-04 - acc: 0.0000e+00 - val_loss: 2.0576e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8264e-04 - acc: 0.0000e+00 - val_loss: 1.9257e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7753e-04 - acc: 0.0000e+00 - val_loss: 3.4138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8731e-04 - acc: 0.0000e+00 - val_loss: 2.1759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8391e-04 - acc: 0.0000e+00 - val_loss: 1.9001e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8392e-04 - acc: 0.0000e+00 - val_loss: 7.6525e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0947e-04 - acc: 0.0000e+00 - val_loss: 1.7666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7135e-04 - acc: 0.0000e+00 - val_loss: 1.7554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7852e-04 - acc: 0.0000e+00 - val_loss: 2.5486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6611e-04 - acc: 0.0000e+00 - val_loss: 2.6239e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8182e-04 - acc: 0.0000e+00 - val_loss: 1.8036e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7199e-04 - acc: 0.0000e+00 - val_loss: 1.7577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5637e-04 - acc: 0.0000e+00 - val_loss: 2.1600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8695e-04 - acc: 0.0000e+00 - val_loss: 7.4549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8026e-04 - acc: 0.0000e+00 - val_loss: 2.4794e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7000e-04 - acc: 0.0000e+00 - val_loss: 3.5737e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6763e-04 - acc: 0.0000e+00 - val_loss: 1.6839e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5622e-04 - acc: 0.0000e+00 - val_loss: 1.7348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5985e-04 - acc: 0.0000e+00 - val_loss: 1.6267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6144e-04 - acc: 0.0000e+00 - val_loss: 3.1402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7031e-04 - acc: 0.0000e+00 - val_loss: 8.4756e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6498e-04 - acc: 0.0000e+00 - val_loss: 1.6553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5236e-04 - acc: 0.0000e+00 - val_loss: 1.5752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6381e-04 - acc: 0.0000e+00 - val_loss: 1.5817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6023e-04 - acc: 0.0000e+00 - val_loss: 2.7356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3247e-04 - acc: 0.0000e+00 - val_loss: 1.6422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4644e-04 - acc: 0.0000e+00 - val_loss: 1.5575e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6397e-04 - acc: 0.0000e+00 - val_loss: 1.5144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5445e-04 - acc: 0.0000e+00 - val_loss: 2.7695e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4848e-04 - acc: 0.0000e+00 - val_loss: 1.7248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3311e-04 - acc: 0.0000e+00 - val_loss: 4.0052e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4159e-04 - acc: 0.0000e+00 - val_loss: 2.3234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4738e-04 - acc: 0.0000e+00 - val_loss: 1.4232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4297e-04 - acc: 0.0000e+00 - val_loss: 1.4645e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3418e-04 - acc: 0.0000e+00 - val_loss: 1.4097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3199e-04 - acc: 0.0000e+00 - val_loss: 3.6554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4490e-04 - acc: 0.0000e+00 - val_loss: 1.7464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2879e-04 - acc: 0.0000e+00 - val_loss: 1.6936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2345e-04 - acc: 0.0000e+00 - val_loss: 1.6393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2255e-04 - acc: 0.0000e+00 - val_loss: 1.8113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3485e-04 - acc: 0.0000e+00 - val_loss: 1.3567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2201e-04 - acc: 0.0000e+00 - val_loss: 1.4130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2188e-04 - acc: 0.0000e+00 - val_loss: 1.9105e-04 - val_acc: 0.0000e+0000\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1391e-04 - acc: 0.0000e+00 - val_loss: 2.3136e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2012e-04 - acc: 0.0000e+00 - val_loss: 1.8512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1108e-04 - acc: 0.0000e+00 - val_loss: 1.5274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2238e-04 - acc: 0.0000e+00 - val_loss: 1.3438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2524e-04 - acc: 0.0000e+00 - val_loss: 4.8044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2214e-04 - acc: 0.0000e+00 - val_loss: 1.4596e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1457e-04 - acc: 0.0000e+00 - val_loss: 3.0914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1937e-04 - acc: 0.0000e+00 - val_loss: 1.3383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1249e-04 - acc: 0.0000e+00 - val_loss: 1.3054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0861e-04 - acc: 0.0000e+00 - val_loss: 3.2082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3097e-04 - acc: 0.0000e+00 - val_loss: 1.5170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1506e-04 - acc: 0.0000e+00 - val_loss: 2.0245e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2407e-04 - acc: 0.0000e+00 - val_loss: 2.0201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0012e-04 - acc: 0.0000e+00 - val_loss: 1.2907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1059e-04 - acc: 0.0000e+00 - val_loss: 1.3377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1127e-04 - acc: 0.0000e+00 - val_loss: 2.1563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0752e-04 - acc: 0.0000e+00 - val_loss: 1.2963e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0548e-04 - acc: 0.0000e+00 - val_loss: 1.4898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7504e-05 - acc: 0.0000e+00 - val_loss: 1.2921e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0204e-04 - acc: 0.0000e+00 - val_loss: 1.8416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4265e-05 - acc: 0.0000e+00 - val_loss: 1.2894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3720e-05 - acc: 0.0000e+00 - val_loss: 1.2774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0131e-04 - acc: 0.0000e+00 - val_loss: 1.5685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4044e-05 - acc: 0.0000e+00 - val_loss: 1.4545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6335e-05 - acc: 0.0000e+00 - val_loss: 2.2784e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3834e-05 - acc: 0.0000e+00 - val_loss: 1.9397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2517e-05 - acc: 0.0000e+00 - val_loss: 1.2676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0039e-04 - acc: 0.0000e+00 - val_loss: 1.4698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6438e-05 - acc: 0.0000e+00 - val_loss: 2.8614e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0214e-04 - acc: 0.0000e+00 - val_loss: 1.2785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3759e-05 - acc: 0.0000e+00 - val_loss: 1.7592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7740e-05 - acc: 0.0000e+00 - val_loss: 1.8724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6387e-05 - acc: 0.0000e+00 - val_loss: 1.3339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2106e-05 - acc: 0.0000e+00 - val_loss: 3.1184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9505e-05 - acc: 0.0000e+00 - val_loss: 1.6738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4567e-05 - acc: 0.0000e+00 - val_loss: 1.5068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8620e-05 - acc: 0.0000e+00 - val_loss: 1.5387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8195e-05 - acc: 0.0000e+00 - val_loss: 2.4338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6478e-05 - acc: 0.0000e+00 - val_loss: 1.3077e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6121e-05 - acc: 0.0000e+00 - val_loss: 1.2244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2299e-05 - acc: 0.0000e+00 - val_loss: 1.3208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2623e-05 - acc: 0.0000e+00 - val_loss: 1.2590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3200e-05 - acc: 0.0000e+00 - val_loss: 1.4197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0783e-05 - acc: 0.0000e+00 - val_loss: 1.2855e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2233e-05 - acc: 0.0000e+00 - val_loss: 1.3273e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0185e-05 - acc: 0.0000e+00 - val_loss: 2.2177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1807e-05 - acc: 0.0000e+00 - val_loss: 1.7995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0771e-05 - acc: 0.0000e+00 - val_loss: 1.2267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1813e-05 - acc: 0.0000e+00 - val_loss: 1.3659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2489e-05 - acc: 0.0000e+00 - val_loss: 1.3445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7506e-05 - acc: 0.0000e+00 - val_loss: 3.8466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9159e-05 - acc: 0.0000e+00 - val_loss: 2.2810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8937e-05 - acc: 0.0000e+00 - val_loss: 1.2509e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7215e-05 - acc: 0.0000e+00 - val_loss: 1.3817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0868e-05 - acc: 0.0000e+00 - val_loss: 1.2075e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7859e-05 - acc: 0.0000e+00 - val_loss: 1.5659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9857e-05 - acc: 0.0000e+00 - val_loss: 1.1981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9683e-05 - acc: 0.0000e+00 - val_loss: 1.4242e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3464e-05 - acc: 0.0000e+00 - val_loss: 1.1791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7422e-05 - acc: 0.0000e+00 - val_loss: 1.7474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8859e-05 - acc: 0.0000e+00 - val_loss: 1.2569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5241e-05 - acc: 0.0000e+00 - val_loss: 1.1227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0622e-05 - acc: 0.0000e+00 - val_loss: 1.9055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2562e-05 - acc: 0.0000e+00 - val_loss: 1.1668e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0783e-05 - acc: 0.0000e+00 - val_loss: 1.7992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1424e-05 - acc: 0.0000e+00 - val_loss: 1.9834e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1905e-05 - acc: 0.0000e+00 - val_loss: 1.1222e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6254e-05 - acc: 0.0000e+00 - val_loss: 1.5660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5019e-05 - acc: 0.0000e+00 - val_loss: 1.8028e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8853e-05 - acc: 0.0000e+00 - val_loss: 1.1951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9495e-05 - acc: 0.0000e+00 - val_loss: 1.2143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1706e-05 - acc: 0.0000e+00 - val_loss: 2.0505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6048e-05 - acc: 0.0000e+00 - val_loss: 1.3667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2882e-05 - acc: 0.0000e+00 - val_loss: 1.2253e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4999e-05 - acc: 0.0000e+00 - val_loss: 1.2375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8232e-05 - acc: 0.0000e+00 - val_loss: 1.3332e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0559e-05 - acc: 0.0000e+00 - val_loss: 1.1764e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6864e-05 - acc: 0.0000e+00 - val_loss: 1.4618e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6028e-05 - acc: 0.0000e+00 - val_loss: 1.1745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1782e-05 - acc: 0.0000e+00 - val_loss: 1.2184e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6450e-05 - acc: 0.0000e+00 - val_loss: 1.2035e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4612e-05 - acc: 0.0000e+00 - val_loss: 1.2221e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0593e-05 - acc: 0.0000e+00 - val_loss: 2.7241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1296e-05 - acc: 0.0000e+00 - val_loss: 1.4057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1691e-05 - acc: 0.0000e+00 - val_loss: 1.1298e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9301e-05 - acc: 0.0000e+00 - val_loss: 1.1585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4087e-05 - acc: 0.0000e+00 - val_loss: 1.5222e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3793e-05 - acc: 0.0000e+00 - val_loss: 1.7010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8608e-05 - acc: 0.0000e+00 - val_loss: 3.1628e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0132e-05 - acc: 0.0000e+00 - val_loss: 1.1609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9550e-05 - acc: 0.0000e+00 - val_loss: 1.1385e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2328e-05 - acc: 0.0000e+00 - val_loss: 2.0685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8998e-05 - acc: 0.0000e+00 - val_loss: 1.1409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8152e-05 - acc: 0.0000e+00 - val_loss: 1.6447e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3882e-05 - acc: 0.0000e+00 - val_loss: 1.2515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8797e-05 - acc: 0.0000e+00 - val_loss: 1.3338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3242e-05 - acc: 0.0000e+00 - val_loss: 1.1289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1616e-05 - acc: 0.0000e+00 - val_loss: 1.5281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9882e-05 - acc: 0.0000e+00 - val_loss: 1.2248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4397e-05 - acc: 0.0000e+00 - val_loss: 1.1416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0084e-05 - acc: 0.0000e+00 - val_loss: 1.2345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2322e-05 - acc: 0.0000e+00 - val_loss: 1.0766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6023e-05 - acc: 0.0000e+00 - val_loss: 1.1570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7515e-05 - acc: 0.0000e+00 - val_loss: 1.1179e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7967e-05 - acc: 0.0000e+00 - val_loss: 1.2051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5422e-05 - acc: 0.0000e+00 - val_loss: 1.7609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1599e-05 - acc: 0.0000e+00 - val_loss: 1.5782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3628e-05 - acc: 0.0000e+00 - val_loss: 1.2488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2825e-05 - acc: 0.0000e+00 - val_loss: 1.1283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9425e-05 - acc: 0.0000e+00 - val_loss: 1.2524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4888e-05 - acc: 0.0000e+00 - val_loss: 1.2252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8506e-05 - acc: 0.0000e+00 - val_loss: 1.4287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7745e-05 - acc: 0.0000e+00 - val_loss: 2.0512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1121e-05 - acc: 0.0000e+00 - val_loss: 1.9467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2846e-05 - acc: 0.0000e+00 - val_loss: 1.2329e-04 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5664e-05 - acc: 0.0000e+00 - val_loss: 1.9110e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8697e-05 - acc: 0.0000e+00 - val_loss: 1.2126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6038e-05 - acc: 0.0000e+00 - val_loss: 2.3818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8044e-05 - acc: 0.0000e+00 - val_loss: 1.3099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3732e-05 - acc: 0.0000e+00 - val_loss: 1.1213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3969e-05 - acc: 0.0000e+00 - val_loss: 1.3187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2717e-05 - acc: 0.0000e+00 - val_loss: 1.0646e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7569e-05 - acc: 0.0000e+00 - val_loss: 1.1197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7443e-05 - acc: 0.0000e+00 - val_loss: 1.0446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2139e-05 - acc: 0.0000e+00 - val_loss: 1.0632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6544e-05 - acc: 0.0000e+00 - val_loss: 1.2540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9468e-05 - acc: 0.0000e+00 - val_loss: 1.9867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1620e-05 - acc: 0.0000e+00 - val_loss: 1.0763e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6003e-05 - acc: 0.0000e+00 - val_loss: 1.0648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2303e-05 - acc: 0.0000e+00 - val_loss: 1.0303e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9844e-05 - acc: 0.0000e+00 - val_loss: 1.0600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2151e-05 - acc: 0.0000e+00 - val_loss: 1.4827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4383e-05 - acc: 0.0000e+00 - val_loss: 1.1854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9670e-05 - acc: 0.0000e+00 - val_loss: 1.0738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8342e-05 - acc: 0.0000e+00 - val_loss: 1.0530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3738e-05 - acc: 0.0000e+00 - val_loss: 1.0798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0454e-05 - acc: 0.0000e+00 - val_loss: 1.2263e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1032e-05 - acc: 0.0000e+00 - val_loss: 1.3996e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9959e-05 - acc: 0.0000e+00 - val_loss: 1.1025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7925e-05 - acc: 0.0000e+00 - val_loss: 1.5510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1216e-05 - acc: 0.0000e+00 - val_loss: 1.9629e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7475e-05 - acc: 0.0000e+00 - val_loss: 1.0115e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1581e-05 - acc: 0.0000e+00 - val_loss: 1.1191e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4284e-05 - acc: 0.0000e+00 - val_loss: 1.0124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7498e-05 - acc: 0.0000e+00 - val_loss: 1.1479e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8663e-05 - acc: 0.0000e+00 - val_loss: 1.7664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7405e-05 - acc: 0.0000e+00 - val_loss: 1.0198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3040e-05 - acc: 0.0000e+00 - val_loss: 1.2547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7431e-05 - acc: 0.0000e+00 - val_loss: 1.9220e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5968e-05 - acc: 0.0000e+00 - val_loss: 1.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2070e-05 - acc: 0.0000e+00 - val_loss: 1.4379e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4778e-05 - acc: 0.0000e+00 - val_loss: 1.2681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3250e-05 - acc: 0.0000e+00 - val_loss: 9.7876e-05 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0361e-05 - acc: 0.0000e+00 - val_loss: 1.3320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8374e-05 - acc: 0.0000e+00 - val_loss: 1.3013e-04 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2750e-05 - acc: 0.0000e+00 - val_loss: 1.0110e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3470e-05 - acc: 0.0000e+00 - val_loss: 1.1140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5594e-05 - acc: 0.0000e+00 - val_loss: 1.5273e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2522e-05 - acc: 0.0000e+00 - val_loss: 1.1535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6578e-05 - acc: 0.0000e+00 - val_loss: 1.5998e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4088e-05 - acc: 0.0000e+00 - val_loss: 1.5390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6779e-05 - acc: 0.0000e+00 - val_loss: 1.4682e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7922e-05 - acc: 0.0000e+00 - val_loss: 9.3174e-05 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3265e-05 - acc: 0.0000e+00 - val_loss: 1.8856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9233e-05 - acc: 0.0000e+00 - val_loss: 1.8091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3853e-05 - acc: 0.0000e+00 - val_loss: 3.0095e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7781e-05 - acc: 0.0000e+00 - val_loss: 1.2316e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1021e-05 - acc: 0.0000e+00 - val_loss: 1.5146e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1456e-05 - acc: 0.0000e+00 - val_loss: 1.3466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5871e-05 - acc: 0.0000e+00 - val_loss: 1.2314e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3193e-05 - acc: 0.0000e+00 - val_loss: 1.0981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3116e-05 - acc: 0.0000e+00 - val_loss: 1.3150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6954e-05 - acc: 0.0000e+00 - val_loss: 1.0201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1027e-05 - acc: 0.0000e+00 - val_loss: 2.4730e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0447e-05 - acc: 0.0000e+00 - val_loss: 1.1942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4079e-05 - acc: 0.0000e+00 - val_loss: 1.1747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2458e-05 - acc: 0.0000e+00 - val_loss: 1.0363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4177e-05 - acc: 0.0000e+00 - val_loss: 1.1266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3721e-05 - acc: 0.0000e+00 - val_loss: 1.1055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0623e-05 - acc: 0.0000e+00 - val_loss: 1.2630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7740e-05 - acc: 0.0000e+00 - val_loss: 1.0913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6993e-05 - acc: 0.0000e+00 - val_loss: 9.7524e-05 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1242e-05 - acc: 0.0000e+00 - val_loss: 1.1515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2337e-05 - acc: 0.0000e+00 - val_loss: 9.7952e-05 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2440e-05 - acc: 0.0000e+00 - val_loss: 1.6855e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5380e-05 - acc: 0.0000e+00 - val_loss: 1.2676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0743e-05 - acc: 0.0000e+00 - val_loss: 2.2898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5650e-05 - acc: 0.0000e+00 - val_loss: 1.0924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8488e-05 - acc: 0.0000e+00 - val_loss: 8.8419e-05 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9993e-05 - acc: 0.0000e+00 - val_loss: 1.1606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9953e-05 - acc: 0.0000e+00 - val_loss: 1.3346e-04 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1597e-05 - acc: 0.0000e+00 - val_loss: 1.6634e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3323e-05 - acc: 0.0000e+00 - val_loss: 1.3890e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1693e-05 - acc: 0.0000e+00 - val_loss: 1.0279e-04 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0918e-05 - acc: 0.0000e+00 - val_loss: 9.3707e-05 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9399e-05 - acc: 0.0000e+00 - val_loss: 1.0380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3103e-05 - acc: 0.0000e+00 - val_loss: 1.4977e-04 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.3189e-05 - acc: 0.0000e+00 - val_loss: 1.3721e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2630e-05 - acc: 0.0000e+00 - val_loss: 1.1542e-04 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9756e-05 - acc: 0.0000e+00 - val_loss: 9.4683e-05 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7233e-05 - acc: 0.0000e+00 - val_loss: 9.0343e-05 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5547e-05 - acc: 0.0000e+00 - val_loss: 9.0549e-05 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8327e-05 - acc: 0.0000e+00 - val_loss: 8.9974e-05 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7631e-05 - acc: 0.0000e+00 - val_loss: 9.6555e-05 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5944e-05 - acc: 0.0000e+00 - val_loss: 2.5733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1099e-05 - acc: 0.0000e+00 - val_loss: 1.9478e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6470e-05 - acc: 0.0000e+00 - val_loss: 3.0808e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4080e-05 - acc: 0.0000e+00 - val_loss: 1.0495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9222e-05 - acc: 0.0000e+00 - val_loss: 8.4861e-05 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8117e-05 - acc: 0.0000e+00 - val_loss: 9.6464e-05 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8539e-05 - acc: 0.0000e+00 - val_loss: 9.0727e-05 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9883e-05 - acc: 0.0000e+00 - val_loss: 8.1974e-05 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5807e-05 - acc: 0.0000e+00 - val_loss: 1.4715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4835e-05 - acc: 0.0000e+00 - val_loss: 9.2197e-05 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5945e-05 - acc: 0.0000e+00 - val_loss: 9.4772e-05 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9566e-05 - acc: 0.0000e+00 - val_loss: 1.9376e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0818e-05 - acc: 0.0000e+00 - val_loss: 1.0003e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9343e-05 - acc: 0.0000e+00 - val_loss: 9.5092e-05 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9634e-05 - acc: 0.0000e+00 - val_loss: 1.1669e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4528e-05 - acc: 0.0000e+00 - val_loss: 1.3761e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6013e-05 - acc: 0.0000e+00 - val_loss: 1.0861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6978e-05 - acc: 0.0000e+00 - val_loss: 2.0963e-04 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6692e-05 - acc: 0.0000e+00 - val_loss: 2.4573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7129e-05 - acc: 0.0000e+00 - val_loss: 2.3804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9061e-05 - acc: 0.0000e+00 - val_loss: 9.7557e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.01020 MSE (0.10 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7047e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.2440e-04 - acc: 0.0000e+00 - val_loss: 6.6885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1595e-04 - acc: 0.0000e+00 - val_loss: 4.3015e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9376e-04 - acc: 0.0000e+00 - val_loss: 4.0145e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6609e-04 - acc: 0.0000e+00 - val_loss: 4.6610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2988e-04 - acc: 0.0000e+00 - val_loss: 3.1850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4119e-04 - acc: 0.0000e+00 - val_loss: 3.8677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1360e-04 - acc: 0.0000e+00 - val_loss: 3.4713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2563e-04 - acc: 0.0000e+00 - val_loss: 6.7438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4692e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3828e-04 - acc: 0.0000e+00 - val_loss: 2.6580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8596e-04 - acc: 0.0000e+00 - val_loss: 5.3410e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3137e-04 - acc: 0.0000e+00 - val_loss: 8.8481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0767e-04 - acc: 0.0000e+00 - val_loss: 4.8390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1022e-04 - acc: 0.0000e+00 - val_loss: 6.7400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8798e-04 - acc: 0.0000e+00 - val_loss: 9.7486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7987e-04 - acc: 0.0000e+00 - val_loss: 6.8535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8777e-04 - acc: 0.0000e+00 - val_loss: 5.7020e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7076e-04 - acc: 0.0000e+00 - val_loss: 2.5843e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2128e-04 - acc: 0.0000e+00 - val_loss: 2.6402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7462e-04 - acc: 0.0000e+00 - val_loss: 2.2810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6210e-04 - acc: 0.0000e+00 - val_loss: 3.5313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6585e-04 - acc: 0.0000e+00 - val_loss: 2.4631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1488e-04 - acc: 0.0000e+00 - val_loss: 3.3157e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6708e-04 - acc: 0.0000e+00 - val_loss: 3.7416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5684e-04 - acc: 0.0000e+00 - val_loss: 7.9296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4138e-04 - acc: 0.0000e+00 - val_loss: 2.4181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3191e-04 - acc: 0.0000e+00 - val_loss: 2.1845e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1511e-04 - acc: 0.0000e+00 - val_loss: 2.2446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2186e-04 - acc: 0.0000e+00 - val_loss: 2.0910e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2725e-04 - acc: 0.0000e+00 - val_loss: 2.3561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2940e-04 - acc: 0.0000e+00 - val_loss: 3.1238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3394e-04 - acc: 0.0000e+00 - val_loss: 2.6932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1165e-04 - acc: 0.0000e+00 - val_loss: 2.1621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1584e-04 - acc: 0.0000e+00 - val_loss: 5.2774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5276e-04 - acc: 0.0000e+00 - val_loss: 8.2725e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3478e-04 - acc: 0.0000e+00 - val_loss: 3.4009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3294e-04 - acc: 0.0000e+00 - val_loss: 3.9240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0828e-04 - acc: 0.0000e+00 - val_loss: 2.3799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9982e-04 - acc: 0.0000e+00 - val_loss: 2.0431e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9265e-04 - acc: 0.0000e+00 - val_loss: 4.9360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0135e-04 - acc: 0.0000e+00 - val_loss: 4.0689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9627e-04 - acc: 0.0000e+00 - val_loss: 1.8716e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7764e-04 - acc: 0.0000e+00 - val_loss: 1.8269e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7685e-04 - acc: 0.0000e+00 - val_loss: 2.4523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8795e-04 - acc: 0.0000e+00 - val_loss: 1.9029e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6938e-04 - acc: 0.0000e+00 - val_loss: 2.9745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7403e-04 - acc: 0.0000e+00 - val_loss: 3.7796e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1103e-04 - acc: 0.0000e+00 - val_loss: 1.9371e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8192e-04 - acc: 0.0000e+00 - val_loss: 3.0683e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5982e-04 - acc: 0.0000e+00 - val_loss: 2.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5126e-04 - acc: 0.0000e+00 - val_loss: 1.9760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5014e-04 - acc: 0.0000e+00 - val_loss: 1.8921e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4582e-04 - acc: 0.0000e+00 - val_loss: 1.8051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5007e-04 - acc: 0.0000e+00 - val_loss: 2.3593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5949e-04 - acc: 0.0000e+00 - val_loss: 1.8523e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4790e-04 - acc: 0.0000e+00 - val_loss: 1.7967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4080e-04 - acc: 0.0000e+00 - val_loss: 1.9178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4572e-04 - acc: 0.0000e+00 - val_loss: 3.2454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4715e-04 - acc: 0.0000e+00 - val_loss: 2.3090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4608e-04 - acc: 0.0000e+00 - val_loss: 6.2801e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4033e-04 - acc: 0.0000e+00 - val_loss: 1.8970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3022e-04 - acc: 0.0000e+00 - val_loss: 2.6361e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3015e-04 - acc: 0.0000e+00 - val_loss: 2.3959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4517e-04 - acc: 0.0000e+00 - val_loss: 4.3565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4071e-04 - acc: 0.0000e+00 - val_loss: 1.8595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3564e-04 - acc: 0.0000e+00 - val_loss: 1.8283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3175e-04 - acc: 0.0000e+00 - val_loss: 1.8106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3212e-04 - acc: 0.0000e+00 - val_loss: 7.9079e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4142e-04 - acc: 0.0000e+00 - val_loss: 1.8438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2241e-04 - acc: 0.0000e+00 - val_loss: 1.9637e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2134e-04 - acc: 0.0000e+00 - val_loss: 1.9795e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2303e-04 - acc: 0.0000e+00 - val_loss: 1.8200e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1591e-04 - acc: 0.0000e+00 - val_loss: 1.8617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2509e-04 - acc: 0.0000e+00 - val_loss: 1.7907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1656e-04 - acc: 0.0000e+00 - val_loss: 4.6717e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1367e-04 - acc: 0.0000e+00 - val_loss: 1.9309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1463e-04 - acc: 0.0000e+00 - val_loss: 3.0223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4130e-04 - acc: 0.0000e+00 - val_loss: 4.0616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2613e-04 - acc: 0.0000e+00 - val_loss: 1.9107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0481e-04 - acc: 0.0000e+00 - val_loss: 2.7407e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1483e-04 - acc: 0.0000e+00 - val_loss: 1.7773e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0660e-04 - acc: 0.0000e+00 - val_loss: 1.7335e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0524e-04 - acc: 0.0000e+00 - val_loss: 2.8505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2553e-04 - acc: 0.0000e+00 - val_loss: 3.5930e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1682e-04 - acc: 0.0000e+00 - val_loss: 2.3035e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0375e-04 - acc: 0.0000e+00 - val_loss: 2.3473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1400e-04 - acc: 0.0000e+00 - val_loss: 3.7711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1315e-04 - acc: 0.0000e+00 - val_loss: 4.4780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0942e-04 - acc: 0.0000e+00 - val_loss: 1.8529e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1823e-04 - acc: 0.0000e+00 - val_loss: 2.4751e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0368e-04 - acc: 0.0000e+00 - val_loss: 1.8130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1755e-04 - acc: 0.0000e+00 - val_loss: 3.8385e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1459e-04 - acc: 0.0000e+00 - val_loss: 1.7053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1151e-04 - acc: 0.0000e+00 - val_loss: 1.6789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0477e-04 - acc: 0.0000e+00 - val_loss: 2.1350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4519e-05 - acc: 0.0000e+00 - val_loss: 2.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8510e-05 - acc: 0.0000e+00 - val_loss: 2.3352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0034e-04 - acc: 0.0000e+00 - val_loss: 2.5685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3274e-05 - acc: 0.0000e+00 - val_loss: 2.0058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9318e-05 - acc: 0.0000e+00 - val_loss: 1.5693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7682e-05 - acc: 0.0000e+00 - val_loss: 1.6589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4833e-05 - acc: 0.0000e+00 - val_loss: 1.7036e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0899e-05 - acc: 0.0000e+00 - val_loss: 1.6080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7552e-05 - acc: 0.0000e+00 - val_loss: 1.7142e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7904e-05 - acc: 0.0000e+00 - val_loss: 2.0942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9562e-05 - acc: 0.0000e+00 - val_loss: 1.8925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3547e-05 - acc: 0.0000e+00 - val_loss: 1.7102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3139e-05 - acc: 0.0000e+00 - val_loss: 1.5895e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2996e-05 - acc: 0.0000e+00 - val_loss: 2.3519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4501e-05 - acc: 0.0000e+00 - val_loss: 2.2187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8456e-05 - acc: 0.0000e+00 - val_loss: 1.5875e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3571e-05 - acc: 0.0000e+00 - val_loss: 3.6666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1100e-04 - acc: 0.0000e+00 - val_loss: 2.5856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0639e-04 - acc: 0.0000e+00 - val_loss: 1.8973e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6261e-05 - acc: 0.0000e+00 - val_loss: 1.4700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7523e-05 - acc: 0.0000e+00 - val_loss: 1.7699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3360e-05 - acc: 0.0000e+00 - val_loss: 2.2095e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2376e-05 - acc: 0.0000e+00 - val_loss: 1.4597e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0325e-04 - acc: 0.0000e+00 - val_loss: 1.6012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7587e-05 - acc: 0.0000e+00 - val_loss: 2.6337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5263e-05 - acc: 0.0000e+00 - val_loss: 1.4663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7693e-05 - acc: 0.0000e+00 - val_loss: 1.6658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3065e-05 - acc: 0.0000e+00 - val_loss: 1.5384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3290e-05 - acc: 0.0000e+00 - val_loss: 2.8128e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8766e-05 - acc: 0.0000e+00 - val_loss: 1.5554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4625e-05 - acc: 0.0000e+00 - val_loss: 1.4093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9797e-05 - acc: 0.0000e+00 - val_loss: 1.6108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7305e-05 - acc: 0.0000e+00 - val_loss: 1.5108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4592e-05 - acc: 0.0000e+00 - val_loss: 2.5204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9475e-05 - acc: 0.0000e+00 - val_loss: 2.6891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8622e-05 - acc: 0.0000e+00 - val_loss: 1.7379e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6863e-05 - acc: 0.0000e+00 - val_loss: 1.4904e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7840e-05 - acc: 0.0000e+00 - val_loss: 1.4870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1085e-05 - acc: 0.0000e+00 - val_loss: 1.6426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3865e-05 - acc: 0.0000e+00 - val_loss: 1.3573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4224e-05 - acc: 0.0000e+00 - val_loss: 1.4545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3954e-05 - acc: 0.0000e+00 - val_loss: 2.2154e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2639e-05 - acc: 0.0000e+00 - val_loss: 1.6129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7703e-05 - acc: 0.0000e+00 - val_loss: 2.3872e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5087e-05 - acc: 0.0000e+00 - val_loss: 1.7779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3217e-05 - acc: 0.0000e+00 - val_loss: 3.8392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5180e-05 - acc: 0.0000e+00 - val_loss: 1.4202e-04 - val_acc: 0.0000e+00- ETA: 0s - loss: 9.2897e-05 - \n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1882e-05 - acc: 0.0000e+00 - val_loss: 4.0928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8688e-05 - acc: 0.0000e+00 - val_loss: 1.6493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4141e-05 - acc: 0.0000e+00 - val_loss: 1.4611e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3430e-05 - acc: 0.0000e+00 - val_loss: 1.4648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7399e-05 - acc: 0.0000e+00 - val_loss: 2.6628e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9887e-05 - acc: 0.0000e+00 - val_loss: 3.6011e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9753e-05 - acc: 0.0000e+00 - val_loss: 1.6192e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1634e-05 - acc: 0.0000e+00 - val_loss: 2.2466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4826e-05 - acc: 0.0000e+00 - val_loss: 2.2539e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6112e-05 - acc: 0.0000e+00 - val_loss: 2.3590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1982e-05 - acc: 0.0000e+00 - val_loss: 3.2697e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7359e-05 - acc: 0.0000e+00 - val_loss: 2.6198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8296e-05 - acc: 0.0000e+00 - val_loss: 1.4091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6299e-05 - acc: 0.0000e+00 - val_loss: 1.3684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1581e-05 - acc: 0.0000e+00 - val_loss: 1.9708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3794e-05 - acc: 0.0000e+00 - val_loss: 1.6217e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8962e-05 - acc: 0.0000e+00 - val_loss: 2.3966e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5534e-05 - acc: 0.0000e+00 - val_loss: 2.1543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7931e-05 - acc: 0.0000e+00 - val_loss: 1.5492e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2376e-05 - acc: 0.0000e+00 - val_loss: 2.6767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1835e-05 - acc: 0.0000e+00 - val_loss: 2.7275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3535e-05 - acc: 0.0000e+00 - val_loss: 1.8911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6043e-05 - acc: 0.0000e+00 - val_loss: 1.3252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2925e-05 - acc: 0.0000e+00 - val_loss: 2.0640e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5092e-05 - acc: 0.0000e+00 - val_loss: 1.5972e-04 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6507e-05 - acc: 0.0000e+00 - val_loss: 1.5043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7465e-05 - acc: 0.0000e+00 - val_loss: 1.6337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3987e-05 - acc: 0.0000e+00 - val_loss: 1.7387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6153e-05 - acc: 0.0000e+00 - val_loss: 3.8340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8529e-05 - acc: 0.0000e+00 - val_loss: 1.9490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1338e-05 - acc: 0.0000e+00 - val_loss: 1.6970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3363e-05 - acc: 0.0000e+00 - val_loss: 3.0670e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4150e-05 - acc: 0.0000e+00 - val_loss: 1.5438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1480e-05 - acc: 0.0000e+00 - val_loss: 1.5380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2509e-05 - acc: 0.0000e+00 - val_loss: 2.7066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5510e-05 - acc: 0.0000e+00 - val_loss: 1.3650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4630e-05 - acc: 0.0000e+00 - val_loss: 1.3353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5565e-05 - acc: 0.0000e+00 - val_loss: 1.4595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5393e-05 - acc: 0.0000e+00 - val_loss: 1.5411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2473e-05 - acc: 0.0000e+00 - val_loss: 2.4780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0011e-05 - acc: 0.0000e+00 - val_loss: 1.3751e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2437e-05 - acc: 0.0000e+00 - val_loss: 1.4915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0253e-05 - acc: 0.0000e+00 - val_loss: 1.3225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2093e-05 - acc: 0.0000e+00 - val_loss: 1.9258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4188e-05 - acc: 0.0000e+00 - val_loss: 1.4524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2855e-05 - acc: 0.0000e+00 - val_loss: 2.9472e-04 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2461e-05 - acc: 0.0000e+00 - val_loss: 1.4657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6744e-05 - acc: 0.0000e+00 - val_loss: 1.6275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5481e-05 - acc: 0.0000e+00 - val_loss: 1.3530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8632e-05 - acc: 0.0000e+00 - val_loss: 1.2967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9056e-05 - acc: 0.0000e+00 - val_loss: 3.0873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2150e-05 - acc: 0.0000e+00 - val_loss: 1.6989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2870e-05 - acc: 0.0000e+00 - val_loss: 1.4103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8973e-05 - acc: 0.0000e+00 - val_loss: 2.6675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4724e-05 - acc: 0.0000e+00 - val_loss: 2.9920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7994e-05 - acc: 0.0000e+00 - val_loss: 1.4166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2931e-05 - acc: 0.0000e+00 - val_loss: 1.3818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0781e-05 - acc: 0.0000e+00 - val_loss: 1.9384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8066e-05 - acc: 0.0000e+00 - val_loss: 2.6163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2765e-05 - acc: 0.0000e+00 - val_loss: 1.4740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9020e-05 - acc: 0.0000e+00 - val_loss: 2.2461e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4533e-05 - acc: 0.0000e+00 - val_loss: 1.2598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4241e-05 - acc: 0.0000e+00 - val_loss: 1.3926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8445e-05 - acc: 0.0000e+00 - val_loss: 1.3943e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0971e-05 - acc: 0.0000e+00 - val_loss: 1.3019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7642e-05 - acc: 0.0000e+00 - val_loss: 1.2290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7466e-05 - acc: 0.0000e+00 - val_loss: 1.2665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2971e-05 - acc: 0.0000e+00 - val_loss: 1.8148e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7039e-05 - acc: 0.0000e+00 - val_loss: 1.7107e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3798e-05 - acc: 0.0000e+00 - val_loss: 1.8323e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8293e-05 - acc: 0.0000e+00 - val_loss: 1.3636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3974e-05 - acc: 0.0000e+00 - val_loss: 3.7898e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0591e-05 - acc: 0.0000e+00 - val_loss: 2.3778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8926e-05 - acc: 0.0000e+00 - val_loss: 1.1722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9471e-05 - acc: 0.0000e+00 - val_loss: 2.1587e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7361e-05 - acc: 0.0000e+00 - val_loss: 1.6339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6394e-05 - acc: 0.0000e+00 - val_loss: 2.5797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1036e-05 - acc: 0.0000e+00 - val_loss: 1.2630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4041e-05 - acc: 0.0000e+00 - val_loss: 1.7537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5730e-05 - acc: 0.0000e+00 - val_loss: 1.6541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7732e-05 - acc: 0.0000e+00 - val_loss: 1.4778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5896e-05 - acc: 0.0000e+00 - val_loss: 1.8634e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0838e-05 - acc: 0.0000e+00 - val_loss: 1.3258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5321e-05 - acc: 0.0000e+00 - val_loss: 2.6912e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2472e-05 - acc: 0.0000e+00 - val_loss: 1.4378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8706e-05 - acc: 0.0000e+00 - val_loss: 1.5918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3799e-05 - acc: 0.0000e+00 - val_loss: 1.4681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0157e-05 - acc: 0.0000e+00 - val_loss: 1.2865e-04 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7393e-05 - acc: 0.0000e+00 - val_loss: 1.6412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6449e-05 - acc: 0.0000e+00 - val_loss: 1.2397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6478e-05 - acc: 0.0000e+00 - val_loss: 4.2292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0995e-05 - acc: 0.0000e+00 - val_loss: 1.9373e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3382e-05 - acc: 0.0000e+00 - val_loss: 1.3537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4566e-05 - acc: 0.0000e+00 - val_loss: 1.8424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2515e-05 - acc: 0.0000e+00 - val_loss: 1.7937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2237e-05 - acc: 0.0000e+00 - val_loss: 1.5285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2276e-05 - acc: 0.0000e+00 - val_loss: 1.3065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3451e-05 - acc: 0.0000e+00 - val_loss: 1.2664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8749e-05 - acc: 0.0000e+00 - val_loss: 5.3545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5261e-05 - acc: 0.0000e+00 - val_loss: 1.8167e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9969e-05 - acc: 0.0000e+00 - val_loss: 1.9029e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4475e-05 - acc: 0.0000e+00 - val_loss: 1.1217e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1917e-05 - acc: 0.0000e+00 - val_loss: 1.1719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1874e-05 - acc: 0.0000e+00 - val_loss: 1.4093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.1113e-05 - acc: 0.0000e+00 - val_loss: 2.7620e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5746e-05 - acc: 0.0000e+00 - val_loss: 3.2060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2537e-05 - acc: 0.0000e+00 - val_loss: 1.6536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0386e-05 - acc: 0.0000e+00 - val_loss: 1.8480e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7452e-05 - acc: 0.0000e+00 - val_loss: 1.7845e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9035e-05 - acc: 0.0000e+00 - val_loss: 1.3608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6192e-05 - acc: 0.0000e+00 - val_loss: 1.4072e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0930e-05 - acc: 0.0000e+00 - val_loss: 1.5739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8575e-05 - acc: 0.0000e+00 - val_loss: 2.4562e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6940e-05 - acc: 0.0000e+00 - val_loss: 1.1496e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9611e-05 - acc: 0.0000e+00 - val_loss: 1.3642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6243e-05 - acc: 0.0000e+00 - val_loss: 1.6713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2638e-05 - acc: 0.0000e+00 - val_loss: 1.3231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8092e-05 - acc: 0.0000e+00 - val_loss: 1.4920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2144e-05 - acc: 0.0000e+00 - val_loss: 1.2118e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9098e-05 - acc: 0.0000e+00 - val_loss: 1.2568e-04 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3898e-05 - acc: 0.0000e+00 - val_loss: 1.3974e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2485e-05 - acc: 0.0000e+00 - val_loss: 1.3433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9859e-05 - acc: 0.0000e+00 - val_loss: 1.7175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8895e-05 - acc: 0.0000e+00 - val_loss: 2.5076e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7728e-05 - acc: 0.0000e+00 - val_loss: 1.8304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5977e-05 - acc: 0.0000e+00 - val_loss: 1.4892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9828e-05 - acc: 0.0000e+00 - val_loss: 1.1163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7622e-05 - acc: 0.0000e+00 - val_loss: 1.5074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2082e-05 - acc: 0.0000e+00 - val_loss: 1.5785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0645e-05 - acc: 0.0000e+00 - val_loss: 1.9091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.4244e-05 - acc: 0.0000e+00 - val_loss: 2.0193e-04 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2321e-05 - acc: 0.0000e+00 - val_loss: 1.8155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5340e-05 - acc: 0.0000e+00 - val_loss: 1.2953e-04 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8348e-05 - acc: 0.0000e+00 - val_loss: 1.3199e-04 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3089e-05 - acc: 0.0000e+00 - val_loss: 1.1697e-04 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8283e-05 - acc: 0.0000e+00 - val_loss: 1.5540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0832e-05 - acc: 0.0000e+00 - val_loss: 1.0603e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4353e-05 - acc: 0.0000e+00 - val_loss: 1.2747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9952e-05 - acc: 0.0000e+00 - val_loss: 1.3812e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.7292e-05 - acc: 0.0000e+00 - val_loss: 1.3522e-04 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8882e-05 - acc: 0.0000e+00 - val_loss: 1.1946e-04 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5171e-05 - acc: 0.0000e+00 - val_loss: 1.1019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9218e-05 - acc: 0.0000e+00 - val_loss: 4.5908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5222e-05 - acc: 0.0000e+00 - val_loss: 1.4138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0875e-05 - acc: 0.0000e+00 - val_loss: 1.6488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8259e-05 - acc: 0.0000e+00 - val_loss: 1.0965e-04 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2715e-05 - acc: 0.0000e+00 - val_loss: 1.2354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6251e-05 - acc: 0.0000e+00 - val_loss: 4.3120e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6403e-05 - acc: 0.0000e+00 - val_loss: 2.2879e-04 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9023e-05 - acc: 0.0000e+00 - val_loss: 1.2297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6180e-05 - acc: 0.0000e+00 - val_loss: 1.2277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8272e-05 - acc: 0.0000e+00 - val_loss: 1.1051e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6324e-05 - acc: 0.0000e+00 - val_loss: 2.8671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9531e-05 - acc: 0.0000e+00 - val_loss: 2.0190e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8640e-05 - acc: 0.0000e+00 - val_loss: 3.7049e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4655e-05 - acc: 0.0000e+00 - val_loss: 1.9034e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.01902 MSE (0.14 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4386e-04 - acc: 0.0000e+00 - val_loss: 5.4717e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5911e-04 - acc: 0.0000e+00 - val_loss: 4.4798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6878e-04 - acc: 0.0000e+00 - val_loss: 4.6753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.0826e-04 - acc: 0.0000e+00 - val_loss: 7.1541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7876e-04 - acc: 0.0000e+00 - val_loss: 2.7994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5514e-04 - acc: 0.0000e+00 - val_loss: 2.9044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.3154e-04 - acc: 0.0000e+00 - val_loss: 2.6270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1989e-04 - acc: 0.0000e+00 - val_loss: 2.5304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0541e-04 - acc: 0.0000e+00 - val_loss: 2.9865e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.4254e-04 - acc: 0.0000e+00 - val_loss: 8.1913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1472e-04 - acc: 0.0000e+00 - val_loss: 4.6979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5242e-04 - acc: 0.0000e+00 - val_loss: 3.1256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2801e-04 - acc: 0.0000e+00 - val_loss: 4.7598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7100e-04 - acc: 0.0000e+00 - val_loss: 3.2847e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.6308e-04 - acc: 0.0000e+00 - val_loss: 4.8486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9300e-04 - acc: 0.0000e+00 - val_loss: 2.7858e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7778e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5661e-04 - acc: 0.0000e+00 - val_loss: 4.5353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3533e-04 - acc: 0.0000e+00 - val_loss: 3.3419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4494e-04 - acc: 0.0000e+00 - val_loss: 2.2743e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0804e-04 - acc: 0.0000e+00 - val_loss: 2.8642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3852e-04 - acc: 0.0000e+00 - val_loss: 8.6978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1388e-04 - acc: 0.0000e+00 - val_loss: 3.2524e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1022e-04 - acc: 0.0000e+00 - val_loss: 2.3178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8452e-04 - acc: 0.0000e+00 - val_loss: 2.4241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9892e-04 - acc: 0.0000e+00 - val_loss: 4.2017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9662e-04 - acc: 0.0000e+00 - val_loss: 2.4998e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7747e-04 - acc: 0.0000e+00 - val_loss: 2.0171e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6957e-04 - acc: 0.0000e+00 - val_loss: 3.4630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6704e-04 - acc: 0.0000e+00 - val_loss: 2.0108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5439e-04 - acc: 0.0000e+00 - val_loss: 2.1021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5575e-04 - acc: 0.0000e+00 - val_loss: 2.0457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4987e-04 - acc: 0.0000e+00 - val_loss: 1.9787e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5587e-04 - acc: 0.0000e+00 - val_loss: 3.0186e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3401e-04 - acc: 0.0000e+00 - val_loss: 3.8604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3493e-04 - acc: 0.0000e+00 - val_loss: 1.9353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3649e-04 - acc: 0.0000e+00 - val_loss: 3.4251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1416e-04 - acc: 0.0000e+00 - val_loss: 4.9627e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1964e-04 - acc: 0.0000e+00 - val_loss: 4.9572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9810e-04 - acc: 0.0000e+00 - val_loss: 2.1679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2570e-04 - acc: 0.0000e+00 - val_loss: 2.0586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0277e-04 - acc: 0.0000e+00 - val_loss: 3.8255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9291e-04 - acc: 0.0000e+00 - val_loss: 3.8149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9607e-04 - acc: 0.0000e+00 - val_loss: 9.4827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0954e-04 - acc: 0.0000e+00 - val_loss: 2.3133e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8128e-04 - acc: 0.0000e+00 - val_loss: 1.9753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8207e-04 - acc: 0.0000e+00 - val_loss: 4.3097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7184e-04 - acc: 0.0000e+00 - val_loss: 2.4755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7364e-04 - acc: 0.0000e+00 - val_loss: 2.9544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7096e-04 - acc: 0.0000e+00 - val_loss: 5.7128e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6964e-04 - acc: 0.0000e+00 - val_loss: 2.1292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7671e-04 - acc: 0.0000e+00 - val_loss: 3.9969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5702e-04 - acc: 0.0000e+00 - val_loss: 5.4666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6992e-04 - acc: 0.0000e+00 - val_loss: 2.9789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6094e-04 - acc: 0.0000e+00 - val_loss: 4.2323e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7045e-04 - acc: 0.0000e+00 - val_loss: 2.1987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5717e-04 - acc: 0.0000e+00 - val_loss: 5.0090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5769e-04 - acc: 0.0000e+00 - val_loss: 2.3909e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5693e-04 - acc: 0.0000e+00 - val_loss: 2.4203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5487e-04 - acc: 0.0000e+00 - val_loss: 2.1495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6468e-04 - acc: 0.0000e+00 - val_loss: 3.7309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5239e-04 - acc: 0.0000e+00 - val_loss: 4.1053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4429e-04 - acc: 0.0000e+00 - val_loss: 2.8143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5112e-04 - acc: 0.0000e+00 - val_loss: 2.2238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5104e-04 - acc: 0.0000e+00 - val_loss: 6.9409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6073e-04 - acc: 0.0000e+00 - val_loss: 2.6559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4011e-04 - acc: 0.0000e+00 - val_loss: 1.9698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4121e-04 - acc: 0.0000e+00 - val_loss: 7.9541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3430e-04 - acc: 0.0000e+00 - val_loss: 1.9281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3912e-04 - acc: 0.0000e+00 - val_loss: 2.1734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2586e-04 - acc: 0.0000e+00 - val_loss: 2.0766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3371e-04 - acc: 0.0000e+00 - val_loss: 2.6869e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3078e-04 - acc: 0.0000e+00 - val_loss: 2.6931e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3657e-04 - acc: 0.0000e+00 - val_loss: 3.4031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3356e-04 - acc: 0.0000e+00 - val_loss: 2.9700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2530e-04 - acc: 0.0000e+00 - val_loss: 6.4052e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3424e-04 - acc: 0.0000e+00 - val_loss: 2.3059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3022e-04 - acc: 0.0000e+00 - val_loss: 1.8061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2594e-04 - acc: 0.0000e+00 - val_loss: 2.8664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1836e-04 - acc: 0.0000e+00 - val_loss: 2.7994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2215e-04 - acc: 0.0000e+00 - val_loss: 4.1451e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2452e-04 - acc: 0.0000e+00 - val_loss: 4.5247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1907e-04 - acc: 0.0000e+00 - val_loss: 3.5772e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2178e-04 - acc: 0.0000e+00 - val_loss: 2.4325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2205e-04 - acc: 0.0000e+00 - val_loss: 1.7202e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3277e-04 - acc: 0.0000e+00 - val_loss: 2.9559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1644e-04 - acc: 0.0000e+00 - val_loss: 1.7751e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1919e-04 - acc: 0.0000e+00 - val_loss: 2.4570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1800e-04 - acc: 0.0000e+00 - val_loss: 2.8960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1036e-04 - acc: 0.0000e+00 - val_loss: 2.1366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2211e-04 - acc: 0.0000e+00 - val_loss: 2.0458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1221e-04 - acc: 0.0000e+00 - val_loss: 2.2724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0279e-04 - acc: 0.0000e+00 - val_loss: 1.8861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0649e-04 - acc: 0.0000e+00 - val_loss: 3.6068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1200e-04 - acc: 0.0000e+00 - val_loss: 2.7149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0834e-04 - acc: 0.0000e+00 - val_loss: 4.6287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3148e-04 - acc: 0.0000e+00 - val_loss: 2.2160e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1892e-04 - acc: 0.0000e+00 - val_loss: 1.8485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0123e-04 - acc: 0.0000e+00 - val_loss: 4.0034e-04 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0113e-04 - acc: 0.0000e+00 - val_loss: 2.7637e-04 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0429e-04 - acc: 0.0000e+00 - val_loss: 1.7193e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1349e-04 - acc: 0.0000e+00 - val_loss: 2.3464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1262e-04 - acc: 0.0000e+00 - val_loss: 1.6379e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1030e-04 - acc: 0.0000e+00 - val_loss: 1.4948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0890e-04 - acc: 0.0000e+00 - val_loss: 1.7867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0323e-04 - acc: 0.0000e+00 - val_loss: 2.7668e-04 - val_acc: 0.0000e+00 ETA: 1s - loss: 1.0399e-04 -\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1591e-04 - acc: 0.0000e+00 - val_loss: 2.7390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0458e-04 - acc: 0.0000e+00 - val_loss: 1.7119e-04 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0202e-04 - acc: 0.0000e+00 - val_loss: 2.5151e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1107e-04 - acc: 0.0000e+00 - val_loss: 2.6078e-04 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2399e-04 - acc: 0.0000e+00 - val_loss: 3.3143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1590e-04 - acc: 0.0000e+00 - val_loss: 1.8577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0652e-04 - acc: 0.0000e+00 - val_loss: 4.1832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0478e-04 - acc: 0.0000e+00 - val_loss: 1.7093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0557e-04 - acc: 0.0000e+00 - val_loss: 1.6134e-04 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0096e-04 - acc: 0.0000e+00 - val_loss: 3.1371e-04 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0885e-04 - acc: 0.0000e+00 - val_loss: 2.5236e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0217e-04 - acc: 0.0000e+00 - val_loss: 2.6262e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0019e-04 - acc: 0.0000e+00 - val_loss: 2.0006e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7932e-05 - acc: 0.0000e+00 - val_loss: 3.8748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0174e-04 - acc: 0.0000e+00 - val_loss: 1.8820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4865e-05 - acc: 0.0000e+00 - val_loss: 2.5676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3420e-05 - acc: 0.0000e+00 - val_loss: 1.6266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0300e-04 - acc: 0.0000e+00 - val_loss: 1.7114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0958e-04 - acc: 0.0000e+00 - val_loss: 2.9933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0269e-04 - acc: 0.0000e+00 - val_loss: 1.4630e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0454e-04 - acc: 0.0000e+00 - val_loss: 3.6714e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0483e-04 - acc: 0.0000e+00 - val_loss: 4.5926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4432e-05 - acc: 0.0000e+00 - val_loss: 1.5934e-04 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2716e-05 - acc: 0.0000e+00 - val_loss: 1.7572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4678e-05 - acc: 0.0000e+00 - val_loss: 2.2130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6648e-05 - acc: 0.0000e+00 - val_loss: 2.2840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0326e-04 - acc: 0.0000e+00 - val_loss: 1.5782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3905e-05 - acc: 0.0000e+00 - val_loss: 1.7204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4373e-05 - acc: 0.0000e+00 - val_loss: 1.7494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6960e-05 - acc: 0.0000e+00 - val_loss: 1.5272e-04 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8571e-05 - acc: 0.0000e+00 - val_loss: 4.9830e-04 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0131e-05 - acc: 0.0000e+00 - val_loss: 2.0329e-04 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1099e-05 - acc: 0.0000e+00 - val_loss: 4.8096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0184e-04 - acc: 0.0000e+00 - val_loss: 2.2018e-04 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9399e-05 - acc: 0.0000e+00 - val_loss: 1.6973e-04 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8588e-05 - acc: 0.0000e+00 - val_loss: 4.8580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2787e-05 - acc: 0.0000e+00 - val_loss: 1.9445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9057e-05 - acc: 0.0000e+00 - val_loss: 1.9007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3715e-05 - acc: 0.0000e+00 - val_loss: 5.7164e-04 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7711e-05 - acc: 0.0000e+00 - val_loss: 2.9675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9916e-05 - acc: 0.0000e+00 - val_loss: 1.4352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2860e-05 - acc: 0.0000e+00 - val_loss: 1.8121e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2551e-05 - acc: 0.0000e+00 - val_loss: 5.3585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0055e-04 - acc: 0.0000e+00 - val_loss: 2.9006e-04 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0379e-04 - acc: 0.0000e+00 - val_loss: 4.6684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1671e-05 - acc: 0.0000e+00 - val_loss: 1.7542e-04 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0315e-05 - acc: 0.0000e+00 - val_loss: 1.7235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0181e-05 - acc: 0.0000e+00 - val_loss: 1.9466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7080e-05 - acc: 0.0000e+00 - val_loss: 1.6134e-04 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8794e-05 - acc: 0.0000e+00 - val_loss: 1.9032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6255e-05 - acc: 0.0000e+00 - val_loss: 1.8715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5782e-05 - acc: 0.0000e+00 - val_loss: 1.8604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1113e-05 - acc: 0.0000e+00 - val_loss: 2.5892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7331e-05 - acc: 0.0000e+00 - val_loss: 2.1153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6033e-05 - acc: 0.0000e+00 - val_loss: 2.3757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 2s - loss: 8.4232e-05 - acc: 0.0000e+00 - val_loss: 1.7204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0269e-04 - acc: 0.0000e+00 - val_loss: 1.7793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7834e-05 - acc: 0.0000e+00 - val_loss: 3.6255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 2s - loss: 8.4666e-05 - acc: 0.0000e+00 - val_loss: 2.3223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2703e-05 - acc: 0.0000e+00 - val_loss: 1.6357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7699e-05 - acc: 0.0000e+00 - val_loss: 2.1625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1496e-05 - acc: 0.0000e+00 - val_loss: 2.6867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 2s - loss: 8.7221e-05 - acc: 0.0000e+00 - val_loss: 2.0651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6792e-05 - acc: 0.0000e+00 - val_loss: 4.4673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2993e-05 - acc: 0.0000e+00 - val_loss: 1.7104e-04 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6934e-05 - acc: 0.0000e+00 - val_loss: 3.8071e-04 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3658e-05 - acc: 0.0000e+00 - val_loss: 1.7402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1573e-05 - acc: 0.0000e+00 - val_loss: 4.2781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8046e-05 - acc: 0.0000e+00 - val_loss: 4.0356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3971e-05 - acc: 0.0000e+00 - val_loss: 1.5127e-04 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 2s - loss: 8.3811e-05 - acc: 0.0000e+00 - val_loss: 2.4027e-04 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 2s - loss: 7.8286e-05 - acc: 0.0000e+00 - val_loss: 1.4240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3377e-05 - acc: 0.0000e+00 - val_loss: 2.4492e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0844e-05 - acc: 0.0000e+00 - val_loss: 2.9170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0601e-05 - acc: 0.0000e+00 - val_loss: 1.8117e-04 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1868e-05 - acc: 0.0000e+00 - val_loss: 2.0404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9355e-05 - acc: 0.0000e+00 - val_loss: 4.4221e-04 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2885e-05 - acc: 0.0000e+00 - val_loss: 2.8940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3434e-05 - acc: 0.0000e+00 - val_loss: 2.6970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7613e-05 - acc: 0.0000e+00 - val_loss: 1.3819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6766e-05 - acc: 0.0000e+00 - val_loss: 1.5381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5138e-05 - acc: 0.0000e+00 - val_loss: 3.1679e-04 - val_acc: 0.0000e+00 - ETA: 0s - loss: 8.8950e-05 - acc\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7643e-05 - acc: 0.0000e+00 - val_loss: 2.2191e-04 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8531e-05 - acc: 0.0000e+00 - val_loss: 1.5878e-04 - val_acc: 0.0000e+000\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6755e-05 - acc: 0.0000e+00 - val_loss: 2.0950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3127e-05 - acc: 0.0000e+00 - val_loss: 2.1628e-04 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8357e-05 - acc: 0.0000e+00 - val_loss: 2.2033e-04 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9893e-05 - acc: 0.0000e+00 - val_loss: 1.6198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1980e-05 - acc: 0.0000e+00 - val_loss: 1.4816e-04 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4150e-05 - acc: 0.0000e+00 - val_loss: 2.9659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6184e-05 - acc: 0.0000e+00 - val_loss: 1.8203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0429e-05 - acc: 0.0000e+00 - val_loss: 1.9676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8432e-05 - acc: 0.0000e+00 - val_loss: 1.7621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2099e-05 - acc: 0.0000e+00 - val_loss: 2.0047e-04 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0038e-05 - acc: 0.0000e+00 - val_loss: 2.5995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9615e-05 - acc: 0.0000e+00 - val_loss: 2.1900e-04 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0319e-05 - acc: 0.0000e+00 - val_loss: 3.1494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2696e-05 - acc: 0.0000e+00 - val_loss: 1.9053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0010e-05 - acc: 0.0000e+00 - val_loss: 3.1766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7783e-05 - acc: 0.0000e+00 - val_loss: 1.7325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2373e-05 - acc: 0.0000e+00 - val_loss: 2.7009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1575e-05 - acc: 0.0000e+00 - val_loss: 3.0607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4362e-05 - acc: 0.0000e+00 - val_loss: 1.9781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6505e-05 - acc: 0.0000e+00 - val_loss: 2.0563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1572e-05 - acc: 0.0000e+00 - val_loss: 1.5519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4095e-05 - acc: 0.0000e+00 - val_loss: 1.4218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9674e-05 - acc: 0.0000e+00 - val_loss: 2.3033e-04 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8890e-05 - acc: 0.0000e+00 - val_loss: 1.2473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4772e-05 - acc: 0.0000e+00 - val_loss: 1.8648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2462e-05 - acc: 0.0000e+00 - val_loss: 1.5368e-04 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7712e-05 - acc: 0.0000e+00 - val_loss: 1.7582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.9960e-05 - acc: 0.0000e+00 - val_loss: 1.5407e-04 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 2s - loss: 7.3900e-05 - acc: 0.0000e+00 - val_loss: 2.4410e-04 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6905e-05 - acc: 0.0000e+00 - val_loss: 1.4138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3777e-05 - acc: 0.0000e+00 - val_loss: 1.9402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8529e-05 - acc: 0.0000e+00 - val_loss: 7.9249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0925e-04 - acc: 0.0000e+00 - val_loss: 1.5116e-04 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4016e-05 - acc: 0.0000e+00 - val_loss: 1.7025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6481e-05 - acc: 0.0000e+00 - val_loss: 4.6258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5338e-05 - acc: 0.0000e+00 - val_loss: 1.4189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5524e-05 - acc: 0.0000e+00 - val_loss: 3.5414e-04 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8513e-05 - acc: 0.0000e+00 - val_loss: 1.9358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5735e-05 - acc: 0.0000e+00 - val_loss: 1.6353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2876e-05 - acc: 0.0000e+00 - val_loss: 1.9740e-04 - val_acc: 0.0000e+0000\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4172e-05 - acc: 0.0000e+00 - val_loss: 2.1658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9871e-05 - acc: 0.0000e+00 - val_loss: 1.4538e-04 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4806e-05 - acc: 0.0000e+00 - val_loss: 3.2176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1779e-05 - acc: 0.0000e+00 - val_loss: 2.0520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3932e-05 - acc: 0.0000e+00 - val_loss: 1.8269e-04 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0548e-05 - acc: 0.0000e+00 - val_loss: 1.4994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6985e-05 - acc: 0.0000e+00 - val_loss: 2.8457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2628e-05 - acc: 0.0000e+00 - val_loss: 2.2156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1611e-05 - acc: 0.0000e+00 - val_loss: 1.6893e-04 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4260e-05 - acc: 0.0000e+00 - val_loss: 2.5932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7109e-05 - acc: 0.0000e+00 - val_loss: 3.8726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1603e-05 - acc: 0.0000e+00 - val_loss: 1.8377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4708e-05 - acc: 0.0000e+00 - val_loss: 1.4539e-04 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3872e-05 - acc: 0.0000e+00 - val_loss: 1.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2336e-05 - acc: 0.0000e+00 - val_loss: 3.3052e-04 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9134e-05 - acc: 0.0000e+00 - val_loss: 1.7232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8414e-05 - acc: 0.0000e+00 - val_loss: 5.2960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3652e-05 - acc: 0.0000e+00 - val_loss: 7.1981e-04 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8544e-05 - acc: 0.0000e+00 - val_loss: 1.9537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2959e-05 - acc: 0.0000e+00 - val_loss: 3.6408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6126e-05 - acc: 0.0000e+00 - val_loss: 2.6155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7503e-05 - acc: 0.0000e+00 - val_loss: 1.8498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1506e-05 - acc: 0.0000e+00 - val_loss: 1.9209e-04 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8756e-05 - acc: 0.0000e+00 - val_loss: 2.7393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1139e-05 - acc: 0.0000e+00 - val_loss: 4.4331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7433e-05 - acc: 0.0000e+00 - val_loss: 1.9213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3941e-05 - acc: 0.0000e+00 - val_loss: 1.5579e-04 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4482e-05 - acc: 0.0000e+00 - val_loss: 4.4241e-04 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0298e-05 - acc: 0.0000e+00 - val_loss: 2.7617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6966e-05 - acc: 0.0000e+00 - val_loss: 2.7828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5900e-05 - acc: 0.0000e+00 - val_loss: 1.7344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3079e-05 - acc: 0.0000e+00 - val_loss: 4.6354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1835e-05 - acc: 0.0000e+00 - val_loss: 2.8672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4642e-05 - acc: 0.0000e+00 - val_loss: 3.2372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4722e-05 - acc: 0.0000e+00 - val_loss: 6.5295e-04 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5105e-05 - acc: 0.0000e+00 - val_loss: 1.8325e-04 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1055e-05 - acc: 0.0000e+00 - val_loss: 2.6456e-04 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7923e-05 - acc: 0.0000e+00 - val_loss: 2.3129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9181e-05 - acc: 0.0000e+00 - val_loss: 2.7518e-04 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3365e-05 - acc: 0.0000e+00 - val_loss: 3.3132e-04 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9777e-05 - acc: 0.0000e+00 - val_loss: 1.6098e-04 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0377e-05 - acc: 0.0000e+00 - val_loss: 2.4420e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4858e-05 - acc: 0.0000e+00 - val_loss: 1.4363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0115e-05 - acc: 0.0000e+00 - val_loss: 2.0925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.1130e-05 - acc: 0.0000e+00 - val_loss: 1.2054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5693e-05 - acc: 0.0000e+00 - val_loss: 2.3336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.7777e-05 - acc: 0.0000e+00 - val_loss: 1.7634e-04 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8940e-05 - acc: 0.0000e+00 - val_loss: 2.9703e-04 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.2386e-05 - acc: 0.0000e+00 - val_loss: 1.3204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9240e-05 - acc: 0.0000e+00 - val_loss: 3.1336e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0363e-05 - acc: 0.0000e+00 - val_loss: 2.3485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8012e-05 - acc: 0.0000e+00 - val_loss: 3.1219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6163e-05 - acc: 0.0000e+00 - val_loss: 3.6892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3121e-05 - acc: 0.0000e+00 - val_loss: 4.4599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0318e-05 - acc: 0.0000e+00 - val_loss: 2.9425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0926e-05 - acc: 0.0000e+00 - val_loss: 7.8019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0558e-05 - acc: 0.0000e+00 - val_loss: 2.0309e-04 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9708e-05 - acc: 0.0000e+00 - val_loss: 2.5192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.5409e-05 - acc: 0.0000e+00 - val_loss: 3.6990e-04 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3968e-05 - acc: 0.0000e+00 - val_loss: 1.5363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8142e-05 - acc: 0.0000e+00 - val_loss: 1.5397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3668e-05 - acc: 0.0000e+00 - val_loss: 1.4684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0757e-05 - acc: 0.0000e+00 - val_loss: 2.9196e-04 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2730e-05 - acc: 0.0000e+00 - val_loss: 2.6135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6917e-05 - acc: 0.0000e+00 - val_loss: 6.9356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6131e-05 - acc: 0.0000e+00 - val_loss: 3.0078e-04 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6266e-05 - acc: 0.0000e+00 - val_loss: 3.5602e-04 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3080e-05 - acc: 0.0000e+00 - val_loss: 4.2830e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00008 MSE (0.01 RMSE)\n",
      "Test Score: 0.03805 MSE (0.20 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 3s - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8205e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0464e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0607e-04 - acc: 0.0000e+00 - val_loss: 3.5865e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4529e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6446e-04 - acc: 0.0000e+00 - val_loss: 4.7940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.0687e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.8588e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.2296e-04 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3806e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.0633e-04 - acc: 0.0000e+00 - val_loss: 2.8050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5517e-04 - acc: 0.0000e+00 - val_loss: 2.7580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9202e-04 - acc: 0.0000e+00 - val_loss: 3.9986e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.6628e-04 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.9721e-04 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5008e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1979e-04 - acc: 0.0000e+00 - val_loss: 3.8112e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9234e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.7317e-04 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6351e-04 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8662e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.5858e-04 - acc: 0.0000e+00 - val_loss: 9.9145e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1628e-04 - acc: 0.0000e+00 - val_loss: 3.7363e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.0881e-04 - acc: 0.0000e+00 - val_loss: 7.8377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9096e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.2150e-04 - acc: 0.0000e+00 - val_loss: 8.9764e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8239e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7979e-04 - acc: 0.0000e+00 - val_loss: 3.0652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.4510e-04 - acc: 0.0000e+00 - val_loss: 2.9828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5371e-04 - acc: 0.0000e+00 - val_loss: 2.3553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.2689e-04 - acc: 0.0000e+00 - val_loss: 2.5611e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3701e-04 - acc: 0.0000e+00 - val_loss: 2.6443e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0594e-04 - acc: 0.0000e+00 - val_loss: 7.7305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9524e-04 - acc: 0.0000e+00 - val_loss: 4.0189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1088e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7307e-04 - acc: 0.0000e+00 - val_loss: 2.8868e-04 - val_acc: 0.0000e+0000e\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7804e-04 - acc: 0.0000e+00 - val_loss: 2.8125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6431e-04 - acc: 0.0000e+00 - val_loss: 4.4726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4018e-04 - acc: 0.0000e+00 - val_loss: 2.6722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.6175e-04 - acc: 0.0000e+00 - val_loss: 5.7507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3272e-04 - acc: 0.0000e+00 - val_loss: 8.0673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3516e-04 - acc: 0.0000e+00 - val_loss: 4.6058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2931e-04 - acc: 0.0000e+00 - val_loss: 3.1342e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5078e-04 - acc: 0.0000e+00 - val_loss: 8.1869e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5140e-04 - acc: 0.0000e+00 - val_loss: 5.7557e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2200e-04 - acc: 0.0000e+00 - val_loss: 4.8446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3785e-04 - acc: 0.0000e+00 - val_loss: 5.3462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2596e-04 - acc: 0.0000e+00 - val_loss: 3.3617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9799e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9827e-04 - acc: 0.0000e+00 - val_loss: 5.7664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8755e-04 - acc: 0.0000e+00 - val_loss: 3.6004e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9766e-04 - acc: 0.0000e+00 - val_loss: 2.9210e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9642e-04 - acc: 0.0000e+00 - val_loss: 3.9535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1163e-04 - acc: 0.0000e+00 - val_loss: 4.8770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8221e-04 - acc: 0.0000e+00 - val_loss: 3.6152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7873e-04 - acc: 0.0000e+00 - val_loss: 3.9166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7510e-04 - acc: 0.0000e+00 - val_loss: 3.8632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7604e-04 - acc: 0.0000e+00 - val_loss: 4.3733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8173e-04 - acc: 0.0000e+00 - val_loss: 6.8579e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8676e-04 - acc: 0.0000e+00 - val_loss: 8.9812e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8157e-04 - acc: 0.0000e+00 - val_loss: 3.0229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7360e-04 - acc: 0.0000e+00 - val_loss: 7.4918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6384e-04 - acc: 0.0000e+00 - val_loss: 7.8085e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6542e-04 - acc: 0.0000e+00 - val_loss: 3.3013e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7062e-04 - acc: 0.0000e+00 - val_loss: 4.4724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6574e-04 - acc: 0.0000e+00 - val_loss: 5.9483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5794e-04 - acc: 0.0000e+00 - val_loss: 6.8203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5336e-04 - acc: 0.0000e+00 - val_loss: 6.0593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5521e-04 - acc: 0.0000e+00 - val_loss: 5.1038e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5413e-04 - acc: 0.0000e+00 - val_loss: 6.2599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6657e-04 - acc: 0.0000e+00 - val_loss: 3.1592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6380e-04 - acc: 0.0000e+00 - val_loss: 2.7866e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5932e-04 - acc: 0.0000e+00 - val_loss: 3.1835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5005e-04 - acc: 0.0000e+00 - val_loss: 4.3268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4746e-04 - acc: 0.0000e+00 - val_loss: 7.5370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5394e-04 - acc: 0.0000e+00 - val_loss: 3.2292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5239e-04 - acc: 0.0000e+00 - val_loss: 5.2693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5191e-04 - acc: 0.0000e+00 - val_loss: 9.4634e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5957e-04 - acc: 0.0000e+00 - val_loss: 6.2523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4833e-04 - acc: 0.0000e+00 - val_loss: 8.2942e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4711e-04 - acc: 0.0000e+00 - val_loss: 9.1043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4169e-04 - acc: 0.0000e+00 - val_loss: 5.8362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4260e-04 - acc: 0.0000e+00 - val_loss: 9.9053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3548e-04 - acc: 0.0000e+00 - val_loss: 8.2100e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3962e-04 - acc: 0.0000e+00 - val_loss: 3.3916e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4152e-04 - acc: 0.0000e+00 - val_loss: 4.3366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3337e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3334e-04 - acc: 0.0000e+00 - val_loss: 6.9874e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4250e-04 - acc: 0.0000e+00 - val_loss: 8.5213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3242e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2681e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2801e-04 - acc: 0.0000e+00 - val_loss: 7.6735e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3938e-04 - acc: 0.0000e+00 - val_loss: 5.2901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3808e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4154e-04 - acc: 0.0000e+00 - val_loss: 9.8377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3216e-04 - acc: 0.0000e+00 - val_loss: 9.2387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3907e-04 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5309e-04 - acc: 0.0000e+00 - val_loss: 8.1559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2758e-04 - acc: 0.0000e+00 - val_loss: 5.3400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3170e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2112e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2947e-04 - acc: 0.0000e+00 - val_loss: 8.5040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3201e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2085e-04 - acc: 0.0000e+00 - val_loss: 9.3465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2332e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1724e-04 - acc: 0.0000e+00 - val_loss: 7.0489e-04 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2396e-04 - acc: 0.0000e+00 - val_loss: 9.8016e-04 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2234e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1883e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+000.000\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2514e-04 - acc: 0.0000e+00 - val_loss: 7.8593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2188e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 2s - loss: 1.3652e-04 - acc: 0.0000e+00 - val_loss: 6.2520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1921e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+000.\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1932e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2542e-04 - acc: 0.0000e+00 - val_loss: 6.3308e-04 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 2s - loss: 1.4133e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3027e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1767e-04 - acc: 0.0000e+00 - val_loss: 6.0836e-04 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1301e-04 - acc: 0.0000e+00 - val_loss: 7.9080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 2s - loss: 1.0753e-04 - acc: 0.0000e+00 - val_loss: 9.8405e-04 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1788e-04 - acc: 0.0000e+00 - val_loss: 3.8826e-04 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2423e-04 - acc: 0.0000e+00 - val_loss: 9.6733e-04 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2056e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+000\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1005e-04 - acc: 0.0000e+00 - val_loss: 6.2626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1821e-04 - acc: 0.0000e+00 - val_loss: 4.8729e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1375e-04 - acc: 0.0000e+00 - val_loss: 9.9913e-04 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1242e-04 - acc: 0.0000e+00 - val_loss: 6.5294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3210e-04 - acc: 0.0000e+00 - val_loss: 5.4471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1742e-04 - acc: 0.0000e+00 - val_loss: 9.6405e-04 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1917e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1449e-04 - acc: 0.0000e+00 - val_loss: 9.2000e-04 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0865e-04 - acc: 0.0000e+00 - val_loss: 8.0901e-04 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0866e-04 - acc: 0.0000e+00 - val_loss: 9.9810e-04 - val_acc: 0.0000e+0000e - ETA: 1s - loss: 1.0834e-04 - - ETA: 0s - loss: 1.0946e-04 - acc: 0.0000e+0\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1446e-04 - acc: 0.0000e+00 - val_loss: 8.6315e-04 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0892e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1534e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1257e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1944e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1707e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1846e-04 - acc: 0.0000e+00 - val_loss: 5.2556e-04 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1968e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0702e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0427e-04 - acc: 0.0000e+00 - val_loss: 9.3992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0374e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0725e-04 - acc: 0.0000e+00 - val_loss: 8.9807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0906e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1253e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0869e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1532e-04 - acc: 0.0000e+00 - val_loss: 8.7471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1143e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1022e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0660e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2214e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0754e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1264e-04 - acc: 0.0000e+00 - val_loss: 8.8631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1225e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1725e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0691e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0652e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0658e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0331e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1288e-04 - acc: 0.0000e+00 - val_loss: 8.6782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0991e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0435e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0656e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1167e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0109e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0841e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1717e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2765e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0331e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0610e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8750e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+000.0000e+ - ETA: 0s - loss: 9.3632e-05 - a\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9783e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0282e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0446e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0175e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0271e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0110e-04 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6696e-05 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7067e-05 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0208e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0890e-04 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0187e-04 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1207e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1059e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0803e-04 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0134e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+000.000\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0001e-04 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8220e-05 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8360e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0382e-04 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5931e-05 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0139e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8990e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5385e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0146e-04 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0006e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3053e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8905e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0692e-04 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4885e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8841e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0503e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4537e-05 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0402e-04 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5872e-05 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4978e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3475e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6428e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7085e-05 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7078e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0278e-05 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5531e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.9501e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.8626e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1751e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6242e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2380e-05 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3692e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3870e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0095e-04 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6934e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0423e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0342e-04 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5432e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6888e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2719e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3481e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2623e-05 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7488e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+000.\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2512e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+000.0000\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4039e-05 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6827e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0347e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+000.0000\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8818e-05 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0575e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8994e-05 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+000.0000e+\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4951e-05 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1674e-05 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6254e-05 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8824e-05 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2132e-05 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.5474e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+000.000\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7269e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5431e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5194e-05 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4119e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4622e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7818e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.4167e-05 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.1000e-05 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3134e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3929e-05 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7647e-05 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7625e-05 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+000\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3267e-05 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0942e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3551e-05 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0067e-05 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.8477e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.2520e-05 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5144e-05 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4355e-05 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0969e-05 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1810e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1823e-05 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1051e-05 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00s - loss: 7.9135e-05 - acc: 0.000\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4315e-05 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6115e-05 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7298e-05 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1670e-05 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3702e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.7613e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+000.\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6305e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8780e-05 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3515e-05 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.5842e-05 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8655e-05 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.1377e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+000.0000e+0\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9263e-05 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.3323e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8771e-05 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4792e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0443e-05 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4249e-05 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2886e-05 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.4691e-05 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0465e-05 - acc: 0.0000e+00 - val_loss: 0.0058 - val_acc: 0.0000e+000.000\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8374e-05 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.0230e-05 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.0778e-05 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+000.000\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.8689e-05 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4792e-05 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.2182e-05 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7594e-05 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9138e-05 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6621e-05 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.7939e-05 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00119 MSE (0.03 RMSE)\n",
      "Test Score: 0.06796 MSE (0.26 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/300\n",
      "13702/13702 [==============================] - 4s - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 6.5230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 4.9021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 9.8289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.6046e-04 - acc: 0.0000e+00 - val_loss: 3.3653e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "13702/13702 [==============================] - 1s - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.7068e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "13702/13702 [==============================] - 1s - loss: 9.3338e-04 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.5037e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6161e-04 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "13702/13702 [==============================] - 1s - loss: 8.6060e-04 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+000.0000e+\n",
      "Epoch 14/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.9179e-04 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+000.000\n",
      "Epoch 15/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6830e-04 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.4102e-04 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.6332e-04 - acc: 0.0000e+00 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "13702/13702 [==============================] - 1s - loss: 7.3765e-04 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6167e-04 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6200e-04 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.6812e-04 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.4723e-04 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9521e-04 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "13702/13702 [==============================] - 1s - loss: 6.3330e-04 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.9014e-04 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8288e-04 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.8344e-04 - acc: 0.0000e+00 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.5036e-04 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "13702/13702 [==============================] - 1s - loss: 5.1867e-04 - acc: 0.0000e+00 - val_loss: 0.0067 - val_acc: 0.0000e+000.0000\n",
      "Epoch 30/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9795e-04 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.9341e-04 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.8631e-04 - acc: 0.0000e+00 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6503e-04 - acc: 0.0000e+00 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6121e-04 - acc: 0.0000e+00 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.1851e-04 - acc: 0.0000e+00 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "13702/13702 [==============================] - 1s - loss: 4.6903e-04 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.8107e-04 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.9109e-04 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.7466e-04 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.5747e-04 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3411e-04 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.0964e-04 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.3134e-04 - acc: 0.0000e+00 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "13702/13702 [==============================] - 1s - loss: 3.1705e-04 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8323e-04 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8594e-04 - acc: 0.0000e+00 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7427e-04 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.8688e-04 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+000.000\n",
      "Epoch 49/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.7037e-04 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.9036e-04 - acc: 0.0000e+00 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5137e-04 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2770e-04 - acc: 0.0000e+00 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5440e-04 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3051e-04 - acc: 0.0000e+00 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.5118e-04 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3575e-04 - acc: 0.0000e+00 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2918e-04 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.4577e-04 - acc: 0.0000e+00 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2373e-04 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1266e-04 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1133e-04 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.3447e-04 - acc: 0.0000e+00 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2961e-04 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0946e-04 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1914e-04 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.1934e-04 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0701e-04 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9894e-04 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9843e-04 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0821e-04 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0083e-04 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9968e-04 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9959e-04 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9667e-04 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+000.0000e+\n",
      "Epoch 75/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2525e-04 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9806e-04 - acc: 0.0000e+00 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9375e-04 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0027e-04 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9015e-04 - acc: 0.0000e+00 - val_loss: 0.0133 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.0844e-04 - acc: 0.0000e+00 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8935e-04 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8755e-04 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+000.0000e+0\n",
      "Epoch 83/300\n",
      "13702/13702 [==============================] - 1s - loss: 2.2090e-04 - acc: 0.0000e+00 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9312e-04 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7749e-04 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8486e-04 - acc: 0.0000e+00 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8044e-04 - acc: 0.0000e+00 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7809e-04 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7205e-04 - acc: 0.0000e+00 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8813e-04 - acc: 0.0000e+00 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7716e-04 - acc: 0.0000e+00 - val_loss: 0.0155 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.8283e-04 - acc: 0.0000e+00 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7787e-04 - acc: 0.0000e+00 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7191e-04 - acc: 0.0000e+00 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7666e-04 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.9055e-04 - acc: 0.0000e+00 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7386e-04 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7108e-04 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7312e-04 - acc: 0.0000e+00 - val_loss: 0.0162 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7301e-04 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6941e-04 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7502e-04 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6959e-04 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6169e-04 - acc: 0.0000e+00 - val_loss: 0.0175 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5937e-04 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6408e-04 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7346e-04 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7607e-04 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6748e-04 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6552e-04 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6837e-04 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6661e-04 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.7291e-04 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5704e-04 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5654e-04 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5805e-04 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6865e-04 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6981e-04 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5490e-04 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6080e-04 - acc: 0.0000e+00 - val_loss: 0.0234 - val_acc: 0.0000e+000.000\n",
      "Epoch 121/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5785e-04 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6486e-04 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4897e-04 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4837e-04 - acc: 0.0000e+00 - val_loss: 0.0236 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6152e-04 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5313e-04 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5579e-04 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5161e-04 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4936e-04 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4931e-04 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5253e-04 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4954e-04 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5850e-04 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6176e-04 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4731e-04 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4503e-04 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+000.000\n",
      "Epoch 137/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4453e-04 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5217e-04 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6020e-04 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5872e-04 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5016e-04 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5569e-04 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6434e-04 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6999e-04 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4926e-04 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5920e-04 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4636e-04 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5600e-04 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6747e-04 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5907e-04 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4717e-04 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4868e-04 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4513e-04 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5364e-04 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4171e-04 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4190e-04 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5245e-04 - acc: 0.0000e+00 - val_loss: 0.0319 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5031e-04 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3929e-04 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4962e-04 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5208e-04 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4527e-04 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5024e-04 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4392e-04 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3748e-04 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4036e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4800e-04 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5110e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5115e-04 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4514e-04 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5196e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4729e-04 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4233e-04 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4182e-04 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.6596e-04 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4592e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4454e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4870e-04 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3853e-04 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4586e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4767e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3342e-04 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3567e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3284e-04 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3521e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4062e-04 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3751e-04 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4756e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4612e-04 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4534e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3642e-04 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3641e-04 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4635e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.5511e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3058e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3434e-04 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3567e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3670e-04 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4268e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3357e-04 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2925e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3948e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3250e-04 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2650e-04 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2902e-04 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3395e-04 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3032e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3161e-04 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3280e-04 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2652e-04 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2995e-04 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3373e-04 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2913e-04 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2724e-04 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3273e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2514e-04 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2304e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2463e-04 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2767e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3333e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2127e-04 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3149e-04 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3118e-04 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3272e-04 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2200e-04 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2153e-04 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3019e-04 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3147e-04 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2180e-04 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2825e-04 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2662e-04 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1807e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3371e-04 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2195e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1892e-04 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.4038e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3148e-04 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1812e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2764e-04 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2171e-04 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2066e-04 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1932e-04 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3358e-04 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3335e-04 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2209e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2205e-04 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1827e-04 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2181e-04 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1912e-04 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2018e-04 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3371e-04 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2450e-04 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2947e-04 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2153e-04 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2082e-04 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1632e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2359e-04 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1809e-04 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1676e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1919e-04 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1845e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1971e-04 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2047e-04 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2095e-04 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2234e-04 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2183e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2994e-04 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1891e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2397e-04 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2183e-04 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3585e-04 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2164e-04 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1416e-04 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1925e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2074e-04 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1966e-04 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1957e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2117e-04 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1540e-04 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1603e-04 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1518e-04 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1142e-04 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.3169e-04 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1358e-04 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1650e-04 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1636e-04 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.2818e-04 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1816e-04 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0846e-04 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1562e-04 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1277e-04 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1469e-04 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1035e-04 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1818e-04 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1572e-04 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1498e-04 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1335e-04 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0915e-04 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.0312e-04 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "13702/13702 [==============================] - 1s - loss: 1.1049e-04 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00651 MSE (0.08 RMSE)\n",
      "Test Score: 0.15820 MSE (0.40 RMSE)\n"
     ]
    }
   ],
   "source": [
    "dlist = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "neurons_LSTM = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "dropout_result = {}\n",
    "\n",
    "for d in dlist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "    dropout_result[d] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.2: 9.0012162654516434e-05, 0.3: 0.0022254438251234927, 0.8: 0.15819754752706974, 0.5: 0.01902325010867283, 0.7: 0.067955376763099332, 0.4: 0.01020233225110141, 0.6: 0.038046965636445065}\n",
      "[0.2]\n"
     ]
    }
   ],
   "source": [
    "min_val = min(dropout_result.values())\n",
    "min_val_key = [k for k, v in dropout_result.items() if v == min_val]\n",
    "print (dropout_result)\n",
    "print (min_val_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYZiZWS5OGGZmlosThpmZ5eKEYWZmufx/Q4p/4M9qMKYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2dec19908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(dropout_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.2 Optimial epochs value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochslist = [10,20,30,40,50,60,70,80,90,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/10\n",
      "13702/13702 [==============================] - 3s - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "13702/13702 [==============================] - 1s - loss: 6.0977e-04 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "13702/13702 [==============================] - 1s - loss: 2.5514e-04 - acc: 0.0000e+00 - val_loss: 5.4461e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.7068e-04 - acc: 0.0000e+00 - val_loss: 3.1617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.3632e-04 - acc: 0.0000e+00 - val_loss: 2.5412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.4826e-04 - acc: 0.0000e+00 - val_loss: 3.8467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.5060e-04 - acc: 0.0000e+00 - val_loss: 2.4584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.3162e-04 - acc: 0.0000e+00 - val_loss: 4.6549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.2821e-04 - acc: 0.0000e+00 - val_loss: 2.3023e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "13702/13702 [==============================] - 1s - loss: 1.1644e-04 - acc: 0.0000e+00 - val_loss: 2.2494e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00688 MSE (0.08 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/20\n",
      "13702/13702 [==============================] - 3s - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "13702/13702 [==============================] - 1s - loss: 5.7648e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "13702/13702 [==============================] - 1s - loss: 2.3047e-04 - acc: 0.0000e+00 - val_loss: 4.4981e-04 - val_acc: 0.0000e+000\n",
      "Epoch 4/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.4836e-04 - acc: 0.0000e+00 - val_loss: 3.9520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.4473e-04 - acc: 0.0000e+00 - val_loss: 2.7514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3865e-04 - acc: 0.0000e+00 - val_loss: 2.5957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3782e-04 - acc: 0.0000e+00 - val_loss: 2.3727e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3275e-04 - acc: 0.0000e+00 - val_loss: 2.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3449e-04 - acc: 0.0000e+00 - val_loss: 2.6785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2307e-04 - acc: 0.0000e+00 - val_loss: 2.4295e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2362e-04 - acc: 0.0000e+00 - val_loss: 2.2618e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.3013e-04 - acc: 0.0000e+00 - val_loss: 3.5044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2809e-04 - acc: 0.0000e+00 - val_loss: 2.9878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2076e-04 - acc: 0.0000e+00 - val_loss: 2.2057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.2301e-04 - acc: 0.0000e+00 - val_loss: 2.4244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.0470e-04 - acc: 0.0000e+00 - val_loss: 2.4535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.1185e-04 - acc: 0.0000e+00 - val_loss: 2.7684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.1273e-04 - acc: 0.0000e+00 - val_loss: 2.0549e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.0107e-04 - acc: 0.0000e+00 - val_loss: 2.0827e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "13702/13702 [==============================] - 1s - loss: 1.1576e-04 - acc: 0.0000e+00 - val_loss: 1.9721e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00399 MSE (0.06 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/30\n",
      "13702/13702 [==============================] - 3s - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "13702/13702 [==============================] - 1s - loss: 7.0148e-04 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "13702/13702 [==============================] - 1s - loss: 2.9509e-04 - acc: 0.0000e+00 - val_loss: 6.0482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.7697e-04 - acc: 0.0000e+00 - val_loss: 3.1067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.5215e-04 - acc: 0.0000e+00 - val_loss: 4.4219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.4073e-04 - acc: 0.0000e+00 - val_loss: 2.6874e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.3135e-04 - acc: 0.0000e+00 - val_loss: 2.7715e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.3380e-04 - acc: 0.0000e+00 - val_loss: 2.3787e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2737e-04 - acc: 0.0000e+00 - val_loss: 2.4054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2328e-04 - acc: 0.0000e+00 - val_loss: 2.3832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2693e-04 - acc: 0.0000e+00 - val_loss: 2.9406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1905e-04 - acc: 0.0000e+00 - val_loss: 2.9851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1706e-04 - acc: 0.0000e+00 - val_loss: 3.2124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2192e-04 - acc: 0.0000e+00 - val_loss: 2.5944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2931e-04 - acc: 0.0000e+00 - val_loss: 2.6223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1747e-04 - acc: 0.0000e+00 - val_loss: 2.4936e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0972e-04 - acc: 0.0000e+00 - val_loss: 2.3647e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0306e-04 - acc: 0.0000e+00 - val_loss: 2.2543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1887e-04 - acc: 0.0000e+00 - val_loss: 2.0989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0859e-04 - acc: 0.0000e+00 - val_loss: 3.8667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1471e-04 - acc: 0.0000e+00 - val_loss: 3.6375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.2573e-04 - acc: 0.0000e+00 - val_loss: 2.6742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1244e-04 - acc: 0.0000e+00 - val_loss: 2.6535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0619e-04 - acc: 0.0000e+00 - val_loss: 2.1584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1700e-04 - acc: 0.0000e+00 - val_loss: 2.0474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0436e-04 - acc: 0.0000e+00 - val_loss: 2.3404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0469e-04 - acc: 0.0000e+00 - val_loss: 2.2938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0402e-04 - acc: 0.0000e+00 - val_loss: 2.4717e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.1419e-04 - acc: 0.0000e+00 - val_loss: 1.8406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/30\n",
      "13702/13702 [==============================] - 1s - loss: 1.0101e-04 - acc: 0.0000e+00 - val_loss: 2.2434e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00248 MSE (0.05 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/40\n",
      "13702/13702 [==============================] - 3s - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "13702/13702 [==============================] - 1s - loss: 7.2688e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "13702/13702 [==============================] - 1s - loss: 2.6004e-04 - acc: 0.0000e+00 - val_loss: 6.3789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.6260e-04 - acc: 0.0000e+00 - val_loss: 3.7565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.5108e-04 - acc: 0.0000e+00 - val_loss: 3.0041e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.4047e-04 - acc: 0.0000e+00 - val_loss: 2.4641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3508e-04 - acc: 0.0000e+00 - val_loss: 2.3550e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3071e-04 - acc: 0.0000e+00 - val_loss: 2.3340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.2566e-04 - acc: 0.0000e+00 - val_loss: 4.3926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3430e-04 - acc: 0.0000e+00 - val_loss: 4.6782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3022e-04 - acc: 0.0000e+00 - val_loss: 3.2948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3279e-04 - acc: 0.0000e+00 - val_loss: 4.6956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.2543e-04 - acc: 0.0000e+00 - val_loss: 2.7856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.2903e-04 - acc: 0.0000e+00 - val_loss: 3.0534e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1479e-04 - acc: 0.0000e+00 - val_loss: 2.4125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1614e-04 - acc: 0.0000e+00 - val_loss: 2.1554e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1369e-04 - acc: 0.0000e+00 - val_loss: 2.4213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0457e-04 - acc: 0.0000e+00 - val_loss: 2.7168e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0646e-04 - acc: 0.0000e+00 - val_loss: 2.0539e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1510e-04 - acc: 0.0000e+00 - val_loss: 2.0423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.3198e-04 - acc: 0.0000e+00 - val_loss: 3.1054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1354e-04 - acc: 0.0000e+00 - val_loss: 3.9297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1534e-04 - acc: 0.0000e+00 - val_loss: 2.6460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0624e-04 - acc: 0.0000e+00 - val_loss: 2.4153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1315e-04 - acc: 0.0000e+00 - val_loss: 2.5060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0642e-04 - acc: 0.0000e+00 - val_loss: 2.1543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.6967e-05 - acc: 0.0000e+00 - val_loss: 2.0206e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0736e-04 - acc: 0.0000e+00 - val_loss: 2.9245e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0128e-04 - acc: 0.0000e+00 - val_loss: 2.7116e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.9848e-05 - acc: 0.0000e+00 - val_loss: 1.7949e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1545e-04 - acc: 0.0000e+00 - val_loss: 6.1536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0434e-04 - acc: 0.0000e+00 - val_loss: 1.9542e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.5638e-05 - acc: 0.0000e+00 - val_loss: 1.7668e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.9248e-05 - acc: 0.0000e+00 - val_loss: 1.8277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0626e-04 - acc: 0.0000e+00 - val_loss: 1.6658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.3601e-05 - acc: 0.0000e+00 - val_loss: 1.7512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.3409e-05 - acc: 0.0000e+00 - val_loss: 5.2558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.1318e-04 - acc: 0.0000e+00 - val_loss: 1.6685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/40\n",
      "13702/13702 [==============================] - 1s - loss: 1.0324e-04 - acc: 0.0000e+00 - val_loss: 3.4065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/40\n",
      "13702/13702 [==============================] - 1s - loss: 9.8323e-05 - acc: 0.0000e+00 - val_loss: 1.6378e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00154 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/50\n",
      "13702/13702 [==============================] - 3s - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "13702/13702 [==============================] - 1s - loss: 6.1155e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "13702/13702 [==============================] - 1s - loss: 2.3406e-04 - acc: 0.0000e+00 - val_loss: 5.1013e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.5794e-04 - acc: 0.0000e+00 - val_loss: 3.3826e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3746e-04 - acc: 0.0000e+00 - val_loss: 2.8517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3370e-04 - acc: 0.0000e+00 - val_loss: 3.0560e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3598e-04 - acc: 0.0000e+00 - val_loss: 2.5555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3494e-04 - acc: 0.0000e+00 - val_loss: 2.4354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2616e-04 - acc: 0.0000e+00 - val_loss: 2.4152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2931e-04 - acc: 0.0000e+00 - val_loss: 2.3151e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2589e-04 - acc: 0.0000e+00 - val_loss: 2.2615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1997e-04 - acc: 0.0000e+00 - val_loss: 2.9215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2614e-04 - acc: 0.0000e+00 - val_loss: 2.4829e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2350e-04 - acc: 0.0000e+00 - val_loss: 2.4059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1747e-04 - acc: 0.0000e+00 - val_loss: 2.8092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2386e-04 - acc: 0.0000e+00 - val_loss: 2.1389e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "13702/13702 [==============================] - 2s - loss: 1.5281e-04 - acc: 0.0000e+00 - val_loss: 7.2467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.3556e-04 - acc: 0.0000e+00 - val_loss: 2.1918e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2646e-04 - acc: 0.0000e+00 - val_loss: 6.1137e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1138e-04 - acc: 0.0000e+00 - val_loss: 2.0882e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0793e-04 - acc: 0.0000e+00 - val_loss: 3.8489e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1824e-04 - acc: 0.0000e+00 - val_loss: 3.1272e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1111e-04 - acc: 0.0000e+00 - val_loss: 3.2462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0455e-04 - acc: 0.0000e+00 - val_loss: 2.5115e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1037e-04 - acc: 0.0000e+00 - val_loss: 2.3322e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0611e-04 - acc: 0.0000e+00 - val_loss: 2.0152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.2070e-04 - acc: 0.0000e+00 - val_loss: 2.0877e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1532e-04 - acc: 0.0000e+00 - val_loss: 3.0907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0028e-04 - acc: 0.0000e+00 - val_loss: 1.8533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.8638e-05 - acc: 0.0000e+00 - val_loss: 1.9049e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.9254e-05 - acc: 0.0000e+00 - val_loss: 1.9360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0794e-04 - acc: 0.0000e+00 - val_loss: 1.9874e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0507e-04 - acc: 0.0000e+00 - val_loss: 4.4674e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0573e-04 - acc: 0.0000e+00 - val_loss: 4.1609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0865e-04 - acc: 0.0000e+00 - val_loss: 1.7750e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.2070e-05 - acc: 0.0000e+00 - val_loss: 1.7007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0111e-04 - acc: 0.0000e+00 - val_loss: 1.8545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.9522e-05 - acc: 0.0000e+00 - val_loss: 1.8062e-04 - val_acc: 0.0000e+0000e+\n",
      "Epoch 39/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.3203e-05 - acc: 0.0000e+00 - val_loss: 1.7256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0144e-04 - acc: 0.0000e+00 - val_loss: 4.2150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.6557e-05 - acc: 0.0000e+00 - val_loss: 1.9540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.6155e-05 - acc: 0.0000e+00 - val_loss: 1.6172e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0363e-04 - acc: 0.0000e+00 - val_loss: 5.1332e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.1237e-04 - acc: 0.0000e+00 - val_loss: 1.6689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.0297e-05 - acc: 0.0000e+00 - val_loss: 2.2556e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.7386e-05 - acc: 0.0000e+00 - val_loss: 2.3616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "13702/13702 [==============================] - 1s - loss: 8.8869e-05 - acc: 0.0000e+00 - val_loss: 4.3205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "13702/13702 [==============================] - 1s - loss: 9.0987e-05 - acc: 0.0000e+00 - val_loss: 2.0496e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "13702/13702 [==============================] - 1s - loss: 8.6313e-05 - acc: 0.0000e+00 - val_loss: 2.4355e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "13702/13702 [==============================] - 1s - loss: 1.0821e-04 - acc: 0.0000e+00 - val_loss: 1.5587e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00170 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/60\n",
      "13702/13702 [==============================] - 4s - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 2/60\n",
      "13702/13702 [==============================] - 1s - loss: 6.2190e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 3/60\n",
      "13702/13702 [==============================] - 1s - loss: 2.6113e-04 - acc: 0.0000e+00 - val_loss: 7.6390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.7826e-04 - acc: 0.0000e+00 - val_loss: 4.4907e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.5425e-04 - acc: 0.0000e+00 - val_loss: 2.5851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.3637e-04 - acc: 0.0000e+00 - val_loss: 2.5611e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2954e-04 - acc: 0.0000e+00 - val_loss: 4.1833e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2692e-04 - acc: 0.0000e+00 - val_loss: 3.0945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2373e-04 - acc: 0.0000e+00 - val_loss: 2.2293e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1538e-04 - acc: 0.0000e+00 - val_loss: 2.7871e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2489e-04 - acc: 0.0000e+00 - val_loss: 3.6884e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1446e-04 - acc: 0.0000e+00 - val_loss: 2.9499e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1719e-04 - acc: 0.0000e+00 - val_loss: 2.2603e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0939e-04 - acc: 0.0000e+00 - val_loss: 2.8784e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1245e-04 - acc: 0.0000e+00 - val_loss: 2.1426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1381e-04 - acc: 0.0000e+00 - val_loss: 2.2118e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0448e-04 - acc: 0.0000e+00 - val_loss: 6.2976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.2278e-04 - acc: 0.0000e+00 - val_loss: 2.6181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0484e-04 - acc: 0.0000e+00 - val_loss: 2.0276e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0132e-04 - acc: 0.0000e+00 - val_loss: 2.2941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0528e-04 - acc: 0.0000e+00 - val_loss: 2.3044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0038e-04 - acc: 0.0000e+00 - val_loss: 1.9034e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.8397e-05 - acc: 0.0000e+00 - val_loss: 4.0959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1769e-04 - acc: 0.0000e+00 - val_loss: 2.9766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0180e-04 - acc: 0.0000e+00 - val_loss: 4.3567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0523e-04 - acc: 0.0000e+00 - val_loss: 3.1456e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1944e-04 - acc: 0.0000e+00 - val_loss: 1.8995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.7833e-05 - acc: 0.0000e+00 - val_loss: 5.1928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0059e-04 - acc: 0.0000e+00 - val_loss: 2.1230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.8660e-05 - acc: 0.0000e+00 - val_loss: 1.8401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.4840e-05 - acc: 0.0000e+00 - val_loss: 1.7217e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0168e-04 - acc: 0.0000e+00 - val_loss: 6.7779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0824e-04 - acc: 0.0000e+00 - val_loss: 2.2220e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0420e-04 - acc: 0.0000e+00 - val_loss: 2.2613e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.5481e-05 - acc: 0.0000e+00 - val_loss: 1.6422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.8293e-05 - acc: 0.0000e+00 - val_loss: 1.6237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.4743e-05 - acc: 0.0000e+00 - val_loss: 1.8087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0063e-04 - acc: 0.0000e+00 - val_loss: 3.6150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.1039e-05 - acc: 0.0000e+00 - val_loss: 1.6905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0646e-04 - acc: 0.0000e+00 - val_loss: 1.7894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0141e-04 - acc: 0.0000e+00 - val_loss: 2.6292e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0765e-04 - acc: 0.0000e+00 - val_loss: 1.5605e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.4441e-05 - acc: 0.0000e+00 - val_loss: 1.7894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.1358e-05 - acc: 0.0000e+00 - val_loss: 2.0495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.7955e-05 - acc: 0.0000e+00 - val_loss: 2.2358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.0812e-04 - acc: 0.0000e+00 - val_loss: 1.5931e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.4419e-05 - acc: 0.0000e+00 - val_loss: 2.1661e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.6623e-05 - acc: 0.0000e+00 - val_loss: 3.0909e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.6570e-05 - acc: 0.0000e+00 - val_loss: 1.7505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.9247e-05 - acc: 0.0000e+00 - val_loss: 3.6997e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.2225e-05 - acc: 0.0000e+00 - val_loss: 1.4757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.3969e-05 - acc: 0.0000e+00 - val_loss: 2.3041e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.8529e-05 - acc: 0.0000e+00 - val_loss: 1.5467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.9060e-05 - acc: 0.0000e+00 - val_loss: 1.4755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.3598e-05 - acc: 0.0000e+00 - val_loss: 1.3752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.8377e-05 - acc: 0.0000e+00 - val_loss: 2.4285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.5100e-05 - acc: 0.0000e+00 - val_loss: 1.7516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/60\n",
      "13702/13702 [==============================] - 1s - loss: 8.7111e-05 - acc: 0.0000e+00 - val_loss: 2.2360e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/60\n",
      "13702/13702 [==============================] - 1s - loss: 1.1126e-04 - acc: 0.0000e+00 - val_loss: 4.3956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/60\n",
      "13702/13702 [==============================] - 1s - loss: 9.5998e-05 - acc: 0.0000e+00 - val_loss: 2.6369e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00006 MSE (0.01 RMSE)\n",
      "Test Score: 0.00199 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/70\n",
      "13702/13702 [==============================] - 3s - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 2/70\n",
      "13702/13702 [==============================] - 1s - loss: 5.3582e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 3/70\n",
      "13702/13702 [==============================] - 1s - loss: 2.2881e-04 - acc: 0.0000e+00 - val_loss: 5.0299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.6550e-04 - acc: 0.0000e+00 - val_loss: 5.0301e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.4928e-04 - acc: 0.0000e+00 - val_loss: 3.9074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.4639e-04 - acc: 0.0000e+00 - val_loss: 2.5880e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.3689e-04 - acc: 0.0000e+00 - val_loss: 2.6389e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.2885e-04 - acc: 0.0000e+00 - val_loss: 2.6504e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.3452e-04 - acc: 0.0000e+00 - val_loss: 2.2839e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1642e-04 - acc: 0.0000e+00 - val_loss: 3.1370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1932e-04 - acc: 0.0000e+00 - val_loss: 2.2707e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1174e-04 - acc: 0.0000e+00 - val_loss: 3.0295e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.2153e-04 - acc: 0.0000e+00 - val_loss: 2.5243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1446e-04 - acc: 0.0000e+00 - val_loss: 2.4334e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0439e-04 - acc: 0.0000e+00 - val_loss: 2.2274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0652e-04 - acc: 0.0000e+00 - val_loss: 2.2469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1017e-04 - acc: 0.0000e+00 - val_loss: 2.8146e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.3383e-04 - acc: 0.0000e+00 - val_loss: 6.2469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.2334e-04 - acc: 0.0000e+00 - val_loss: 2.2057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0665e-04 - acc: 0.0000e+00 - val_loss: 1.9796e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0551e-04 - acc: 0.0000e+00 - val_loss: 2.3774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0147e-04 - acc: 0.0000e+00 - val_loss: 3.9446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0268e-04 - acc: 0.0000e+00 - val_loss: 2.1510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1566e-04 - acc: 0.0000e+00 - val_loss: 3.7664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0949e-04 - acc: 0.0000e+00 - val_loss: 1.9650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0191e-04 - acc: 0.0000e+00 - val_loss: 1.8888e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0533e-04 - acc: 0.0000e+00 - val_loss: 1.8349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.6611e-05 - acc: 0.0000e+00 - val_loss: 1.7928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0848e-04 - acc: 0.0000e+00 - val_loss: 3.2516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0761e-04 - acc: 0.0000e+00 - val_loss: 2.0436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.5905e-05 - acc: 0.0000e+00 - val_loss: 5.1163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0422e-04 - acc: 0.0000e+00 - val_loss: 3.6409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0747e-04 - acc: 0.0000e+00 - val_loss: 3.8852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.8784e-05 - acc: 0.0000e+00 - val_loss: 1.7454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.3227e-05 - acc: 0.0000e+00 - val_loss: 2.0640e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.9350e-05 - acc: 0.0000e+00 - val_loss: 1.7662e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.1767e-05 - acc: 0.0000e+00 - val_loss: 1.8748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.5590e-05 - acc: 0.0000e+00 - val_loss: 1.7979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.2854e-05 - acc: 0.0000e+00 - val_loss: 1.6606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.2675e-05 - acc: 0.0000e+00 - val_loss: 2.9546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.6049e-05 - acc: 0.0000e+00 - val_loss: 3.1068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.5226e-05 - acc: 0.0000e+00 - val_loss: 1.7401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.7237e-05 - acc: 0.0000e+00 - val_loss: 5.6944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.8594e-05 - acc: 0.0000e+00 - val_loss: 2.1229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.6426e-05 - acc: 0.0000e+00 - val_loss: 1.6023e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.6209e-05 - acc: 0.0000e+00 - val_loss: 1.8303e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.9519e-05 - acc: 0.0000e+00 - val_loss: 2.6528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.9857e-05 - acc: 0.0000e+00 - val_loss: 1.9774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.9208e-05 - acc: 0.0000e+00 - val_loss: 1.4867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.8011e-05 - acc: 0.0000e+00 - val_loss: 3.8530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.6348e-05 - acc: 0.0000e+00 - val_loss: 2.3431e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.5395e-05 - acc: 0.0000e+00 - val_loss: 3.0095e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.2310e-05 - acc: 0.0000e+00 - val_loss: 4.1776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.1565e-04 - acc: 0.0000e+00 - val_loss: 4.8927e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.4294e-05 - acc: 0.0000e+00 - val_loss: 2.3631e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/70\n",
      "13702/13702 [==============================] - 1s - loss: 9.2164e-05 - acc: 0.0000e+00 - val_loss: 4.0009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0545e-04 - acc: 0.0000e+00 - val_loss: 5.7392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.5057e-05 - acc: 0.0000e+00 - val_loss: 1.4124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.9082e-05 - acc: 0.0000e+00 - val_loss: 3.3778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.0651e-05 - acc: 0.0000e+00 - val_loss: 1.5310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.5129e-05 - acc: 0.0000e+00 - val_loss: 1.3490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/70\n",
      "13702/13702 [==============================] - 1s - loss: 7.9467e-05 - acc: 0.0000e+00 - val_loss: 1.9223e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.2660e-05 - acc: 0.0000e+00 - val_loss: 1.6330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.1874e-05 - acc: 0.0000e+00 - val_loss: 1.2952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/70\n",
      "13702/13702 [==============================] - 1s - loss: 7.7345e-05 - acc: 0.0000e+00 - val_loss: 1.3393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.8544e-05 - acc: 0.0000e+00 - val_loss: 1.6032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.1075e-05 - acc: 0.0000e+00 - val_loss: 1.5639e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/70\n",
      "13702/13702 [==============================] - 1s - loss: 8.7115e-05 - acc: 0.0000e+00 - val_loss: 2.3282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/70\n",
      "13702/13702 [==============================] - 1s - loss: 1.0141e-04 - acc: 0.0000e+00 - val_loss: 1.8696e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/70\n",
      "13702/13702 [==============================] - 1s - loss: 7.5550e-05 - acc: 0.0000e+00 - val_loss: 1.2372e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00077 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/80\n",
      "13702/13702 [==============================] - 3s - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 2/80\n",
      "13702/13702 [==============================] - 1s - loss: 6.6267e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 3/80\n",
      "13702/13702 [==============================] - 1s - loss: 2.4498e-04 - acc: 0.0000e+00 - val_loss: 5.5771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.7450e-04 - acc: 0.0000e+00 - val_loss: 3.4238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.4284e-04 - acc: 0.0000e+00 - val_loss: 2.8612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.4325e-04 - acc: 0.0000e+00 - val_loss: 2.5068e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2786e-04 - acc: 0.0000e+00 - val_loss: 2.4169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.3242e-04 - acc: 0.0000e+00 - val_loss: 2.5684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.3923e-04 - acc: 0.0000e+00 - val_loss: 2.4193e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2400e-04 - acc: 0.0000e+00 - val_loss: 2.2988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1814e-04 - acc: 0.0000e+00 - val_loss: 2.4150e-04 - val_acc: 0.0000e+0000e+0\n",
      "Epoch 12/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1486e-04 - acc: 0.0000e+00 - val_loss: 2.5128e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1179e-04 - acc: 0.0000e+00 - val_loss: 2.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1877e-04 - acc: 0.0000e+00 - val_loss: 2.2166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2411e-04 - acc: 0.0000e+00 - val_loss: 2.5036e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0942e-04 - acc: 0.0000e+00 - val_loss: 3.0699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1899e-04 - acc: 0.0000e+00 - val_loss: 2.7711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0949e-04 - acc: 0.0000e+00 - val_loss: 2.3521e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1111e-04 - acc: 0.0000e+00 - val_loss: 4.0093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1555e-04 - acc: 0.0000e+00 - val_loss: 2.0657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1336e-04 - acc: 0.0000e+00 - val_loss: 6.0995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.1706e-04 - acc: 0.0000e+00 - val_loss: 1.9505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0549e-04 - acc: 0.0000e+00 - val_loss: 3.7993e-04 - val_acc: 0.0000e+0000\n",
      "Epoch 24/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0323e-04 - acc: 0.0000e+00 - val_loss: 4.6305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0563e-04 - acc: 0.0000e+00 - val_loss: 1.9053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0076e-04 - acc: 0.0000e+00 - val_loss: 1.9249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0156e-04 - acc: 0.0000e+00 - val_loss: 1.7626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0609e-04 - acc: 0.0000e+00 - val_loss: 2.2839e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2693e-04 - acc: 0.0000e+00 - val_loss: 3.9463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.6310e-05 - acc: 0.0000e+00 - val_loss: 1.7287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.8896e-05 - acc: 0.0000e+00 - val_loss: 2.1525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0166e-04 - acc: 0.0000e+00 - val_loss: 2.3176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.4258e-05 - acc: 0.0000e+00 - val_loss: 2.6754e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.6097e-05 - acc: 0.0000e+00 - val_loss: 1.6225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.8813e-05 - acc: 0.0000e+00 - val_loss: 1.6897e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.3064e-05 - acc: 0.0000e+00 - val_loss: 1.7338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.2087e-04 - acc: 0.0000e+00 - val_loss: 1.8374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0334e-04 - acc: 0.0000e+00 - val_loss: 1.7992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/80\n",
      "13702/13702 [==============================] - 1s - loss: 1.0013e-04 - acc: 0.0000e+00 - val_loss: 1.7599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.7584e-05 - acc: 0.0000e+00 - val_loss: 2.8530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.0456e-05 - acc: 0.0000e+00 - val_loss: 1.5835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.7274e-05 - acc: 0.0000e+00 - val_loss: 3.0339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.9506e-05 - acc: 0.0000e+00 - val_loss: 1.7252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.5057e-05 - acc: 0.0000e+00 - val_loss: 2.2257e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.5424e-05 - acc: 0.0000e+00 - val_loss: 2.0976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.1165e-05 - acc: 0.0000e+00 - val_loss: 2.2740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.0630e-05 - acc: 0.0000e+00 - val_loss: 1.6769e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.8074e-05 - acc: 0.0000e+00 - val_loss: 1.4536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.2209e-05 - acc: 0.0000e+00 - val_loss: 1.7540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.2851e-05 - acc: 0.0000e+00 - val_loss: 2.5243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.7746e-05 - acc: 0.0000e+00 - val_loss: 1.4287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.5136e-05 - acc: 0.0000e+00 - val_loss: 1.7713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.4671e-05 - acc: 0.0000e+00 - val_loss: 1.5599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.1294e-05 - acc: 0.0000e+00 - val_loss: 5.7339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.7756e-05 - acc: 0.0000e+00 - val_loss: 2.1205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.5863e-05 - acc: 0.0000e+00 - val_loss: 2.8925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.4177e-05 - acc: 0.0000e+00 - val_loss: 2.1622e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.4812e-05 - acc: 0.0000e+00 - val_loss: 4.5734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.0191e-05 - acc: 0.0000e+00 - val_loss: 1.3329e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.9338e-05 - acc: 0.0000e+00 - val_loss: 1.4307e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.8886e-05 - acc: 0.0000e+00 - val_loss: 1.3166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.0856e-05 - acc: 0.0000e+00 - val_loss: 4.1046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.5818e-05 - acc: 0.0000e+00 - val_loss: 1.5463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.6955e-05 - acc: 0.0000e+00 - val_loss: 2.3536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.5087e-05 - acc: 0.0000e+00 - val_loss: 1.3392e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.4392e-05 - acc: 0.0000e+00 - val_loss: 2.1612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.1212e-05 - acc: 0.0000e+00 - val_loss: 1.4533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.6028e-05 - acc: 0.0000e+00 - val_loss: 1.2536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.5669e-05 - acc: 0.0000e+00 - val_loss: 1.2413e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.5304e-05 - acc: 0.0000e+00 - val_loss: 4.5873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/80\n",
      "13702/13702 [==============================] - 1s - loss: 9.2571e-05 - acc: 0.0000e+00 - val_loss: 1.8844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.7260e-05 - acc: 0.0000e+00 - val_loss: 1.3345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.1495e-05 - acc: 0.0000e+00 - val_loss: 1.5215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.2013e-05 - acc: 0.0000e+00 - val_loss: 1.5635e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.6542e-05 - acc: 0.0000e+00 - val_loss: 2.3782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.9235e-05 - acc: 0.0000e+00 - val_loss: 1.4939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.4172e-05 - acc: 0.0000e+00 - val_loss: 1.2089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.3653e-05 - acc: 0.0000e+00 - val_loss: 1.7867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/80\n",
      "13702/13702 [==============================] - 1s - loss: 8.6238e-05 - acc: 0.0000e+00 - val_loss: 1.2428e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/80\n",
      "13702/13702 [==============================] - 1s - loss: 7.3179e-05 - acc: 0.0000e+00 - val_loss: 1.3517e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00088 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13702/13702 [==============================] - 3s - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13702/13702 [==============================] - 1s - loss: 6.6089e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13702/13702 [==============================] - 1s - loss: 2.5927e-04 - acc: 0.0000e+00 - val_loss: 5.5867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.6719e-04 - acc: 0.0000e+00 - val_loss: 3.8243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.5463e-04 - acc: 0.0000e+00 - val_loss: 3.4004e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.4104e-04 - acc: 0.0000e+00 - val_loss: 2.8467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.4020e-04 - acc: 0.0000e+00 - val_loss: 2.3961e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.4476e-04 - acc: 0.0000e+00 - val_loss: 2.4082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.2445e-04 - acc: 0.0000e+00 - val_loss: 2.7234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.3098e-04 - acc: 0.0000e+00 - val_loss: 2.3597e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.3057e-04 - acc: 0.0000e+00 - val_loss: 2.2887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.5747e-04 - acc: 0.0000e+00 - val_loss: 3.1798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.2063e-04 - acc: 0.0000e+00 - val_loss: 2.2660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.2787e-04 - acc: 0.0000e+00 - val_loss: 4.2290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.2890e-04 - acc: 0.0000e+00 - val_loss: 2.6728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1739e-04 - acc: 0.0000e+00 - val_loss: 2.2743e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1680e-04 - acc: 0.0000e+00 - val_loss: 2.1673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1155e-04 - acc: 0.0000e+00 - val_loss: 3.0512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1115e-04 - acc: 0.0000e+00 - val_loss: 2.3868e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0944e-04 - acc: 0.0000e+00 - val_loss: 4.0689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1379e-04 - acc: 0.0000e+00 - val_loss: 4.3390e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0414e-04 - acc: 0.0000e+00 - val_loss: 1.9290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0869e-04 - acc: 0.0000e+00 - val_loss: 1.8922e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0707e-04 - acc: 0.0000e+00 - val_loss: 2.2854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0978e-04 - acc: 0.0000e+00 - val_loss: 1.9289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0658e-04 - acc: 0.0000e+00 - val_loss: 4.5127e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1089e-04 - acc: 0.0000e+00 - val_loss: 2.4062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0182e-04 - acc: 0.0000e+00 - val_loss: 1.7791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.7911e-05 - acc: 0.0000e+00 - val_loss: 2.1099e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.8986e-05 - acc: 0.0000e+00 - val_loss: 2.5993e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.6738e-05 - acc: 0.0000e+00 - val_loss: 4.7060e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0112e-04 - acc: 0.0000e+00 - val_loss: 1.6995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.1422e-05 - acc: 0.0000e+00 - val_loss: 1.8584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.4577e-05 - acc: 0.0000e+00 - val_loss: 2.0896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.4214e-05 - acc: 0.0000e+00 - val_loss: 1.7028e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.6956e-05 - acc: 0.0000e+00 - val_loss: 1.7034e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.6899e-05 - acc: 0.0000e+00 - val_loss: 3.3117e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.0311e-05 - acc: 0.0000e+00 - val_loss: 1.7297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.4781e-05 - acc: 0.0000e+00 - val_loss: 2.3161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.2546e-05 - acc: 0.0000e+00 - val_loss: 4.0132e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.0944e-05 - acc: 0.0000e+00 - val_loss: 2.1072e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.4480e-05 - acc: 0.0000e+00 - val_loss: 1.9303e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0171e-04 - acc: 0.0000e+00 - val_loss: 7.2657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0352e-04 - acc: 0.0000e+00 - val_loss: 2.7287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.9083e-05 - acc: 0.0000e+00 - val_loss: 6.3949e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0643e-04 - acc: 0.0000e+00 - val_loss: 2.8457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.4561e-05 - acc: 0.0000e+00 - val_loss: 1.4829e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.3505e-05 - acc: 0.0000e+00 - val_loss: 2.7795e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0506e-04 - acc: 0.0000e+00 - val_loss: 1.5058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.1471e-05 - acc: 0.0000e+00 - val_loss: 1.8744e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.4561e-05 - acc: 0.0000e+00 - val_loss: 1.8416e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.8978e-05 - acc: 0.0000e+00 - val_loss: 1.9445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.8354e-05 - acc: 0.0000e+00 - val_loss: 1.4585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.3938e-05 - acc: 0.0000e+00 - val_loss: 1.3755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.1736e-05 - acc: 0.0000e+00 - val_loss: 1.6637e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.7534e-05 - acc: 0.0000e+00 - val_loss: 1.3509e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.3059e-05 - acc: 0.0000e+00 - val_loss: 1.4621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.5632e-05 - acc: 0.0000e+00 - val_loss: 2.0207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.5058e-05 - acc: 0.0000e+00 - val_loss: 1.4563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.3599e-05 - acc: 0.0000e+00 - val_loss: 2.7951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0955e-04 - acc: 0.0000e+00 - val_loss: 2.6817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.1209e-04 - acc: 0.0000e+00 - val_loss: 1.5426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.3626e-05 - acc: 0.0000e+00 - val_loss: 3.6299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.8951e-05 - acc: 0.0000e+00 - val_loss: 2.5082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.6647e-05 - acc: 0.0000e+00 - val_loss: 1.3087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.4261e-05 - acc: 0.0000e+00 - val_loss: 1.5975e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.6224e-05 - acc: 0.0000e+00 - val_loss: 1.9494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.7741e-05 - acc: 0.0000e+00 - val_loss: 1.4849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.2226e-05 - acc: 0.0000e+00 - val_loss: 1.2277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.3065e-05 - acc: 0.0000e+00 - val_loss: 2.9331e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.1996e-05 - acc: 0.0000e+00 - val_loss: 1.7227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.0804e-05 - acc: 0.0000e+00 - val_loss: 1.5162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.6628e-05 - acc: 0.0000e+00 - val_loss: 2.8939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.1165e-05 - acc: 0.0000e+00 - val_loss: 4.1937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.6824e-05 - acc: 0.0000e+00 - val_loss: 4.4946e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13702/13702 [==============================] - 1s - loss: 1.0001e-04 - acc: 0.0000e+00 - val_loss: 6.7111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13702/13702 [==============================] - 1s - loss: 9.8819e-05 - acc: 0.0000e+00 - val_loss: 1.3231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.2757e-05 - acc: 0.0000e+00 - val_loss: 1.1742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13702/13702 [==============================] - 1s - loss: 6.6830e-05 - acc: 0.0000e+00 - val_loss: 1.1508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.4761e-05 - acc: 0.0000e+00 - val_loss: 1.1612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.0506e-05 - acc: 0.0000e+00 - val_loss: 1.1273e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.3993e-05 - acc: 0.0000e+00 - val_loss: 1.1665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.2404e-05 - acc: 0.0000e+00 - val_loss: 1.8418e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13702/13702 [==============================] - 1s - loss: 8.3052e-05 - acc: 0.0000e+00 - val_loss: 1.3797e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.3539e-05 - acc: 0.0000e+00 - val_loss: 1.1409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.0346e-05 - acc: 0.0000e+00 - val_loss: 1.1774e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.2422e-05 - acc: 0.0000e+00 - val_loss: 1.1808e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13702/13702 [==============================] - 1s - loss: 6.8385e-05 - acc: 0.0000e+00 - val_loss: 1.0849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13702/13702 [==============================] - 1s - loss: 7.2681e-05 - acc: 0.0000e+00 - val_loss: 1.0970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13702/13702 [==============================] - 1s - loss: 6.5907e-05 - acc: 0.0000e+00 - val_loss: 1.4743e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00032 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13702 samples, validate on 1523 samples\n",
      "Epoch 1/100\n",
      "13702/13702 [==============================] - 3s - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.3824e-04 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "13702/13702 [==============================] - 1s - loss: 2.3779e-04 - acc: 0.0000e+00 - val_loss: 5.2778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.5669e-04 - acc: 0.0000e+00 - val_loss: 3.4203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.4916e-04 - acc: 0.0000e+00 - val_loss: 3.9398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.3578e-04 - acc: 0.0000e+00 - val_loss: 2.6067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.3061e-04 - acc: 0.0000e+00 - val_loss: 2.4931e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.4447e-04 - acc: 0.0000e+00 - val_loss: 2.4685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.3549e-04 - acc: 0.0000e+00 - val_loss: 3.0951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1994e-04 - acc: 0.0000e+00 - val_loss: 2.3173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1903e-04 - acc: 0.0000e+00 - val_loss: 3.9398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2634e-04 - acc: 0.0000e+00 - val_loss: 2.4660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1832e-04 - acc: 0.0000e+00 - val_loss: 2.2484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2101e-04 - acc: 0.0000e+00 - val_loss: 2.2053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2049e-04 - acc: 0.0000e+00 - val_loss: 2.2910e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1224e-04 - acc: 0.0000e+00 - val_loss: 2.2444e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1165e-04 - acc: 0.0000e+00 - val_loss: 3.2504e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0988e-04 - acc: 0.0000e+00 - val_loss: 2.0211e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1368e-04 - acc: 0.0000e+00 - val_loss: 2.5594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.3644e-04 - acc: 0.0000e+00 - val_loss: 2.6951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1308e-04 - acc: 0.0000e+00 - val_loss: 2.6979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0683e-04 - acc: 0.0000e+00 - val_loss: 1.9775e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0029e-04 - acc: 0.0000e+00 - val_loss: 2.0724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0851e-04 - acc: 0.0000e+00 - val_loss: 3.7251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0738e-04 - acc: 0.0000e+00 - val_loss: 2.5096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1324e-04 - acc: 0.0000e+00 - val_loss: 2.0262e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0401e-04 - acc: 0.0000e+00 - val_loss: 3.0671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0098e-04 - acc: 0.0000e+00 - val_loss: 4.7762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1684e-04 - acc: 0.0000e+00 - val_loss: 1.8941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0706e-04 - acc: 0.0000e+00 - val_loss: 3.4940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2781e-04 - acc: 0.0000e+00 - val_loss: 1.8850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0194e-04 - acc: 0.0000e+00 - val_loss: 1.9970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.2364e-04 - acc: 0.0000e+00 - val_loss: 2.8180e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0743e-04 - acc: 0.0000e+00 - val_loss: 1.7792e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.4082e-05 - acc: 0.0000e+00 - val_loss: 1.9092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0805e-04 - acc: 0.0000e+00 - val_loss: 1.7552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.7711e-05 - acc: 0.0000e+00 - val_loss: 2.2564e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.8585e-05 - acc: 0.0000e+00 - val_loss: 1.8616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1931e-04 - acc: 0.0000e+00 - val_loss: 1.8008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.9851e-05 - acc: 0.0000e+00 - val_loss: 1.7408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0531e-04 - acc: 0.0000e+00 - val_loss: 1.8432e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0655e-04 - acc: 0.0000e+00 - val_loss: 3.1590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0102e-04 - acc: 0.0000e+00 - val_loss: 2.0471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.4763e-05 - acc: 0.0000e+00 - val_loss: 1.6779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.4119e-05 - acc: 0.0000e+00 - val_loss: 1.7765e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.6664e-05 - acc: 0.0000e+00 - val_loss: 2.2464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.9921e-05 - acc: 0.0000e+00 - val_loss: 1.7101e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.3820e-05 - acc: 0.0000e+00 - val_loss: 2.1212e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.7753e-05 - acc: 0.0000e+00 - val_loss: 1.5561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.1039e-05 - acc: 0.0000e+00 - val_loss: 2.8530e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.6943e-05 - acc: 0.0000e+00 - val_loss: 2.1737e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.0655e-05 - acc: 0.0000e+00 - val_loss: 1.8859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.2950e-05 - acc: 0.0000e+00 - val_loss: 1.4745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.0031e-04 - acc: 0.0000e+00 - val_loss: 4.0727e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.7670e-05 - acc: 0.0000e+00 - val_loss: 1.7582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.5274e-05 - acc: 0.0000e+00 - val_loss: 3.6586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1647e-04 - acc: 0.0000e+00 - val_loss: 2.0324e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "13702/13702 [==============================] - 1s - loss: 1.1154e-04 - acc: 0.0000e+00 - val_loss: 1.9097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.1990e-05 - acc: 0.0000e+00 - val_loss: 1.5139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.9407e-05 - acc: 0.0000e+00 - val_loss: 1.4982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.8360e-05 - acc: 0.0000e+00 - val_loss: 2.7859e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.9392e-05 - acc: 0.0000e+00 - val_loss: 1.3830e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.5109e-05 - acc: 0.0000e+00 - val_loss: 1.8507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.9735e-05 - acc: 0.0000e+00 - val_loss: 1.3697e-04 - val_acc: 0.0000e+0000\n",
      "Epoch 65/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.6296e-05 - acc: 0.0000e+00 - val_loss: 1.5770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.0695e-05 - acc: 0.0000e+00 - val_loss: 1.3700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.6389e-05 - acc: 0.0000e+00 - val_loss: 3.4893e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.2476e-05 - acc: 0.0000e+00 - val_loss: 5.0106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.0194e-05 - acc: 0.0000e+00 - val_loss: 1.5320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.5919e-05 - acc: 0.0000e+00 - val_loss: 1.3555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.5843e-05 - acc: 0.0000e+00 - val_loss: 2.4102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "13702/13702 [==============================] - 1s - loss: 9.3884e-05 - acc: 0.0000e+00 - val_loss: 1.9546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.2290e-05 - acc: 0.0000e+00 - val_loss: 1.4807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.5925e-05 - acc: 0.0000e+00 - val_loss: 1.7940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.0279e-05 - acc: 0.0000e+00 - val_loss: 1.2596e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.1769e-05 - acc: 0.0000e+00 - val_loss: 1.2512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.4212e-05 - acc: 0.0000e+00 - val_loss: 1.2629e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.7390e-05 - acc: 0.0000e+00 - val_loss: 3.4290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.2783e-05 - acc: 0.0000e+00 - val_loss: 4.3815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.0093e-05 - acc: 0.0000e+00 - val_loss: 1.2592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.3900e-05 - acc: 0.0000e+00 - val_loss: 1.3849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.2417e-05 - acc: 0.0000e+00 - val_loss: 1.4017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.2069e-05 - acc: 0.0000e+00 - val_loss: 1.7169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.2940e-05 - acc: 0.0000e+00 - val_loss: 1.1742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.1765e-05 - acc: 0.0000e+00 - val_loss: 1.2945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.6684e-05 - acc: 0.0000e+00 - val_loss: 1.1967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.7971e-05 - acc: 0.0000e+00 - val_loss: 1.4357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.7052e-05 - acc: 0.0000e+00 - val_loss: 2.5226e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.0868e-05 - acc: 0.0000e+00 - val_loss: 1.5820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.2275e-05 - acc: 0.0000e+00 - val_loss: 1.1268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.9113e-05 - acc: 0.0000e+00 - val_loss: 5.6330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "13702/13702 [==============================] - 1s - loss: 8.9301e-05 - acc: 0.0000e+00 - val_loss: 2.4219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.8177e-05 - acc: 0.0000e+00 - val_loss: 1.1760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.6104e-05 - acc: 0.0000e+00 - val_loss: 1.7106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.0517e-05 - acc: 0.0000e+00 - val_loss: 1.3550e-04 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.3658e-05 - acc: 0.0000e+00 - val_loss: 1.7458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.0193e-05 - acc: 0.0000e+00 - val_loss: 1.0757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.5794e-05 - acc: 0.0000e+00 - val_loss: 1.1581e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "13702/13702 [==============================] - 1s - loss: 6.3649e-05 - acc: 0.0000e+00 - val_loss: 1.9939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "13702/13702 [==============================] - 1s - loss: 7.0166e-05 - acc: 0.0000e+00 - val_loss: 1.4096e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00086 MSE (0.03 RMSE)\n"
     ]
    }
   ],
   "source": [
    "epochs_result = {}\n",
    "\n",
    "for epochs in epochslist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "    epochs_result[epochs] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzjWKJxLnnHON8v8B3ipJUWwioCcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2922df93a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(epochs_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3 Optimal number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 22, 32)            4736      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 13,601\n",
      "Trainable params: 13,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 2s - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0841 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 9.8019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1308e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 4.5217e-04 - acc: 0.0000e+00 - val_loss: 6.0801e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.6125e-04 - acc: 0.0000e+00 - val_loss: 3.2174e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.4450e-04 - acc: 0.0000e+00 - val_loss: 3.1738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3887e-04 - acc: 0.0000e+00 - val_loss: 3.4616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3747e-04 - acc: 0.0000e+00 - val_loss: 3.0563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.2240e-04 - acc: 0.0000e+00 - val_loss: 4.5232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.1574e-04 - acc: 0.0000e+00 - val_loss: 3.1352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.0739e-04 - acc: 0.0000e+00 - val_loss: 5.6274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.9365e-04 - acc: 0.0000e+00 - val_loss: 2.5694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.8381e-04 - acc: 0.0000e+00 - val_loss: 2.2885e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7394e-04 - acc: 0.0000e+00 - val_loss: 2.4461e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7457e-04 - acc: 0.0000e+00 - val_loss: 2.3578e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6887e-04 - acc: 0.0000e+00 - val_loss: 2.2138e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6127e-04 - acc: 0.0000e+00 - val_loss: 2.4881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7469e-04 - acc: 0.0000e+00 - val_loss: 2.6547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6144e-04 - acc: 0.0000e+00 - val_loss: 4.7081e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7553e-04 - acc: 0.0000e+00 - val_loss: 2.4093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7055e-04 - acc: 0.0000e+00 - val_loss: 3.2517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3755e-04 - acc: 0.0000e+00 - val_loss: 2.0021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.5404e-04 - acc: 0.0000e+00 - val_loss: 5.1493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3615e-04 - acc: 0.0000e+00 - val_loss: 2.1185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3941e-04 - acc: 0.0000e+00 - val_loss: 2.4835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4132e-04 - acc: 0.0000e+00 - val_loss: 3.2255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3250e-04 - acc: 0.0000e+00 - val_loss: 2.9311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3988e-04 - acc: 0.0000e+00 - val_loss: 3.2929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4467e-04 - acc: 0.0000e+00 - val_loss: 2.4528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2333e-04 - acc: 0.0000e+00 - val_loss: 2.7753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1993e-04 - acc: 0.0000e+00 - val_loss: 3.1895e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2244e-04 - acc: 0.0000e+00 - val_loss: 1.9019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4162e-04 - acc: 0.0000e+00 - val_loss: 1.9278e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2809e-04 - acc: 0.0000e+00 - val_loss: 2.6528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2006e-04 - acc: 0.0000e+00 - val_loss: 1.8928e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0997e-04 - acc: 0.0000e+00 - val_loss: 1.8447e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1408e-04 - acc: 0.0000e+00 - val_loss: 3.0332e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0831e-04 - acc: 0.0000e+00 - val_loss: 1.7982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1007e-04 - acc: 0.0000e+00 - val_loss: 1.9491e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9675e-04 - acc: 0.0000e+00 - val_loss: 1.9274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1145e-04 - acc: 0.0000e+00 - val_loss: 1.7986e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0728e-04 - acc: 0.0000e+00 - val_loss: 1.9320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0651e-04 - acc: 0.0000e+00 - val_loss: 1.7766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0627e-04 - acc: 0.0000e+00 - val_loss: 1.7718e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1044e-04 - acc: 0.0000e+00 - val_loss: 2.0235e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8987e-04 - acc: 0.0000e+00 - val_loss: 1.7146e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8103e-04 - acc: 0.0000e+00 - val_loss: 2.0828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9037e-04 - acc: 0.0000e+00 - val_loss: 2.2063e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9263e-04 - acc: 0.0000e+00 - val_loss: 1.8588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8914e-04 - acc: 0.0000e+00 - val_loss: 2.5464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1299e-04 - acc: 0.0000e+00 - val_loss: 1.7413e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7338e-04 - acc: 0.0000e+00 - val_loss: 1.8425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7103e-04 - acc: 0.0000e+00 - val_loss: 1.9687e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7167e-04 - acc: 0.0000e+00 - val_loss: 1.9969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7282e-04 - acc: 0.0000e+00 - val_loss: 1.8351e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6896e-04 - acc: 0.0000e+00 - val_loss: 3.3851e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8303e-04 - acc: 0.0000e+00 - val_loss: 2.1563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5803e-04 - acc: 0.0000e+00 - val_loss: 1.7686e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6912e-04 - acc: 0.0000e+00 - val_loss: 1.6861e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6470e-04 - acc: 0.0000e+00 - val_loss: 1.8890e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6077e-04 - acc: 0.0000e+00 - val_loss: 1.8594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6172e-04 - acc: 0.0000e+00 - val_loss: 1.6547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6332e-04 - acc: 0.0000e+00 - val_loss: 1.7847e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5917e-04 - acc: 0.0000e+00 - val_loss: 2.1358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5229e-04 - acc: 0.0000e+00 - val_loss: 1.7062e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5705e-04 - acc: 0.0000e+00 - val_loss: 1.7001e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4763e-04 - acc: 0.0000e+00 - val_loss: 1.6984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5539e-04 - acc: 0.0000e+00 - val_loss: 2.2463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4528e-04 - acc: 0.0000e+00 - val_loss: 1.7183e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4018e-04 - acc: 0.0000e+00 - val_loss: 2.2541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4930e-04 - acc: 0.0000e+00 - val_loss: 2.1791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4455e-04 - acc: 0.0000e+00 - val_loss: 1.7050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4507e-04 - acc: 0.0000e+00 - val_loss: 1.6679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3132e-04 - acc: 0.0000e+00 - val_loss: 2.0364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4370e-04 - acc: 0.0000e+00 - val_loss: 1.8145e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3519e-04 - acc: 0.0000e+00 - val_loss: 3.7377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4701e-04 - acc: 0.0000e+00 - val_loss: 4.1943e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3439e-04 - acc: 0.0000e+00 - val_loss: 2.0473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2879e-04 - acc: 0.0000e+00 - val_loss: 1.7536e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2293e-04 - acc: 0.0000e+00 - val_loss: 1.7878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2901e-04 - acc: 0.0000e+00 - val_loss: 3.0140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3271e-04 - acc: 0.0000e+00 - val_loss: 3.2067e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2968e-04 - acc: 0.0000e+00 - val_loss: 2.1139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1750e-04 - acc: 0.0000e+00 - val_loss: 1.8835e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2748e-04 - acc: 0.0000e+00 - val_loss: 1.9147e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2567e-04 - acc: 0.0000e+00 - val_loss: 2.1327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2347e-04 - acc: 0.0000e+00 - val_loss: 1.7156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1792e-04 - acc: 0.0000e+00 - val_loss: 1.8401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1104e-04 - acc: 0.0000e+00 - val_loss: 1.7696e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1118e-04 - acc: 0.0000e+00 - val_loss: 2.2785e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00005 MSE (0.01 RMSE)\n",
      "Test Score: 0.00809 MSE (0.09 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 22, 32)            4736      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,145\n",
      "Trainable params: 14,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - ETA: 0s - loss: 0.0239 - acc: 0.0000e+0 - 2s - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0137 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6673e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 4.5537e-04 - acc: 0.0000e+00 - val_loss: 9.7508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 4.0013e-04 - acc: 0.0000e+00 - val_loss: 5.1892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.7835e-04 - acc: 0.0000e+00 - val_loss: 3.7573e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.7209e-04 - acc: 0.0000e+00 - val_loss: 3.4938e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3857e-04 - acc: 0.0000e+00 - val_loss: 2.8594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3065e-04 - acc: 0.0000e+00 - val_loss: 3.7322e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.1574e-04 - acc: 0.0000e+00 - val_loss: 2.4896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.0677e-04 - acc: 0.0000e+00 - val_loss: 2.3476e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.1454e-04 - acc: 0.0000e+00 - val_loss: 2.1837e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3050e-04 - acc: 0.0000e+00 - val_loss: 2.3540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7673e-04 - acc: 0.0000e+00 - val_loss: 4.4183e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.7449e-04 - acc: 0.0000e+00 - val_loss: 2.2809e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6815e-04 - acc: 0.0000e+00 - val_loss: 2.3394e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6183e-04 - acc: 0.0000e+00 - val_loss: 2.1246e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6673e-04 - acc: 0.0000e+00 - val_loss: 2.5620e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.5763e-04 - acc: 0.0000e+00 - val_loss: 2.1607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4085e-04 - acc: 0.0000e+00 - val_loss: 7.3177e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6710e-04 - acc: 0.0000e+00 - val_loss: 2.0957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2858e-04 - acc: 0.0000e+00 - val_loss: 5.0905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3903e-04 - acc: 0.0000e+00 - val_loss: 2.7810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3128e-04 - acc: 0.0000e+00 - val_loss: 2.5337e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4047e-04 - acc: 0.0000e+00 - val_loss: 6.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3320e-04 - acc: 0.0000e+00 - val_loss: 5.3161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2623e-04 - acc: 0.0000e+00 - val_loss: 2.0268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1202e-04 - acc: 0.0000e+00 - val_loss: 2.0359e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0972e-04 - acc: 0.0000e+00 - val_loss: 3.9546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2268e-04 - acc: 0.0000e+00 - val_loss: 2.0290e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0346e-04 - acc: 0.0000e+00 - val_loss: 3.9124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0151e-04 - acc: 0.0000e+00 - val_loss: 2.2003e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0388e-04 - acc: 0.0000e+00 - val_loss: 2.5419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9070e-04 - acc: 0.0000e+00 - val_loss: 2.0046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9934e-04 - acc: 0.0000e+00 - val_loss: 3.4510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0421e-04 - acc: 0.0000e+00 - val_loss: 1.8840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9383e-04 - acc: 0.0000e+00 - val_loss: 8.0139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8778e-04 - acc: 0.0000e+00 - val_loss: 2.0490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9604e-04 - acc: 0.0000e+00 - val_loss: 4.8461e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8282e-04 - acc: 0.0000e+00 - val_loss: 2.4399e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7226e-04 - acc: 0.0000e+00 - val_loss: 1.8196e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7449e-04 - acc: 0.0000e+00 - val_loss: 2.6886e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6390e-04 - acc: 0.0000e+00 - val_loss: 4.3978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6134e-04 - acc: 0.0000e+00 - val_loss: 2.6092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6577e-04 - acc: 0.0000e+00 - val_loss: 1.8296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6382e-04 - acc: 0.0000e+00 - val_loss: 3.2945e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5330e-04 - acc: 0.0000e+00 - val_loss: 1.8462e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5972e-04 - acc: 0.0000e+00 - val_loss: 6.4905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5776e-04 - acc: 0.0000e+00 - val_loss: 2.0012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4338e-04 - acc: 0.0000e+00 - val_loss: 2.0442e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4535e-04 - acc: 0.0000e+00 - val_loss: 5.0196e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2988e-04 - acc: 0.0000e+00 - val_loss: 1.8333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4286e-04 - acc: 0.0000e+00 - val_loss: 4.0023e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2560e-04 - acc: 0.0000e+00 - val_loss: 2.8604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2104e-04 - acc: 0.0000e+00 - val_loss: 3.8935e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2313e-04 - acc: 0.0000e+00 - val_loss: 1.8014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2327e-04 - acc: 0.0000e+00 - val_loss: 3.4365e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1252e-04 - acc: 0.0000e+00 - val_loss: 3.4353e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1358e-04 - acc: 0.0000e+00 - val_loss: 3.6140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1349e-04 - acc: 0.0000e+00 - val_loss: 3.4278e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0809e-04 - acc: 0.0000e+00 - val_loss: 3.7535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9576e-05 - acc: 0.0000e+00 - val_loss: 2.9398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0462e-04 - acc: 0.0000e+00 - val_loss: 2.7304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0765e-04 - acc: 0.0000e+00 - val_loss: 3.1029e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0486e-04 - acc: 0.0000e+00 - val_loss: 2.6433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0384e-04 - acc: 0.0000e+00 - val_loss: 5.6881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0465e-04 - acc: 0.0000e+00 - val_loss: 2.1451e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0251e-04 - acc: 0.0000e+00 - val_loss: 4.4722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5657e-05 - acc: 0.0000e+00 - val_loss: 2.9252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0183e-04 - acc: 0.0000e+00 - val_loss: 4.3997e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9849e-05 - acc: 0.0000e+00 - val_loss: 3.2019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2292e-05 - acc: 0.0000e+00 - val_loss: 2.3244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3430e-05 - acc: 0.0000e+00 - val_loss: 2.3518e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3135e-05 - acc: 0.0000e+00 - val_loss: 2.5017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0136e-05 - acc: 0.0000e+00 - val_loss: 4.5469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9215e-05 - acc: 0.0000e+00 - val_loss: 2.8440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3321e-05 - acc: 0.0000e+00 - val_loss: 3.8150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9715e-05 - acc: 0.0000e+00 - val_loss: 6.2238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1365e-05 - acc: 0.0000e+00 - val_loss: 4.0256e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8879e-05 - acc: 0.0000e+00 - val_loss: 7.0585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4942e-05 - acc: 0.0000e+00 - val_loss: 5.9327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9788e-05 - acc: 0.0000e+00 - val_loss: 5.4626e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9706e-05 - acc: 0.0000e+00 - val_loss: 9.3332e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3022e-05 - acc: 0.0000e+00 - val_loss: 8.0722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3190e-05 - acc: 0.0000e+00 - val_loss: 6.7787e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1818e-05 - acc: 0.0000e+00 - val_loss: 6.8897e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4998e-05 - acc: 0.0000e+00 - val_loss: 4.9481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7689e-05 - acc: 0.0000e+00 - val_loss: 4.0089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8570e-05 - acc: 0.0000e+00 - val_loss: 7.6558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4375e-05 - acc: 0.0000e+00 - val_loss: 5.0817e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00011 MSE (0.01 RMSE)\n",
      "Test Score: 0.00266 MSE (0.05 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 22, 32)            4736      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 15,233\n",
      "Trainable params: 15,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 2s - loss: 0.0211 - acc: 0.0000e+00 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 5.9589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 5.0133e-04 - acc: 0.0000e+00 - val_loss: 8.2404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 4.0202e-04 - acc: 0.0000e+00 - val_loss: 6.6533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3818e-04 - acc: 0.0000e+00 - val_loss: 5.6144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.3962e-04 - acc: 0.0000e+00 - val_loss: 3.2445e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.9927e-04 - acc: 0.0000e+00 - val_loss: 2.8042e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.8216e-04 - acc: 0.0000e+00 - val_loss: 2.5814e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6754e-04 - acc: 0.0000e+00 - val_loss: 2.4850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.6402e-04 - acc: 0.0000e+00 - val_loss: 2.4268e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.5773e-04 - acc: 0.0000e+00 - val_loss: 4.0016e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4322e-04 - acc: 0.0000e+00 - val_loss: 2.3327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4410e-04 - acc: 0.0000e+00 - val_loss: 2.2570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4345e-04 - acc: 0.0000e+00 - val_loss: 2.5484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3237e-04 - acc: 0.0000e+00 - val_loss: 5.3237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2947e-04 - acc: 0.0000e+00 - val_loss: 2.6386e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1937e-04 - acc: 0.0000e+00 - val_loss: 3.1218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2115e-04 - acc: 0.0000e+00 - val_loss: 2.3339e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1661e-04 - acc: 0.0000e+00 - val_loss: 4.5529e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0738e-04 - acc: 0.0000e+00 - val_loss: 2.5439e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0121e-04 - acc: 0.0000e+00 - val_loss: 3.5531e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9814e-04 - acc: 0.0000e+00 - val_loss: 6.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9455e-04 - acc: 0.0000e+00 - val_loss: 2.9765e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8654e-04 - acc: 0.0000e+00 - val_loss: 7.0856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8610e-04 - acc: 0.0000e+00 - val_loss: 7.8086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7281e-04 - acc: 0.0000e+00 - val_loss: 3.5580e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6975e-04 - acc: 0.0000e+00 - val_loss: 4.4894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8793e-04 - acc: 0.0000e+00 - val_loss: 2.3526e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6958e-04 - acc: 0.0000e+00 - val_loss: 6.5960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5209e-04 - acc: 0.0000e+00 - val_loss: 2.7544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6878e-04 - acc: 0.0000e+00 - val_loss: 8.1988e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5693e-04 - acc: 0.0000e+00 - val_loss: 3.3091e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4335e-04 - acc: 0.0000e+00 - val_loss: 5.0719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4194e-04 - acc: 0.0000e+00 - val_loss: 6.1710e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4598e-04 - acc: 0.0000e+00 - val_loss: 6.7880e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4778e-04 - acc: 0.0000e+00 - val_loss: 8.6340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4149e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3593e-04 - acc: 0.0000e+00 - val_loss: 7.0729e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1836e-04 - acc: 0.0000e+00 - val_loss: 5.0911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2053e-04 - acc: 0.0000e+00 - val_loss: 8.4274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2624e-04 - acc: 0.0000e+00 - val_loss: 5.4251e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1889e-04 - acc: 0.0000e+00 - val_loss: 9.6545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0966e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1389e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0837e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0395e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0222e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0680e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7726e-05 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1378e-05 - acc: 0.0000e+00 - val_loss: 7.8944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0154e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1396e-05 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2052e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6839e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5298e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0312e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3334e-05 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8709e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0145e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6999e-05 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6172e-05 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8825e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7180e-05 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5055e-05 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1416e-05 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7308e-05 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2139e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9727e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0371e-05 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2991e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1147e-05 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8318e-05 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4916e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.1955e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1073e-05 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9245e-05 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4233e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8574e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.2959e-05 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6269e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7170e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6238e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8216e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.1329e-05 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 5.6402e-05 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.1755e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4283e-05 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5990e-05 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 5.7552e-05 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.2102e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00033 MSE (0.02 RMSE)\n",
      "Test Score: 0.01148 MSE (0.11 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 22, 64)            17664     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 22, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 51,745\n",
      "Trainable params: 51,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 2s - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.6470e-04 - acc: 0.0000e+00 - val_loss: 6.2854e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3806e-04 - acc: 0.0000e+00 - val_loss: 3.3297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2258e-04 - acc: 0.0000e+00 - val_loss: 3.1455e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1450e-04 - acc: 0.0000e+00 - val_loss: 2.6590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1916e-04 - acc: 0.0000e+00 - val_loss: 3.8236e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9080e-04 - acc: 0.0000e+00 - val_loss: 2.5676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8886e-04 - acc: 0.0000e+00 - val_loss: 3.4520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8814e-04 - acc: 0.0000e+00 - val_loss: 3.1629e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9755e-04 - acc: 0.0000e+00 - val_loss: 2.4818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8762e-04 - acc: 0.0000e+00 - val_loss: 2.4071e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8490e-04 - acc: 0.0000e+00 - val_loss: 2.3425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9992e-04 - acc: 0.0000e+00 - val_loss: 4.4923e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7197e-04 - acc: 0.0000e+00 - val_loss: 2.6967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7359e-04 - acc: 0.0000e+00 - val_loss: 4.3604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8068e-04 - acc: 0.0000e+00 - val_loss: 2.1058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6487e-04 - acc: 0.0000e+00 - val_loss: 2.1788e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7661e-04 - acc: 0.0000e+00 - val_loss: 2.2932e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6782e-04 - acc: 0.0000e+00 - val_loss: 2.7017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6598e-04 - acc: 0.0000e+00 - val_loss: 2.1216e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5660e-04 - acc: 0.0000e+00 - val_loss: 2.4616e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6272e-04 - acc: 0.0000e+00 - val_loss: 1.9881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4802e-04 - acc: 0.0000e+00 - val_loss: 2.4627e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6218e-04 - acc: 0.0000e+00 - val_loss: 2.4333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5858e-04 - acc: 0.0000e+00 - val_loss: 2.3508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5488e-04 - acc: 0.0000e+00 - val_loss: 2.4143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5595e-04 - acc: 0.0000e+00 - val_loss: 2.6521e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6891e-04 - acc: 0.0000e+00 - val_loss: 1.9908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3846e-04 - acc: 0.0000e+00 - val_loss: 1.8755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4574e-04 - acc: 0.0000e+00 - val_loss: 1.8321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4663e-04 - acc: 0.0000e+00 - val_loss: 2.3112e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3985e-04 - acc: 0.0000e+00 - val_loss: 1.9247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7216e-04 - acc: 0.0000e+00 - val_loss: 2.8092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4310e-04 - acc: 0.0000e+00 - val_loss: 1.9515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3955e-04 - acc: 0.0000e+00 - val_loss: 2.7510e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4510e-04 - acc: 0.0000e+00 - val_loss: 2.8844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4596e-04 - acc: 0.0000e+00 - val_loss: 2.4819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5197e-04 - acc: 0.0000e+00 - val_loss: 2.4457e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4812e-04 - acc: 0.0000e+00 - val_loss: 2.3604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3879e-04 - acc: 0.0000e+00 - val_loss: 1.7850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3658e-04 - acc: 0.0000e+00 - val_loss: 2.0768e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3741e-04 - acc: 0.0000e+00 - val_loss: 2.9593e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5629e-04 - acc: 0.0000e+00 - val_loss: 2.2557e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5754e-04 - acc: 0.0000e+00 - val_loss: 1.9944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2757e-04 - acc: 0.0000e+00 - val_loss: 2.2804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3443e-04 - acc: 0.0000e+00 - val_loss: 1.8129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4145e-04 - acc: 0.0000e+00 - val_loss: 1.7648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3789e-04 - acc: 0.0000e+00 - val_loss: 3.0929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4322e-04 - acc: 0.0000e+00 - val_loss: 5.8995e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3296e-04 - acc: 0.0000e+00 - val_loss: 1.7357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2907e-04 - acc: 0.0000e+00 - val_loss: 1.9288e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2637e-04 - acc: 0.0000e+00 - val_loss: 2.2969e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3505e-04 - acc: 0.0000e+00 - val_loss: 1.7779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2286e-04 - acc: 0.0000e+00 - val_loss: 1.9032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3533e-04 - acc: 0.0000e+00 - val_loss: 3.6319e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3468e-04 - acc: 0.0000e+00 - val_loss: 3.9971e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2715e-04 - acc: 0.0000e+00 - val_loss: 3.1400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4353e-04 - acc: 0.0000e+00 - val_loss: 3.3600e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2772e-04 - acc: 0.0000e+00 - val_loss: 2.1673e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3437e-04 - acc: 0.0000e+00 - val_loss: 3.5086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3030e-04 - acc: 0.0000e+00 - val_loss: 1.7212e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2405e-04 - acc: 0.0000e+00 - val_loss: 1.8532e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2132e-04 - acc: 0.0000e+00 - val_loss: 1.5348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1552e-04 - acc: 0.0000e+00 - val_loss: 1.6766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1451e-04 - acc: 0.0000e+00 - val_loss: 1.7817e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1936e-04 - acc: 0.0000e+00 - val_loss: 1.7408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2370e-04 - acc: 0.0000e+00 - val_loss: 1.5738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1756e-04 - acc: 0.0000e+00 - val_loss: 1.7293e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2459e-04 - acc: 0.0000e+00 - val_loss: 3.7088e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2877e-04 - acc: 0.0000e+00 - val_loss: 3.3771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1495e-04 - acc: 0.0000e+00 - val_loss: 3.1040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1601e-04 - acc: 0.0000e+00 - val_loss: 1.8384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1692e-04 - acc: 0.0000e+00 - val_loss: 1.8424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0721e-04 - acc: 0.0000e+00 - val_loss: 1.9633e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1054e-04 - acc: 0.0000e+00 - val_loss: 2.3135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0588e-04 - acc: 0.0000e+00 - val_loss: 1.8488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0353e-04 - acc: 0.0000e+00 - val_loss: 2.2807e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0941e-04 - acc: 0.0000e+00 - val_loss: 1.5074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1118e-04 - acc: 0.0000e+00 - val_loss: 1.5970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0155e-04 - acc: 0.0000e+00 - val_loss: 1.4412e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4178e-05 - acc: 0.0000e+00 - val_loss: 1.4362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0368e-04 - acc: 0.0000e+00 - val_loss: 1.4380e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4621e-05 - acc: 0.0000e+00 - val_loss: 3.2962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7291e-05 - acc: 0.0000e+00 - val_loss: 3.5430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1066e-04 - acc: 0.0000e+00 - val_loss: 1.5532e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2600e-05 - acc: 0.0000e+00 - val_loss: 1.7726e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9959e-05 - acc: 0.0000e+00 - val_loss: 1.9204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4024e-05 - acc: 0.0000e+00 - val_loss: 1.4287e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3301e-05 - acc: 0.0000e+00 - val_loss: 1.3879e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00177 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 22, 64)            17664     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 22, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 52,801\n",
      "Trainable params: 52,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0165e-04 - acc: 0.0000e+00 - val_loss: 8.2970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.7721e-04 - acc: 0.0000e+00 - val_loss: 7.6723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.8068e-04 - acc: 0.0000e+00 - val_loss: 7.3129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3887e-04 - acc: 0.0000e+00 - val_loss: 2.6333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9935e-04 - acc: 0.0000e+00 - val_loss: 2.4566e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0403e-04 - acc: 0.0000e+00 - val_loss: 3.4284e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8217e-04 - acc: 0.0000e+00 - val_loss: 3.3037e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.9463e-04 - acc: 0.0000e+00 - val_loss: 2.3828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8308e-04 - acc: 0.0000e+00 - val_loss: 3.0253e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8285e-04 - acc: 0.0000e+00 - val_loss: 2.8349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8349e-04 - acc: 0.0000e+00 - val_loss: 4.1486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6737e-04 - acc: 0.0000e+00 - val_loss: 3.7957e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7332e-04 - acc: 0.0000e+00 - val_loss: 2.8277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6216e-04 - acc: 0.0000e+00 - val_loss: 2.3721e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7225e-04 - acc: 0.0000e+00 - val_loss: 2.7439e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6864e-04 - acc: 0.0000e+00 - val_loss: 2.0275e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6925e-04 - acc: 0.0000e+00 - val_loss: 4.0249e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6630e-04 - acc: 0.0000e+00 - val_loss: 2.1992e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7049e-04 - acc: 0.0000e+00 - val_loss: 2.4559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6008e-04 - acc: 0.0000e+00 - val_loss: 3.3924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5873e-04 - acc: 0.0000e+00 - val_loss: 1.9231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5198e-04 - acc: 0.0000e+00 - val_loss: 3.9207e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6206e-04 - acc: 0.0000e+00 - val_loss: 1.8952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5761e-04 - acc: 0.0000e+00 - val_loss: 1.9089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4740e-04 - acc: 0.0000e+00 - val_loss: 2.1694e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4532e-04 - acc: 0.0000e+00 - val_loss: 2.1952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4907e-04 - acc: 0.0000e+00 - val_loss: 3.6601e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5727e-04 - acc: 0.0000e+00 - val_loss: 1.7864e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6226e-04 - acc: 0.0000e+00 - val_loss: 4.0328e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4268e-04 - acc: 0.0000e+00 - val_loss: 4.0546e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3835e-04 - acc: 0.0000e+00 - val_loss: 2.0555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4690e-04 - acc: 0.0000e+00 - val_loss: 1.7280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3294e-04 - acc: 0.0000e+00 - val_loss: 1.7233e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5111e-04 - acc: 0.0000e+00 - val_loss: 3.2609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4745e-04 - acc: 0.0000e+00 - val_loss: 4.2219e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4084e-04 - acc: 0.0000e+00 - val_loss: 2.0300e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3696e-04 - acc: 0.0000e+00 - val_loss: 1.7031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3157e-04 - acc: 0.0000e+00 - val_loss: 1.9916e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3233e-04 - acc: 0.0000e+00 - val_loss: 2.1978e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3340e-04 - acc: 0.0000e+00 - val_loss: 2.3406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3796e-04 - acc: 0.0000e+00 - val_loss: 3.0887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4475e-04 - acc: 0.0000e+00 - val_loss: 2.6176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3613e-04 - acc: 0.0000e+00 - val_loss: 3.5597e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3672e-04 - acc: 0.0000e+00 - val_loss: 3.5454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2905e-04 - acc: 0.0000e+00 - val_loss: 1.7676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4060e-04 - acc: 0.0000e+00 - val_loss: 1.6176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3328e-04 - acc: 0.0000e+00 - val_loss: 4.9908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1766e-04 - acc: 0.0000e+00 - val_loss: 1.6788e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1982e-04 - acc: 0.0000e+00 - val_loss: 2.2569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0611e-04 - acc: 0.0000e+00 - val_loss: 2.4419e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0941e-04 - acc: 0.0000e+00 - val_loss: 2.2179e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1105e-04 - acc: 0.0000e+00 - val_loss: 1.5933e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1352e-04 - acc: 0.0000e+00 - val_loss: 4.8780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1338e-04 - acc: 0.0000e+00 - val_loss: 2.2228e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1819e-04 - acc: 0.0000e+00 - val_loss: 6.5505e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1412e-04 - acc: 0.0000e+00 - val_loss: 3.1636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0838e-04 - acc: 0.0000e+00 - val_loss: 1.6188e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0664e-04 - acc: 0.0000e+00 - val_loss: 2.4612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0956e-04 - acc: 0.0000e+00 - val_loss: 1.8218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0582e-04 - acc: 0.0000e+00 - val_loss: 1.7021e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0480e-04 - acc: 0.0000e+00 - val_loss: 1.4567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0443e-04 - acc: 0.0000e+00 - val_loss: 2.3643e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0482e-04 - acc: 0.0000e+00 - val_loss: 2.0244e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5602e-05 - acc: 0.0000e+00 - val_loss: 1.7169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7371e-05 - acc: 0.0000e+00 - val_loss: 1.4162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0320e-04 - acc: 0.0000e+00 - val_loss: 1.4840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6087e-05 - acc: 0.0000e+00 - val_loss: 3.9798e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2435e-05 - acc: 0.0000e+00 - val_loss: 1.5709e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5935e-05 - acc: 0.0000e+00 - val_loss: 2.3722e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1369e-04 - acc: 0.0000e+00 - val_loss: 6.1083e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8962e-05 - acc: 0.0000e+00 - val_loss: 4.6924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6212e-05 - acc: 0.0000e+00 - val_loss: 2.6261e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4726e-05 - acc: 0.0000e+00 - val_loss: 1.4454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2757e-05 - acc: 0.0000e+00 - val_loss: 1.4044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3207e-05 - acc: 0.0000e+00 - val_loss: 4.2748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5406e-05 - acc: 0.0000e+00 - val_loss: 1.4677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3313e-05 - acc: 0.0000e+00 - val_loss: 1.4022e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7492e-05 - acc: 0.0000e+00 - val_loss: 3.0055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9549e-05 - acc: 0.0000e+00 - val_loss: 1.4027e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7814e-05 - acc: 0.0000e+00 - val_loss: 1.5432e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8402e-05 - acc: 0.0000e+00 - val_loss: 1.5542e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4894e-05 - acc: 0.0000e+00 - val_loss: 3.0311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7918e-05 - acc: 0.0000e+00 - val_loss: 1.7926e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6159e-05 - acc: 0.0000e+00 - val_loss: 1.4333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6418e-05 - acc: 0.0000e+00 - val_loss: 1.5161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5919e-05 - acc: 0.0000e+00 - val_loss: 1.7120e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5666e-05 - acc: 0.0000e+00 - val_loss: 1.6153e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4419e-05 - acc: 0.0000e+00 - val_loss: 1.3607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3003e-05 - acc: 0.0000e+00 - val_loss: 1.6121e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00138 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 22, 64)            17664     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,913\n",
      "Trainable params: 54,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 7.6493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1870e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 3.2406e-04 - acc: 0.0000e+00 - val_loss: 8.7555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.5841e-04 - acc: 0.0000e+00 - val_loss: 4.5806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3539e-04 - acc: 0.0000e+00 - val_loss: 3.8046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.1862e-04 - acc: 0.0000e+00 - val_loss: 2.8976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.0569e-04 - acc: 0.0000e+00 - val_loss: 2.7522e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8941e-04 - acc: 0.0000e+00 - val_loss: 2.5996e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.8259e-04 - acc: 0.0000e+00 - val_loss: 2.8500e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7568e-04 - acc: 0.0000e+00 - val_loss: 2.4485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7467e-04 - acc: 0.0000e+00 - val_loss: 2.2767e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6192e-04 - acc: 0.0000e+00 - val_loss: 2.2818e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7912e-04 - acc: 0.0000e+00 - val_loss: 3.0594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.7072e-04 - acc: 0.0000e+00 - val_loss: 3.2454e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5923e-04 - acc: 0.0000e+00 - val_loss: 2.2892e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5762e-04 - acc: 0.0000e+00 - val_loss: 2.4994e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5353e-04 - acc: 0.0000e+00 - val_loss: 5.3604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5253e-04 - acc: 0.0000e+00 - val_loss: 2.1351e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4118e-04 - acc: 0.0000e+00 - val_loss: 2.1671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4606e-04 - acc: 0.0000e+00 - val_loss: 2.3224e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4970e-04 - acc: 0.0000e+00 - val_loss: 2.0434e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4506e-04 - acc: 0.0000e+00 - val_loss: 3.2599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4201e-04 - acc: 0.0000e+00 - val_loss: 2.0185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3931e-04 - acc: 0.0000e+00 - val_loss: 2.2374e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4450e-04 - acc: 0.0000e+00 - val_loss: 2.5359e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3178e-04 - acc: 0.0000e+00 - val_loss: 1.9632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3041e-04 - acc: 0.0000e+00 - val_loss: 1.9674e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2723e-04 - acc: 0.0000e+00 - val_loss: 2.2081e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3133e-04 - acc: 0.0000e+00 - val_loss: 3.2289e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3373e-04 - acc: 0.0000e+00 - val_loss: 2.2305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2955e-04 - acc: 0.0000e+00 - val_loss: 1.9149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2329e-04 - acc: 0.0000e+00 - val_loss: 2.8650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4788e-04 - acc: 0.0000e+00 - val_loss: 2.1054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3056e-04 - acc: 0.0000e+00 - val_loss: 2.0794e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1670e-04 - acc: 0.0000e+00 - val_loss: 2.1426e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2510e-04 - acc: 0.0000e+00 - val_loss: 2.3832e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3198e-04 - acc: 0.0000e+00 - val_loss: 2.6084e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2277e-04 - acc: 0.0000e+00 - val_loss: 1.7984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1547e-04 - acc: 0.0000e+00 - val_loss: 1.9252e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1456e-04 - acc: 0.0000e+00 - val_loss: 2.1058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0897e-04 - acc: 0.0000e+00 - val_loss: 1.9886e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1372e-04 - acc: 0.0000e+00 - val_loss: 3.1545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2244e-04 - acc: 0.0000e+00 - val_loss: 1.8304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0779e-04 - acc: 0.0000e+00 - val_loss: 1.8690e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0383e-04 - acc: 0.0000e+00 - val_loss: 1.7989e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0365e-04 - acc: 0.0000e+00 - val_loss: 1.7738e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9621e-05 - acc: 0.0000e+00 - val_loss: 2.4415e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1287e-04 - acc: 0.0000e+00 - val_loss: 1.7203e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0126e-04 - acc: 0.0000e+00 - val_loss: 1.8039e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4142e-05 - acc: 0.0000e+00 - val_loss: 1.6777e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0252e-04 - acc: 0.0000e+00 - val_loss: 1.6583e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6325e-05 - acc: 0.0000e+00 - val_loss: 1.9728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0733e-04 - acc: 0.0000e+00 - val_loss: 1.8468e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1328e-05 - acc: 0.0000e+00 - val_loss: 1.6565e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0119e-04 - acc: 0.0000e+00 - val_loss: 2.8045e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4479e-05 - acc: 0.0000e+00 - val_loss: 1.6905e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6434e-05 - acc: 0.0000e+00 - val_loss: 2.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5829e-05 - acc: 0.0000e+00 - val_loss: 3.5569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8612e-05 - acc: 0.0000e+00 - val_loss: 1.6402e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7552e-05 - acc: 0.0000e+00 - val_loss: 3.3322e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9838e-05 - acc: 0.0000e+00 - val_loss: 2.6305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7704e-05 - acc: 0.0000e+00 - val_loss: 1.7996e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2530e-05 - acc: 0.0000e+00 - val_loss: 1.9366e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8412e-05 - acc: 0.0000e+00 - val_loss: 2.1357e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9956e-05 - acc: 0.0000e+00 - val_loss: 3.8152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1437e-05 - acc: 0.0000e+00 - val_loss: 1.6025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6889e-05 - acc: 0.0000e+00 - val_loss: 1.8163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8690e-05 - acc: 0.0000e+00 - val_loss: 1.5278e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9613e-05 - acc: 0.0000e+00 - val_loss: 2.7162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5427e-05 - acc: 0.0000e+00 - val_loss: 1.8852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2462e-05 - acc: 0.0000e+00 - val_loss: 1.6141e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8553e-05 - acc: 0.0000e+00 - val_loss: 1.4941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7627e-05 - acc: 0.0000e+00 - val_loss: 2.2867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4349e-05 - acc: 0.0000e+00 - val_loss: 3.2484e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5879e-05 - acc: 0.0000e+00 - val_loss: 2.2411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6685e-05 - acc: 0.0000e+00 - val_loss: 3.4162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3943e-05 - acc: 0.0000e+00 - val_loss: 1.4585e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2147e-05 - acc: 0.0000e+00 - val_loss: 3.3074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3522e-05 - acc: 0.0000e+00 - val_loss: 1.6361e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3981e-05 - acc: 0.0000e+00 - val_loss: 2.8698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9285e-05 - acc: 0.0000e+00 - val_loss: 2.5161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6671e-05 - acc: 0.0000e+00 - val_loss: 3.2597e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2722e-05 - acc: 0.0000e+00 - val_loss: 1.4449e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8358e-05 - acc: 0.0000e+00 - val_loss: 1.6838e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8868e-05 - acc: 0.0000e+00 - val_loss: 2.6274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7294e-05 - acc: 0.0000e+00 - val_loss: 1.5343e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9974e-05 - acc: 0.0000e+00 - val_loss: 1.4106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0446e-05 - acc: 0.0000e+00 - val_loss: 1.5149e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7856e-05 - acc: 0.0000e+00 - val_loss: 2.3106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.3477e-05 - acc: 0.0000e+00 - val_loss: 1.4003e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00038 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 201,761\n",
      "Trainable params: 201,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0135e-04 - acc: 0.0000e+00 - val_loss: 7.9778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.2988e-04 - acc: 0.0000e+00 - val_loss: 4.0974e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5909e-04 - acc: 0.0000e+00 - val_loss: 2.7059e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6150e-04 - acc: 0.0000e+00 - val_loss: 2.8499e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4205e-04 - acc: 0.0000e+00 - val_loss: 2.7307e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3622e-04 - acc: 0.0000e+00 - val_loss: 2.6169e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3439e-04 - acc: 0.0000e+00 - val_loss: 3.6463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3161e-04 - acc: 0.0000e+00 - val_loss: 3.2192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2638e-04 - acc: 0.0000e+00 - val_loss: 2.4598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3444e-04 - acc: 0.0000e+00 - val_loss: 2.5040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.5538e-04 - acc: 0.0000e+00 - val_loss: 2.6858e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2431e-04 - acc: 0.0000e+00 - val_loss: 2.9642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2674e-04 - acc: 0.0000e+00 - val_loss: 2.2718e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2662e-04 - acc: 0.0000e+00 - val_loss: 2.3571e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1523e-04 - acc: 0.0000e+00 - val_loss: 3.5211e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1906e-04 - acc: 0.0000e+00 - val_loss: 2.3659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1073e-04 - acc: 0.0000e+00 - val_loss: 2.4160e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3022e-04 - acc: 0.0000e+00 - val_loss: 5.2010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1976e-04 - acc: 0.0000e+00 - val_loss: 2.2919e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2578e-04 - acc: 0.0000e+00 - val_loss: 1.9875e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1479e-04 - acc: 0.0000e+00 - val_loss: 5.4671e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2771e-04 - acc: 0.0000e+00 - val_loss: 2.2813e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1064e-04 - acc: 0.0000e+00 - val_loss: 2.1403e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1562e-04 - acc: 0.0000e+00 - val_loss: 4.6397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1513e-04 - acc: 0.0000e+00 - val_loss: 2.0225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1052e-04 - acc: 0.0000e+00 - val_loss: 2.1024e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2012e-04 - acc: 0.0000e+00 - val_loss: 3.0166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3098e-04 - acc: 0.0000e+00 - val_loss: 2.8126e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0054e-04 - acc: 0.0000e+00 - val_loss: 1.8434e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0663e-04 - acc: 0.0000e+00 - val_loss: 1.9666e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0971e-04 - acc: 0.0000e+00 - val_loss: 4.8166e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0433e-04 - acc: 0.0000e+00 - val_loss: 1.7781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0173e-04 - acc: 0.0000e+00 - val_loss: 1.7939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0078e-04 - acc: 0.0000e+00 - val_loss: 3.4770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0440e-04 - acc: 0.0000e+00 - val_loss: 1.7856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9727e-05 - acc: 0.0000e+00 - val_loss: 2.0045e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8596e-05 - acc: 0.0000e+00 - val_loss: 2.6811e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3717e-05 - acc: 0.0000e+00 - val_loss: 1.8528e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.5726e-05 - acc: 0.0000e+00 - val_loss: 1.7148e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3957e-05 - acc: 0.0000e+00 - val_loss: 1.9260e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9433e-05 - acc: 0.0000e+00 - val_loss: 2.8541e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1211e-04 - acc: 0.0000e+00 - val_loss: 1.7728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8419e-05 - acc: 0.0000e+00 - val_loss: 1.8370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9244e-05 - acc: 0.0000e+00 - val_loss: 1.6803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8887e-05 - acc: 0.0000e+00 - val_loss: 2.5497e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0554e-04 - acc: 0.0000e+00 - val_loss: 8.6904e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0222e-04 - acc: 0.0000e+00 - val_loss: 1.5651e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9952e-05 - acc: 0.0000e+00 - val_loss: 2.0667e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9617e-05 - acc: 0.0000e+00 - val_loss: 3.3641e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0052e-04 - acc: 0.0000e+00 - val_loss: 3.1608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7289e-05 - acc: 0.0000e+00 - val_loss: 2.0358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9652e-05 - acc: 0.0000e+00 - val_loss: 3.1544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7613e-05 - acc: 0.0000e+00 - val_loss: 1.7070e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0939e-05 - acc: 0.0000e+00 - val_loss: 1.4660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8302e-05 - acc: 0.0000e+00 - val_loss: 1.4959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2394e-05 - acc: 0.0000e+00 - val_loss: 2.2587e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5878e-05 - acc: 0.0000e+00 - val_loss: 1.4417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0366e-05 - acc: 0.0000e+00 - val_loss: 1.3990e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9234e-05 - acc: 0.0000e+00 - val_loss: 5.4526e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0924e-04 - acc: 0.0000e+00 - val_loss: 1.6160e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3049e-05 - acc: 0.0000e+00 - val_loss: 1.5958e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7156e-05 - acc: 0.0000e+00 - val_loss: 1.4954e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4683e-05 - acc: 0.0000e+00 - val_loss: 1.3376e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5895e-05 - acc: 0.0000e+00 - val_loss: 1.3590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2361e-05 - acc: 0.0000e+00 - val_loss: 3.2972e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3841e-05 - acc: 0.0000e+00 - val_loss: 1.5102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6869e-05 - acc: 0.0000e+00 - val_loss: 1.3101e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9675e-05 - acc: 0.0000e+00 - val_loss: 2.9063e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3225e-05 - acc: 0.0000e+00 - val_loss: 1.6304e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.9093e-05 - acc: 0.0000e+00 - val_loss: 1.5105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5507e-05 - acc: 0.0000e+00 - val_loss: 1.2687e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8855e-05 - acc: 0.0000e+00 - val_loss: 1.4716e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5875e-05 - acc: 0.0000e+00 - val_loss: 1.2970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9661e-05 - acc: 0.0000e+00 - val_loss: 2.9140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0714e-05 - acc: 0.0000e+00 - val_loss: 1.5282e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8692e-05 - acc: 0.0000e+00 - val_loss: 3.0283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7298e-05 - acc: 0.0000e+00 - val_loss: 1.2766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7579e-05 - acc: 0.0000e+00 - val_loss: 1.2711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8256e-05 - acc: 0.0000e+00 - val_loss: 1.3092e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2849e-05 - acc: 0.0000e+00 - val_loss: 1.2915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0962e-05 - acc: 0.0000e+00 - val_loss: 1.8090e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0272e-05 - acc: 0.0000e+00 - val_loss: 2.5761e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1490e-05 - acc: 0.0000e+00 - val_loss: 2.3482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4252e-05 - acc: 0.0000e+00 - val_loss: 1.9887e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6815e-05 - acc: 0.0000e+00 - val_loss: 1.7044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1103e-05 - acc: 0.0000e+00 - val_loss: 1.1659e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3005e-05 - acc: 0.0000e+00 - val_loss: 1.1951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6756e-05 - acc: 0.0000e+00 - val_loss: 1.7315e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5129e-05 - acc: 0.0000e+00 - val_loss: 1.2389e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00177 MSE (0.04 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4685e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.3079e-04 - acc: 0.0000e+00 - val_loss: 4.8296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4901e-04 - acc: 0.0000e+00 - val_loss: 3.1693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4651e-04 - acc: 0.0000e+00 - val_loss: 3.4361e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4371e-04 - acc: 0.0000e+00 - val_loss: 4.0962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3268e-04 - acc: 0.0000e+00 - val_loss: 2.8050e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2866e-04 - acc: 0.0000e+00 - val_loss: 2.2919e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2785e-04 - acc: 0.0000e+00 - val_loss: 3.1446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2105e-04 - acc: 0.0000e+00 - val_loss: 2.3474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1481e-04 - acc: 0.0000e+00 - val_loss: 2.2996e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2460e-04 - acc: 0.0000e+00 - val_loss: 2.5498e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1191e-04 - acc: 0.0000e+00 - val_loss: 2.2189e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0823e-04 - acc: 0.0000e+00 - val_loss: 2.1247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2236e-04 - acc: 0.0000e+00 - val_loss: 3.5636e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1671e-04 - acc: 0.0000e+00 - val_loss: 2.0682e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1988e-04 - acc: 0.0000e+00 - val_loss: 2.1105e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1019e-04 - acc: 0.0000e+00 - val_loss: 2.2230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2445e-04 - acc: 0.0000e+00 - val_loss: 3.1447e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3697e-04 - acc: 0.0000e+00 - val_loss: 9.0660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4049e-04 - acc: 0.0000e+00 - val_loss: 2.6466e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0399e-04 - acc: 0.0000e+00 - val_loss: 2.2812e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1088e-04 - acc: 0.0000e+00 - val_loss: 2.5135e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8831e-05 - acc: 0.0000e+00 - val_loss: 1.9055e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7984e-05 - acc: 0.0000e+00 - val_loss: 2.5349e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0425e-04 - acc: 0.0000e+00 - val_loss: 3.5400e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9999e-05 - acc: 0.0000e+00 - val_loss: 2.4460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4188e-05 - acc: 0.0000e+00 - val_loss: 1.8002e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0128e-04 - acc: 0.0000e+00 - val_loss: 2.4929e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3605e-05 - acc: 0.0000e+00 - val_loss: 3.5280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0502e-04 - acc: 0.0000e+00 - val_loss: 1.9450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0064e-04 - acc: 0.0000e+00 - val_loss: 5.6009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1432e-04 - acc: 0.0000e+00 - val_loss: 1.7679e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2862e-05 - acc: 0.0000e+00 - val_loss: 1.7638e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8320e-05 - acc: 0.0000e+00 - val_loss: 6.0299e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0669e-04 - acc: 0.0000e+00 - val_loss: 1.6939e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4543e-05 - acc: 0.0000e+00 - val_loss: 2.0192e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0118e-04 - acc: 0.0000e+00 - val_loss: 2.3486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5330e-05 - acc: 0.0000e+00 - val_loss: 1.6804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2218e-05 - acc: 0.0000e+00 - val_loss: 1.8588e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0036e-04 - acc: 0.0000e+00 - val_loss: 2.4266e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.8635e-05 - acc: 0.0000e+00 - val_loss: 1.5695e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3445e-05 - acc: 0.0000e+00 - val_loss: 1.5683e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4116e-05 - acc: 0.0000e+00 - val_loss: 1.5286e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4973e-05 - acc: 0.0000e+00 - val_loss: 1.5757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8143e-05 - acc: 0.0000e+00 - val_loss: 2.6552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6381e-05 - acc: 0.0000e+00 - val_loss: 1.6570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0738e-04 - acc: 0.0000e+00 - val_loss: 2.0487e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9032e-05 - acc: 0.0000e+00 - val_loss: 1.4960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2504e-05 - acc: 0.0000e+00 - val_loss: 2.9658e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5187e-05 - acc: 0.0000e+00 - val_loss: 1.9009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6104e-05 - acc: 0.0000e+00 - val_loss: 1.5197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6806e-05 - acc: 0.0000e+00 - val_loss: 1.5614e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6898e-05 - acc: 0.0000e+00 - val_loss: 1.9437e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6926e-05 - acc: 0.0000e+00 - val_loss: 1.8327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0379e-04 - acc: 0.0000e+00 - val_loss: 1.4271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3747e-05 - acc: 0.0000e+00 - val_loss: 1.6740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2297e-05 - acc: 0.0000e+00 - val_loss: 2.3617e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4170e-05 - acc: 0.0000e+00 - val_loss: 1.4652e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2720e-05 - acc: 0.0000e+00 - val_loss: 1.3791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3972e-05 - acc: 0.0000e+00 - val_loss: 1.6514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3344e-05 - acc: 0.0000e+00 - val_loss: 3.4760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1770e-05 - acc: 0.0000e+00 - val_loss: 1.5910e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7348e-05 - acc: 0.0000e+00 - val_loss: 1.3755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5690e-05 - acc: 0.0000e+00 - val_loss: 2.0227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4634e-05 - acc: 0.0000e+00 - val_loss: 3.2888e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2604e-05 - acc: 0.0000e+00 - val_loss: 2.7122e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6580e-05 - acc: 0.0000e+00 - val_loss: 2.4608e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.8147e-05 - acc: 0.0000e+00 - val_loss: 2.0378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4151e-05 - acc: 0.0000e+00 - val_loss: 1.6642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2906e-05 - acc: 0.0000e+00 - val_loss: 1.3460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1060e-05 - acc: 0.0000e+00 - val_loss: 1.6483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2112e-05 - acc: 0.0000e+00 - val_loss: 2.2681e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2737e-05 - acc: 0.0000e+00 - val_loss: 1.8742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2589e-05 - acc: 0.0000e+00 - val_loss: 1.3082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4040e-05 - acc: 0.0000e+00 - val_loss: 1.2492e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6149e-05 - acc: 0.0000e+00 - val_loss: 1.3526e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4875e-05 - acc: 0.0000e+00 - val_loss: 2.4930e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7066e-05 - acc: 0.0000e+00 - val_loss: 1.5552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.4858e-05 - acc: 0.0000e+00 - val_loss: 1.5645e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7532e-05 - acc: 0.0000e+00 - val_loss: 1.1672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3302e-05 - acc: 0.0000e+00 - val_loss: 1.7040e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5768e-05 - acc: 0.0000e+00 - val_loss: 1.4459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.3349e-05 - acc: 0.0000e+00 - val_loss: 1.2094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0339e-05 - acc: 0.0000e+00 - val_loss: 1.2544e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0084e-05 - acc: 0.0000e+00 - val_loss: 1.3450e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4950e-05 - acc: 0.0000e+00 - val_loss: 2.5771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4149e-05 - acc: 0.0000e+00 - val_loss: 1.1225e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.1039e-05 - acc: 0.0000e+00 - val_loss: 1.3706e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8161e-05 - acc: 0.0000e+00 - val_loss: 1.4752e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00004 MSE (0.01 RMSE)\n",
      "Test Score: 0.00058 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 208,001\n",
      "Trainable params: 208,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 3s - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 1s - loss: 5.3170e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 1s - loss: 2.4575e-04 - acc: 0.0000e+00 - val_loss: 7.3277e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.6794e-04 - acc: 0.0000e+00 - val_loss: 3.8844e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.4654e-04 - acc: 0.0000e+00 - val_loss: 3.0690e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.3218e-04 - acc: 0.0000e+00 - val_loss: 2.6919e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2376e-04 - acc: 0.0000e+00 - val_loss: 4.8150e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.2782e-04 - acc: 0.0000e+00 - val_loss: 2.5125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1812e-04 - acc: 0.0000e+00 - val_loss: 2.2962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1712e-04 - acc: 0.0000e+00 - val_loss: 2.5547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1125e-04 - acc: 0.0000e+00 - val_loss: 2.1821e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0734e-04 - acc: 0.0000e+00 - val_loss: 2.6543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0973e-04 - acc: 0.0000e+00 - val_loss: 2.5447e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0790e-04 - acc: 0.0000e+00 - val_loss: 2.3483e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1635e-04 - acc: 0.0000e+00 - val_loss: 3.1654e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.1173e-04 - acc: 0.0000e+00 - val_loss: 2.5463e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0314e-04 - acc: 0.0000e+00 - val_loss: 2.2820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8267e-05 - acc: 0.0000e+00 - val_loss: 2.6831e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0017e-04 - acc: 0.0000e+00 - val_loss: 2.5274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0263e-04 - acc: 0.0000e+00 - val_loss: 1.9952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6244e-05 - acc: 0.0000e+00 - val_loss: 3.9944e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0117e-04 - acc: 0.0000e+00 - val_loss: 3.7485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9505e-05 - acc: 0.0000e+00 - val_loss: 2.2896e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9569e-05 - acc: 0.0000e+00 - val_loss: 3.4030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0822e-04 - acc: 0.0000e+00 - val_loss: 4.0790e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0860e-04 - acc: 0.0000e+00 - val_loss: 1.9156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0410e-04 - acc: 0.0000e+00 - val_loss: 2.0479e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0539e-04 - acc: 0.0000e+00 - val_loss: 4.8511e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0613e-04 - acc: 0.0000e+00 - val_loss: 2.3689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6721e-05 - acc: 0.0000e+00 - val_loss: 2.4239e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.4572e-05 - acc: 0.0000e+00 - val_loss: 2.5441e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.6483e-05 - acc: 0.0000e+00 - val_loss: 1.7625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.7408e-05 - acc: 0.0000e+00 - val_loss: 1.8031e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0514e-04 - acc: 0.0000e+00 - val_loss: 2.8330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0244e-04 - acc: 0.0000e+00 - val_loss: 2.0231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2074e-05 - acc: 0.0000e+00 - val_loss: 4.2372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3310e-05 - acc: 0.0000e+00 - val_loss: 2.0393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2361e-05 - acc: 0.0000e+00 - val_loss: 2.0808e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5475e-05 - acc: 0.0000e+00 - val_loss: 1.6378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.9638e-05 - acc: 0.0000e+00 - val_loss: 1.7345e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.2546e-05 - acc: 0.0000e+00 - val_loss: 5.1234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.8866e-05 - acc: 0.0000e+00 - val_loss: 1.6806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7333e-05 - acc: 0.0000e+00 - val_loss: 1.5935e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.5070e-05 - acc: 0.0000e+00 - val_loss: 1.7870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0402e-04 - acc: 0.0000e+00 - val_loss: 1.6310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2837e-05 - acc: 0.0000e+00 - val_loss: 2.0760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.6093e-05 - acc: 0.0000e+00 - val_loss: 1.7476e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.1053e-05 - acc: 0.0000e+00 - val_loss: 2.3940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.3303e-05 - acc: 0.0000e+00 - val_loss: 2.1411e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.9595e-05 - acc: 0.0000e+00 - val_loss: 1.7173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 1s - loss: 1.0123e-04 - acc: 0.0000e+00 - val_loss: 1.4850e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3607e-05 - acc: 0.0000e+00 - val_loss: 2.6273e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4974e-05 - acc: 0.0000e+00 - val_loss: 2.7776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 1s - loss: 9.0545e-05 - acc: 0.0000e+00 - val_loss: 2.4902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.3915e-05 - acc: 0.0000e+00 - val_loss: 1.4514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2979e-05 - acc: 0.0000e+00 - val_loss: 1.6482e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.4259e-05 - acc: 0.0000e+00 - val_loss: 1.7087e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5439e-05 - acc: 0.0000e+00 - val_loss: 1.3558e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.2382e-05 - acc: 0.0000e+00 - val_loss: 3.6089e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7982e-05 - acc: 0.0000e+00 - val_loss: 2.9310e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6975e-05 - acc: 0.0000e+00 - val_loss: 1.8401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7190e-05 - acc: 0.0000e+00 - val_loss: 1.7782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.5438e-05 - acc: 0.0000e+00 - val_loss: 1.5962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1334e-05 - acc: 0.0000e+00 - val_loss: 2.3654e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.2133e-05 - acc: 0.0000e+00 - val_loss: 1.3777e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7748e-05 - acc: 0.0000e+00 - val_loss: 1.9043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.1454e-05 - acc: 0.0000e+00 - val_loss: 1.7700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.0152e-05 - acc: 0.0000e+00 - val_loss: 1.4367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7906e-05 - acc: 0.0000e+00 - val_loss: 1.5113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.7129e-05 - acc: 0.0000e+00 - val_loss: 1.4507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 1s - loss: 7.6346e-05 - acc: 0.0000e+00 - val_loss: 2.3820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8821e-05 - acc: 0.0000e+00 - val_loss: 1.4567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6241e-05 - acc: 0.0000e+00 - val_loss: 2.9517e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.7688e-05 - acc: 0.0000e+00 - val_loss: 1.5904e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 1s - loss: 8.0465e-05 - acc: 0.0000e+00 - val_loss: 1.4471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8593e-05 - acc: 0.0000e+00 - val_loss: 2.0261e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9944e-05 - acc: 0.0000e+00 - val_loss: 1.4383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5650e-05 - acc: 0.0000e+00 - val_loss: 1.8689e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4978e-05 - acc: 0.0000e+00 - val_loss: 1.2999e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5564e-05 - acc: 0.0000e+00 - val_loss: 1.1914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.2767e-05 - acc: 0.0000e+00 - val_loss: 1.4582e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5553e-05 - acc: 0.0000e+00 - val_loss: 1.1507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7178e-05 - acc: 0.0000e+00 - val_loss: 1.2124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6201e-05 - acc: 0.0000e+00 - val_loss: 2.4094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.9020e-05 - acc: 0.0000e+00 - val_loss: 1.2595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.6232e-05 - acc: 0.0000e+00 - val_loss: 1.9633e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.4495e-05 - acc: 0.0000e+00 - val_loss: 1.1766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.8396e-05 - acc: 0.0000e+00 - val_loss: 1.3237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.7739e-05 - acc: 0.0000e+00 - val_loss: 3.2675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 1s - loss: 6.5728e-05 - acc: 0.0000e+00 - val_loss: 1.2978e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00051 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 796,705\n",
      "Trainable params: 796,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.3310e-04 - acc: 0.0000e+00 - val_loss: 6.3033e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.3745e-04 - acc: 0.0000e+00 - val_loss: 2.9478e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0845e-04 - acc: 0.0000e+00 - val_loss: 2.6393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.8539e-05 - acc: 0.0000e+00 - val_loss: 2.8786e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0005e-04 - acc: 0.0000e+00 - val_loss: 3.8208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0627e-04 - acc: 0.0000e+00 - val_loss: 2.9814e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3142e-05 - acc: 0.0000e+00 - val_loss: 2.4569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0297e-04 - acc: 0.0000e+00 - val_loss: 8.0937e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1450e-04 - acc: 0.0000e+00 - val_loss: 2.9584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.7232e-05 - acc: 0.0000e+00 - val_loss: 3.6543e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0030e-04 - acc: 0.0000e+00 - val_loss: 2.7120e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4092e-05 - acc: 0.0000e+00 - val_loss: 2.2967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4319e-05 - acc: 0.0000e+00 - val_loss: 2.2113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0924e-05 - acc: 0.0000e+00 - val_loss: 2.4672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2067e-05 - acc: 0.0000e+00 - val_loss: 2.5258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.9537e-05 - acc: 0.0000e+00 - val_loss: 2.2433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0070e-04 - acc: 0.0000e+00 - val_loss: 2.3401e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3551e-05 - acc: 0.0000e+00 - val_loss: 2.6915e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6260e-05 - acc: 0.0000e+00 - val_loss: 3.4556e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.6131e-05 - acc: 0.0000e+00 - val_loss: 2.3066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1438e-05 - acc: 0.0000e+00 - val_loss: 1.9621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6994e-05 - acc: 0.0000e+00 - val_loss: 2.9049e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0167e-04 - acc: 0.0000e+00 - val_loss: 3.0819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.5200e-04 - acc: 0.0000e+00 - val_loss: 3.5665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1190e-05 - acc: 0.0000e+00 - val_loss: 2.7108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5759e-05 - acc: 0.0000e+00 - val_loss: 1.9469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1196e-05 - acc: 0.0000e+00 - val_loss: 2.8074e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5423e-05 - acc: 0.0000e+00 - val_loss: 2.2285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8698e-05 - acc: 0.0000e+00 - val_loss: 1.8129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9218e-05 - acc: 0.0000e+00 - val_loss: 1.8054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3541e-05 - acc: 0.0000e+00 - val_loss: 2.4826e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4460e-05 - acc: 0.0000e+00 - val_loss: 2.6781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1310e-05 - acc: 0.0000e+00 - val_loss: 8.5075e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3961e-05 - acc: 0.0000e+00 - val_loss: 2.6197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8477e-05 - acc: 0.0000e+00 - val_loss: 1.7291e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5672e-05 - acc: 0.0000e+00 - val_loss: 1.9632e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5011e-05 - acc: 0.0000e+00 - val_loss: 1.6803e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4966e-05 - acc: 0.0000e+00 - val_loss: 1.5507e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1242e-05 - acc: 0.0000e+00 - val_loss: 4.5114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0893e-05 - acc: 0.0000e+00 - val_loss: 2.1917e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0144e-04 - acc: 0.0000e+00 - val_loss: 1.5423e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0315e-04 - acc: 0.0000e+00 - val_loss: 2.3157e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5310e-05 - acc: 0.0000e+00 - val_loss: 1.8406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5867e-05 - acc: 0.0000e+00 - val_loss: 1.4676e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8867e-05 - acc: 0.0000e+00 - val_loss: 1.4567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0101e-05 - acc: 0.0000e+00 - val_loss: 2.1274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0356e-05 - acc: 0.0000e+00 - val_loss: 1.5297e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0867e-05 - acc: 0.0000e+00 - val_loss: 2.0406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5659e-05 - acc: 0.0000e+00 - val_loss: 2.1243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5254e-05 - acc: 0.0000e+00 - val_loss: 1.7563e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4401e-05 - acc: 0.0000e+00 - val_loss: 1.9959e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9934e-05 - acc: 0.0000e+00 - val_loss: 1.5515e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0821e-05 - acc: 0.0000e+00 - val_loss: 1.6017e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4790e-05 - acc: 0.0000e+00 - val_loss: 1.7770e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8293e-05 - acc: 0.0000e+00 - val_loss: 1.5406e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8009e-05 - acc: 0.0000e+00 - val_loss: 5.7840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1708e-05 - acc: 0.0000e+00 - val_loss: 1.3741e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9262e-05 - acc: 0.0000e+00 - val_loss: 1.7759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5764e-05 - acc: 0.0000e+00 - val_loss: 1.8133e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4565e-05 - acc: 0.0000e+00 - val_loss: 1.2009e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4235e-05 - acc: 0.0000e+00 - val_loss: 1.3678e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7988e-05 - acc: 0.0000e+00 - val_loss: 2.6540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1905e-05 - acc: 0.0000e+00 - val_loss: 2.0152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2395e-05 - acc: 0.0000e+00 - val_loss: 5.3506e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9165e-05 - acc: 0.0000e+00 - val_loss: 1.4375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6399e-05 - acc: 0.0000e+00 - val_loss: 1.1962e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0283e-05 - acc: 0.0000e+00 - val_loss: 2.7642e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2015e-05 - acc: 0.0000e+00 - val_loss: 1.1984e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5632e-05 - acc: 0.0000e+00 - val_loss: 2.4695e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7413e-05 - acc: 0.0000e+00 - val_loss: 1.3103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8937e-05 - acc: 0.0000e+00 - val_loss: 1.1271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1963e-05 - acc: 0.0000e+00 - val_loss: 1.3947e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4133e-05 - acc: 0.0000e+00 - val_loss: 1.1294e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8761e-05 - acc: 0.0000e+00 - val_loss: 1.1375e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8949e-05 - acc: 0.0000e+00 - val_loss: 1.0669e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7898e-05 - acc: 0.0000e+00 - val_loss: 2.4619e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8353e-05 - acc: 0.0000e+00 - val_loss: 1.1384e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1247e-05 - acc: 0.0000e+00 - val_loss: 1.6741e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0448e-05 - acc: 0.0000e+00 - val_loss: 1.0701e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1989e-05 - acc: 0.0000e+00 - val_loss: 3.3952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0954e-05 - acc: 0.0000e+00 - val_loss: 1.0516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5193e-05 - acc: 0.0000e+00 - val_loss: 1.4999e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5840e-05 - acc: 0.0000e+00 - val_loss: 1.0229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9783e-05 - acc: 0.0000e+00 - val_loss: 1.0082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0107e-05 - acc: 0.0000e+00 - val_loss: 1.5523e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2912e-05 - acc: 0.0000e+00 - val_loss: 1.3979e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1143e-05 - acc: 0.0000e+00 - val_loss: 9.8613e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9673e-05 - acc: 0.0000e+00 - val_loss: 1.0354e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9925e-05 - acc: 0.0000e+00 - val_loss: 9.6869e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00071 MSE (0.03 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 800,833\n",
      "Trainable params: 800,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 3.1762e-04 - acc: 0.0000e+00 - val_loss: 6.2745e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.5307e-04 - acc: 0.0000e+00 - val_loss: 3.8348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0878e-04 - acc: 0.0000e+00 - val_loss: 2.7381e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0411e-04 - acc: 0.0000e+00 - val_loss: 2.5320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.5639e-05 - acc: 0.0000e+00 - val_loss: 2.8773e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0412e-04 - acc: 0.0000e+00 - val_loss: 2.4197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5853e-05 - acc: 0.0000e+00 - val_loss: 2.9283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5361e-05 - acc: 0.0000e+00 - val_loss: 3.1665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.9827e-05 - acc: 0.0000e+00 - val_loss: 2.1170e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.2749e-05 - acc: 0.0000e+00 - val_loss: 3.4663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6069e-05 - acc: 0.0000e+00 - val_loss: 2.1086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.1938e-05 - acc: 0.0000e+00 - val_loss: 2.0096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3655e-05 - acc: 0.0000e+00 - val_loss: 3.1467e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7304e-05 - acc: 0.0000e+00 - val_loss: 3.9102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.5494e-05 - acc: 0.0000e+00 - val_loss: 1.8815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6201e-05 - acc: 0.0000e+00 - val_loss: 2.9243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7635e-05 - acc: 0.0000e+00 - val_loss: 1.8097e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1000e-05 - acc: 0.0000e+00 - val_loss: 2.0198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7215e-05 - acc: 0.0000e+00 - val_loss: 1.7100e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9287e-05 - acc: 0.0000e+00 - val_loss: 3.3076e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0768e-05 - acc: 0.0000e+00 - val_loss: 1.7367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8671e-05 - acc: 0.0000e+00 - val_loss: 1.7448e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.3348e-05 - acc: 0.0000e+00 - val_loss: 1.6685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0435e-04 - acc: 0.0000e+00 - val_loss: 4.8952e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.4527e-05 - acc: 0.0000e+00 - val_loss: 1.6342e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9623e-05 - acc: 0.0000e+00 - val_loss: 1.6144e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9107e-05 - acc: 0.0000e+00 - val_loss: 2.1771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1061e-05 - acc: 0.0000e+00 - val_loss: 2.1561e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0758e-05 - acc: 0.0000e+00 - val_loss: 1.5033e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8513e-05 - acc: 0.0000e+00 - val_loss: 1.5234e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1976e-05 - acc: 0.0000e+00 - val_loss: 1.9570e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0862e-05 - acc: 0.0000e+00 - val_loss: 1.8302e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5913e-05 - acc: 0.0000e+00 - val_loss: 2.4115e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.3368e-05 - acc: 0.0000e+00 - val_loss: 3.6891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6337e-05 - acc: 0.0000e+00 - val_loss: 3.9069e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1995e-05 - acc: 0.0000e+00 - val_loss: 6.9418e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1108e-05 - acc: 0.0000e+00 - val_loss: 1.4640e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9820e-05 - acc: 0.0000e+00 - val_loss: 2.0474e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5930e-05 - acc: 0.0000e+00 - val_loss: 1.4271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.9180e-05 - acc: 0.0000e+00 - val_loss: 1.2974e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0244e-05 - acc: 0.0000e+00 - val_loss: 2.1810e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1317e-05 - acc: 0.0000e+00 - val_loss: 1.3586e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.0566e-05 - acc: 0.0000e+00 - val_loss: 4.3881e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.5703e-05 - acc: 0.0000e+00 - val_loss: 1.7405e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6752e-05 - acc: 0.0000e+00 - val_loss: 1.2157e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2369e-05 - acc: 0.0000e+00 - val_loss: 1.3106e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1495e-05 - acc: 0.0000e+00 - val_loss: 1.3340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1741e-04 - acc: 0.0000e+00 - val_loss: 2.0397e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2194e-05 - acc: 0.0000e+00 - val_loss: 1.3704e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7236e-05 - acc: 0.0000e+00 - val_loss: 1.5559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2989e-05 - acc: 0.0000e+00 - val_loss: 1.1665e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4549e-05 - acc: 0.0000e+00 - val_loss: 1.6413e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5304e-05 - acc: 0.0000e+00 - val_loss: 2.7490e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6171e-05 - acc: 0.0000e+00 - val_loss: 1.9201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8330e-05 - acc: 0.0000e+00 - val_loss: 4.1592e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9335e-05 - acc: 0.0000e+00 - val_loss: 1.1460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7448e-05 - acc: 0.0000e+00 - val_loss: 1.2008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9417e-05 - acc: 0.0000e+00 - val_loss: 1.0950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1140e-05 - acc: 0.0000e+00 - val_loss: 1.0766e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1937e-05 - acc: 0.0000e+00 - val_loss: 2.3076e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8266e-05 - acc: 0.0000e+00 - val_loss: 1.0760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5861e-05 - acc: 0.0000e+00 - val_loss: 1.4369e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4926e-05 - acc: 0.0000e+00 - val_loss: 3.2232e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3248e-05 - acc: 0.0000e+00 - val_loss: 1.8481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7679e-05 - acc: 0.0000e+00 - val_loss: 1.2871e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7880e-05 - acc: 0.0000e+00 - val_loss: 2.4993e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6346e-05 - acc: 0.0000e+00 - val_loss: 1.0069e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1183e-05 - acc: 0.0000e+00 - val_loss: 1.0771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7082e-05 - acc: 0.0000e+00 - val_loss: 2.9158e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0512e-05 - acc: 0.0000e+00 - val_loss: 1.2987e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9147e-05 - acc: 0.0000e+00 - val_loss: 2.5739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1296e-05 - acc: 0.0000e+00 - val_loss: 9.9959e-05 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9777e-05 - acc: 0.0000e+00 - val_loss: 9.6162e-05 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1116e-05 - acc: 0.0000e+00 - val_loss: 1.1731e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0422e-05 - acc: 0.0000e+00 - val_loss: 1.4577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1013e-05 - acc: 0.0000e+00 - val_loss: 1.0623e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9559e-05 - acc: 0.0000e+00 - val_loss: 1.3815e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6423e-05 - acc: 0.0000e+00 - val_loss: 1.4018e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2166e-05 - acc: 0.0000e+00 - val_loss: 1.5155e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8065e-05 - acc: 0.0000e+00 - val_loss: 1.1399e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9102e-05 - acc: 0.0000e+00 - val_loss: 8.9431e-05 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1838e-05 - acc: 0.0000e+00 - val_loss: 1.7270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4163e-05 - acc: 0.0000e+00 - val_loss: 1.6806e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7365e-05 - acc: 0.0000e+00 - val_loss: 1.2908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6763e-05 - acc: 0.0000e+00 - val_loss: 1.0595e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0788e-05 - acc: 0.0000e+00 - val_loss: 1.5208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0592e-05 - acc: 0.0000e+00 - val_loss: 1.0276e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5310e-05 - acc: 0.0000e+00 - val_loss: 1.6509e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6720e-05 - acc: 0.0000e+00 - val_loss: 1.3959e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00003 MSE (0.01 RMSE)\n",
      "Test Score: 0.00021 MSE (0.01 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 22, 256)           267264    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 809,089\n",
      "Trainable params: 809,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 4s - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0181e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.6371e-04 - acc: 0.0000e+00 - val_loss: 4.1609e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.2213e-04 - acc: 0.0000e+00 - val_loss: 3.2139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.1409e-04 - acc: 0.0000e+00 - val_loss: 4.1379e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0606e-04 - acc: 0.0000e+00 - val_loss: 2.4285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.8232e-05 - acc: 0.0000e+00 - val_loss: 2.3283e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0070e-04 - acc: 0.0000e+00 - val_loss: 2.2279e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.0621e-05 - acc: 0.0000e+00 - val_loss: 2.2914e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.8094e-05 - acc: 0.0000e+00 - val_loss: 2.1350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.7727e-05 - acc: 0.0000e+00 - val_loss: 2.0742e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.6307e-05 - acc: 0.0000e+00 - val_loss: 2.3852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4454e-05 - acc: 0.0000e+00 - val_loss: 1.9922e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7632e-05 - acc: 0.0000e+00 - val_loss: 1.9435e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.8439e-05 - acc: 0.0000e+00 - val_loss: 1.9311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6799e-05 - acc: 0.0000e+00 - val_loss: 2.7103e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0145e-05 - acc: 0.0000e+00 - val_loss: 1.8856e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 2s - loss: 1.0098e-04 - acc: 0.0000e+00 - val_loss: 2.2187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.4428e-05 - acc: 0.0000e+00 - val_loss: 2.2218e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1758e-05 - acc: 0.0000e+00 - val_loss: 1.9211e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.2834e-05 - acc: 0.0000e+00 - val_loss: 2.1215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.7957e-05 - acc: 0.0000e+00 - val_loss: 2.0983e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5747e-05 - acc: 0.0000e+00 - val_loss: 1.7711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9023e-05 - acc: 0.0000e+00 - val_loss: 2.0176e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.1649e-05 - acc: 0.0000e+00 - val_loss: 1.8603e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.3357e-05 - acc: 0.0000e+00 - val_loss: 3.3086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5898e-05 - acc: 0.0000e+00 - val_loss: 1.9545e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7264e-05 - acc: 0.0000e+00 - val_loss: 1.6782e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.6493e-05 - acc: 0.0000e+00 - val_loss: 4.3663e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6357e-05 - acc: 0.0000e+00 - val_loss: 1.6497e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0731e-05 - acc: 0.0000e+00 - val_loss: 1.5683e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3049e-05 - acc: 0.0000e+00 - val_loss: 1.5698e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0850e-05 - acc: 0.0000e+00 - val_loss: 1.8113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4386e-05 - acc: 0.0000e+00 - val_loss: 1.6883e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3276e-05 - acc: 0.0000e+00 - val_loss: 2.7601e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.1896e-05 - acc: 0.0000e+00 - val_loss: 1.6007e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1360e-05 - acc: 0.0000e+00 - val_loss: 1.7175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3682e-05 - acc: 0.0000e+00 - val_loss: 1.6422e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.7071e-05 - acc: 0.0000e+00 - val_loss: 1.7621e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7570e-05 - acc: 0.0000e+00 - val_loss: 1.5119e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.1288e-05 - acc: 0.0000e+00 - val_loss: 2.1572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.3713e-05 - acc: 0.0000e+00 - val_loss: 1.6333e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9881e-05 - acc: 0.0000e+00 - val_loss: 1.7215e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2633e-05 - acc: 0.0000e+00 - val_loss: 1.3589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4513e-05 - acc: 0.0000e+00 - val_loss: 1.7724e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.2045e-05 - acc: 0.0000e+00 - val_loss: 1.9163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 2s - loss: 7.5259e-05 - acc: 0.0000e+00 - val_loss: 2.2824e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.8696e-05 - acc: 0.0000e+00 - val_loss: 1.4655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6153e-05 - acc: 0.0000e+00 - val_loss: 1.3362e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9115e-05 - acc: 0.0000e+00 - val_loss: 1.6425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0320e-05 - acc: 0.0000e+00 - val_loss: 1.2688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4085e-05 - acc: 0.0000e+00 - val_loss: 1.9757e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 2s - loss: 8.0367e-05 - acc: 0.0000e+00 - val_loss: 1.6377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9877e-05 - acc: 0.0000e+00 - val_loss: 1.2305e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0607e-05 - acc: 0.0000e+00 - val_loss: 3.8728e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 2s - loss: 9.2545e-05 - acc: 0.0000e+00 - val_loss: 3.0147e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.0281e-05 - acc: 0.0000e+00 - val_loss: 1.4459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4326e-05 - acc: 0.0000e+00 - val_loss: 1.2723e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0050e-05 - acc: 0.0000e+00 - val_loss: 1.2949e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5365e-05 - acc: 0.0000e+00 - val_loss: 1.2775e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.4587e-05 - acc: 0.0000e+00 - val_loss: 1.1553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6952e-05 - acc: 0.0000e+00 - val_loss: 3.5440e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.7505e-05 - acc: 0.0000e+00 - val_loss: 1.2739e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1206e-05 - acc: 0.0000e+00 - val_loss: 1.3347e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9365e-05 - acc: 0.0000e+00 - val_loss: 2.1700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.9185e-05 - acc: 0.0000e+00 - val_loss: 3.3951e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8418e-05 - acc: 0.0000e+00 - val_loss: 2.6330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.6553e-05 - acc: 0.0000e+00 - val_loss: 1.4572e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.9944e-05 - acc: 0.0000e+00 - val_loss: 3.8270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.6265e-05 - acc: 0.0000e+00 - val_loss: 1.9433e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9580e-05 - acc: 0.0000e+00 - val_loss: 1.0720e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.1305e-05 - acc: 0.0000e+00 - val_loss: 1.8352e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3313e-05 - acc: 0.0000e+00 - val_loss: 1.0967e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.5718e-05 - acc: 0.0000e+00 - val_loss: 1.1168e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.7179e-05 - acc: 0.0000e+00 - val_loss: 1.6778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9833e-05 - acc: 0.0000e+00 - val_loss: 1.8654e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6820e-05 - acc: 0.0000e+00 - val_loss: 1.1794e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.3134e-05 - acc: 0.0000e+00 - val_loss: 1.5263e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0241e-05 - acc: 0.0000e+00 - val_loss: 1.0799e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.7767e-05 - acc: 0.0000e+00 - val_loss: 1.0010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.0136e-05 - acc: 0.0000e+00 - val_loss: 1.0205e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.8949e-05 - acc: 0.0000e+00 - val_loss: 1.3785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9370e-05 - acc: 0.0000e+00 - val_loss: 9.9040e-05 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.7166e-05 - acc: 0.0000e+00 - val_loss: 1.1173e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.8248e-05 - acc: 0.0000e+00 - val_loss: 1.7276e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 2s - loss: 6.4496e-05 - acc: 0.0000e+00 - val_loss: 1.9274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.9201e-05 - acc: 0.0000e+00 - val_loss: 2.4660e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6730e-05 - acc: 0.0000e+00 - val_loss: 9.9719e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 2s - loss: 4.6232e-05 - acc: 0.0000e+00 - val_loss: 2.0847e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 2s - loss: 5.2217e-05 - acc: 0.0000e+00 - val_loss: 9.5365e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00030 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 22, 512)           1058816   \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 22, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,166,241\n",
      "Trainable params: 3,166,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 7s - loss: 0.0074 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.7744e-04 - acc: 0.0000e+00 - val_loss: 3.4495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.2383e-05 - acc: 0.0000e+00 - val_loss: 3.1878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.8010e-05 - acc: 0.0000e+00 - val_loss: 5.9432e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.6156e-05 - acc: 0.0000e+00 - val_loss: 2.6485e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.8003e-05 - acc: 0.0000e+00 - val_loss: 3.1075e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.6360e-05 - acc: 0.0000e+00 - val_loss: 3.4285e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.0516e-05 - acc: 0.0000e+00 - val_loss: 3.9601e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.0337e-04 - acc: 0.0000e+00 - val_loss: 3.1765e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.0934e-04 - acc: 0.0000e+00 - val_loss: 3.2519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.8272e-05 - acc: 0.0000e+00 - val_loss: 4.7571e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.4994e-05 - acc: 0.0000e+00 - val_loss: 2.9675e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.2102e-05 - acc: 0.0000e+00 - val_loss: 2.8599e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.0325e-04 - acc: 0.0000e+00 - val_loss: 2.4849e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.5081e-05 - acc: 0.0000e+00 - val_loss: 2.3204e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.4864e-05 - acc: 0.0000e+00 - val_loss: 2.2429e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.8728e-05 - acc: 0.0000e+00 - val_loss: 2.4237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.3073e-05 - acc: 0.0000e+00 - val_loss: 2.3263e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.4732e-05 - acc: 0.0000e+00 - val_loss: 9.5417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.2801e-05 - acc: 0.0000e+00 - val_loss: 2.3274e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.1270e-05 - acc: 0.0000e+00 - val_loss: 3.0606e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.6542e-05 - acc: 0.0000e+00 - val_loss: 2.1356e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.3672e-05 - acc: 0.0000e+00 - val_loss: 2.0471e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.2687e-05 - acc: 0.0000e+00 - val_loss: 2.1525e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1923e-05 - acc: 0.0000e+00 - val_loss: 2.6906e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.5529e-05 - acc: 0.0000e+00 - val_loss: 2.2161e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.6567e-05 - acc: 0.0000e+00 - val_loss: 3.0321e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.3865e-05 - acc: 0.0000e+00 - val_loss: 2.1432e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.8791e-05 - acc: 0.0000e+00 - val_loss: 3.4520e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7491e-05 - acc: 0.0000e+00 - val_loss: 2.4891e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4428e-05 - acc: 0.0000e+00 - val_loss: 2.2451e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.6747e-05 - acc: 0.0000e+00 - val_loss: 2.7320e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.5721e-05 - acc: 0.0000e+00 - val_loss: 2.4247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5621e-05 - acc: 0.0000e+00 - val_loss: 1.9781e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1395e-05 - acc: 0.0000e+00 - val_loss: 5.5046e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.9735e-05 - acc: 0.0000e+00 - val_loss: 1.7398e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.6767e-05 - acc: 0.0000e+00 - val_loss: 8.1312e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8467e-05 - acc: 0.0000e+00 - val_loss: 1.9842e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2052e-05 - acc: 0.0000e+00 - val_loss: 2.2533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1900e-05 - acc: 0.0000e+00 - val_loss: 1.7377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4266e-05 - acc: 0.0000e+00 - val_loss: 4.0736e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4379e-05 - acc: 0.0000e+00 - val_loss: 2.7438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3307e-05 - acc: 0.0000e+00 - val_loss: 1.4855e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0383e-05 - acc: 0.0000e+00 - val_loss: 1.6908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2109e-05 - acc: 0.0000e+00 - val_loss: 1.4925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8929e-05 - acc: 0.0000e+00 - val_loss: 2.0280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6286e-05 - acc: 0.0000e+00 - val_loss: 3.6762e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9321e-05 - acc: 0.0000e+00 - val_loss: 4.1044e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.7442e-05 - acc: 0.0000e+00 - val_loss: 2.6415e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1384e-05 - acc: 0.0000e+00 - val_loss: 1.2662e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3324e-05 - acc: 0.0000e+00 - val_loss: 1.7271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.5706e-05 - acc: 0.0000e+00 - val_loss: 3.7834e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7666e-05 - acc: 0.0000e+00 - val_loss: 1.3999e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3377e-05 - acc: 0.0000e+00 - val_loss: 1.2388e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.0172e-05 - acc: 0.0000e+00 - val_loss: 2.4319e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.6979e-05 - acc: 0.0000e+00 - val_loss: 1.2924e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7535e-05 - acc: 0.0000e+00 - val_loss: 4.3677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4995e-05 - acc: 0.0000e+00 - val_loss: 2.8436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0257e-05 - acc: 0.0000e+00 - val_loss: 1.1430e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0646e-05 - acc: 0.0000e+00 - val_loss: 1.9424e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6332e-05 - acc: 0.0000e+00 - val_loss: 7.3764e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5294e-05 - acc: 0.0000e+00 - val_loss: 1.1102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0142e-05 - acc: 0.0000e+00 - val_loss: 4.0685e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0925e-05 - acc: 0.0000e+00 - val_loss: 1.3003e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4738e-05 - acc: 0.0000e+00 - val_loss: 1.0553e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0880e-05 - acc: 0.0000e+00 - val_loss: 1.5358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.8448e-05 - acc: 0.0000e+00 - val_loss: 2.8436e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0430e-05 - acc: 0.0000e+00 - val_loss: 1.8442e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0367e-05 - acc: 0.0000e+00 - val_loss: 2.5187e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2968e-05 - acc: 0.0000e+00 - val_loss: 3.0867e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6618e-05 - acc: 0.0000e+00 - val_loss: 1.6065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2401e-05 - acc: 0.0000e+00 - val_loss: 1.6702e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0544e-05 - acc: 0.0000e+00 - val_loss: 9.5525e-05 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9828e-05 - acc: 0.0000e+00 - val_loss: 1.8311e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1247e-05 - acc: 0.0000e+00 - val_loss: 3.4708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.0362e-05 - acc: 0.0000e+00 - val_loss: 1.1589e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2499e-05 - acc: 0.0000e+00 - val_loss: 1.3025e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2591e-05 - acc: 0.0000e+00 - val_loss: 1.2744e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.5940e-05 - acc: 0.0000e+00 - val_loss: 9.2073e-05 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.7204e-05 - acc: 0.0000e+00 - val_loss: 1.3093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6906e-05 - acc: 0.0000e+00 - val_loss: 9.7412e-05 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2656e-05 - acc: 0.0000e+00 - val_loss: 2.3259e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9680e-05 - acc: 0.0000e+00 - val_loss: 1.3716e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5916e-05 - acc: 0.0000e+00 - val_loss: 9.1353e-05 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7735e-05 - acc: 0.0000e+00 - val_loss: 9.1079e-05 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5627e-05 - acc: 0.0000e+00 - val_loss: 1.7377e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1069e-05 - acc: 0.0000e+00 - val_loss: 2.5054e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1901e-05 - acc: 0.0000e+00 - val_loss: 3.0488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3568e-05 - acc: 0.0000e+00 - val_loss: 1.4197e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6352e-05 - acc: 0.0000e+00 - val_loss: 8.7662e-05 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00002 MSE (0.00 RMSE)\n",
      "Test Score: 0.00056 MSE (0.02 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 22, 512)           1058816   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 22, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,174,465\n",
      "Trainable params: 3,174,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 7s - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.7627e-04 - acc: 0.0000e+00 - val_loss: 8.7711e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.6591e-04 - acc: 0.0000e+00 - val_loss: 4.3464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.1055e-04 - acc: 0.0000e+00 - val_loss: 3.1364e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.6402e-05 - acc: 0.0000e+00 - val_loss: 2.6699e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.0669e-05 - acc: 0.0000e+00 - val_loss: 2.3708e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.7800e-05 - acc: 0.0000e+00 - val_loss: 2.6208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 5s - loss: 9.0497e-05 - acc: 0.0000e+00 - val_loss: 2.3972e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1067e-05 - acc: 0.0000e+00 - val_loss: 2.4296e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.9885e-05 - acc: 0.0000e+00 - val_loss: 2.5970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.1293e-05 - acc: 0.0000e+00 - val_loss: 2.2061e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.0748e-05 - acc: 0.0000e+00 - val_loss: 2.1607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.5438e-05 - acc: 0.0000e+00 - val_loss: 3.1982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.7950e-05 - acc: 0.0000e+00 - val_loss: 2.6940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.7328e-05 - acc: 0.0000e+00 - val_loss: 2.0519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.3397e-05 - acc: 0.0000e+00 - val_loss: 2.2156e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.0194e-05 - acc: 0.0000e+00 - val_loss: 2.1489e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1922e-05 - acc: 0.0000e+00 - val_loss: 2.2043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7475e-05 - acc: 0.0000e+00 - val_loss: 1.9719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.9206e-05 - acc: 0.0000e+00 - val_loss: 3.4417e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.3915e-05 - acc: 0.0000e+00 - val_loss: 2.8902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.9033e-05 - acc: 0.0000e+00 - val_loss: 2.5501e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8111e-05 - acc: 0.0000e+00 - val_loss: 6.4109e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.6134e-05 - acc: 0.0000e+00 - val_loss: 2.0495e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7076e-05 - acc: 0.0000e+00 - val_loss: 1.9230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.9483e-05 - acc: 0.0000e+00 - val_loss: 2.2378e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6974e-05 - acc: 0.0000e+00 - val_loss: 3.5238e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4746e-05 - acc: 0.0000e+00 - val_loss: 1.6960e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7180e-05 - acc: 0.0000e+00 - val_loss: 2.9533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3362e-05 - acc: 0.0000e+00 - val_loss: 1.7395e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.9658e-05 - acc: 0.0000e+00 - val_loss: 2.7860e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.8084e-05 - acc: 0.0000e+00 - val_loss: 2.2948e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0821e-05 - acc: 0.0000e+00 - val_loss: 1.6719e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8743e-05 - acc: 0.0000e+00 - val_loss: 3.2100e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.7563e-05 - acc: 0.0000e+00 - val_loss: 1.5917e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.9278e-05 - acc: 0.0000e+00 - val_loss: 1.8111e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4663e-05 - acc: 0.0000e+00 - val_loss: 1.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3156e-05 - acc: 0.0000e+00 - val_loss: 1.6793e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2560e-05 - acc: 0.0000e+00 - val_loss: 1.7672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2714e-05 - acc: 0.0000e+00 - val_loss: 1.9043e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7904e-05 - acc: 0.0000e+00 - val_loss: 1.8789e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2191e-05 - acc: 0.0000e+00 - val_loss: 1.9801e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2251e-05 - acc: 0.0000e+00 - val_loss: 2.5759e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1228e-05 - acc: 0.0000e+00 - val_loss: 2.9425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4749e-05 - acc: 0.0000e+00 - val_loss: 3.1890e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.8371e-05 - acc: 0.0000e+00 - val_loss: 1.5237e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6497e-05 - acc: 0.0000e+00 - val_loss: 3.3804e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4504e-05 - acc: 0.0000e+00 - val_loss: 1.3825e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0490e-05 - acc: 0.0000e+00 - val_loss: 1.4198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4790e-05 - acc: 0.0000e+00 - val_loss: 2.0868e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3868e-05 - acc: 0.0000e+00 - val_loss: 1.4702e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2877e-05 - acc: 0.0000e+00 - val_loss: 1.2672e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3234e-05 - acc: 0.0000e+00 - val_loss: 1.7786e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1293e-05 - acc: 0.0000e+00 - val_loss: 2.4828e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8906e-05 - acc: 0.0000e+00 - val_loss: 3.9230e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3556e-05 - acc: 0.0000e+00 - val_loss: 5.8902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4967e-05 - acc: 0.0000e+00 - val_loss: 2.3537e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3928e-05 - acc: 0.0000e+00 - val_loss: 1.9513e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1963e-05 - acc: 0.0000e+00 - val_loss: 1.3201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0514e-05 - acc: 0.0000e+00 - val_loss: 2.3785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1522e-05 - acc: 0.0000e+00 - val_loss: 1.3313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1900e-05 - acc: 0.0000e+00 - val_loss: 1.2340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1488e-05 - acc: 0.0000e+00 - val_loss: 1.8833e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8815e-05 - acc: 0.0000e+00 - val_loss: 2.8125e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1729e-05 - acc: 0.0000e+00 - val_loss: 1.1163e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0148e-05 - acc: 0.0000e+00 - val_loss: 1.4508e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5945e-05 - acc: 0.0000e+00 - val_loss: 1.2213e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7222e-05 - acc: 0.0000e+00 - val_loss: 1.7338e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6965e-05 - acc: 0.0000e+00 - val_loss: 1.3902e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.8000e-05 - acc: 0.0000e+00 - val_loss: 2.2710e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4208e-05 - acc: 0.0000e+00 - val_loss: 1.1956e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4768e-05 - acc: 0.0000e+00 - val_loss: 2.4201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6059e-05 - acc: 0.0000e+00 - val_loss: 2.6171e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2302e-05 - acc: 0.0000e+00 - val_loss: 1.0281e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0051e-05 - acc: 0.0000e+00 - val_loss: 1.1258e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.0282e-05 - acc: 0.0000e+00 - val_loss: 1.8706e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0816e-05 - acc: 0.0000e+00 - val_loss: 1.0030e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3881e-05 - acc: 0.0000e+00 - val_loss: 3.4460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6086e-05 - acc: 0.0000e+00 - val_loss: 1.7175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4014e-05 - acc: 0.0000e+00 - val_loss: 9.8474e-05 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2938e-05 - acc: 0.0000e+00 - val_loss: 3.6452e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2751e-05 - acc: 0.0000e+00 - val_loss: 1.5063e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0101e-05 - acc: 0.0000e+00 - val_loss: 1.1372e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.7873e-05 - acc: 0.0000e+00 - val_loss: 1.1552e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9376e-05 - acc: 0.0000e+00 - val_loss: 9.7031e-05 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4795e-05 - acc: 0.0000e+00 - val_loss: 1.2941e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8544e-05 - acc: 0.0000e+00 - val_loss: 1.1371e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9842e-05 - acc: 0.0000e+00 - val_loss: 1.2123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9124e-05 - acc: 0.0000e+00 - val_loss: 9.4820e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.7951e-05 - acc: 0.0000e+00 - val_loss: 2.2827e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00006 MSE (0.01 RMSE)\n",
      "Test Score: 0.00021 MSE (0.01 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 22, 512)           1058816   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 22, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,190,913\n",
      "Trainable params: 3,190,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13707 samples, validate on 1523 samples\n",
      "Epoch 1/90\n",
      "13707/13707 [==============================] - 7s - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7127e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.5277e-04 - acc: 0.0000e+00 - val_loss: 5.1752e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.1383e-04 - acc: 0.0000e+00 - val_loss: 3.1569e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.3033e-05 - acc: 0.0000e+00 - val_loss: 2.9547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.4735e-05 - acc: 0.0000e+00 - val_loss: 3.0643e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.5323e-05 - acc: 0.0000e+00 - val_loss: 2.4925e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.1686e-05 - acc: 0.0000e+00 - val_loss: 2.1852e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.3006e-05 - acc: 0.0000e+00 - val_loss: 2.3519e-04 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8317e-05 - acc: 0.0000e+00 - val_loss: 2.2700e-04 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.5661e-05 - acc: 0.0000e+00 - val_loss: 2.1559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.8524e-05 - acc: 0.0000e+00 - val_loss: 2.3825e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.5461e-05 - acc: 0.0000e+00 - val_loss: 3.3604e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.9308e-05 - acc: 0.0000e+00 - val_loss: 2.8185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.7471e-05 - acc: 0.0000e+00 - val_loss: 2.4124e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.6734e-05 - acc: 0.0000e+00 - val_loss: 1.9131e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.0376e-05 - acc: 0.0000e+00 - val_loss: 1.9164e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7234e-05 - acc: 0.0000e+00 - val_loss: 1.8514e-04 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.0717e-05 - acc: 0.0000e+00 - val_loss: 3.0114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.2376e-05 - acc: 0.0000e+00 - val_loss: 2.2846e-04 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.7468e-05 - acc: 0.0000e+00 - val_loss: 1.7822e-04 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "13707/13707 [==============================] - 5s - loss: 7.3096e-05 - acc: 0.0000e+00 - val_loss: 2.3393e-04 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.8082e-05 - acc: 0.0000e+00 - val_loss: 3.0920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.2944e-05 - acc: 0.0000e+00 - val_loss: 2.0705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "13707/13707 [==============================] - 5s - loss: 8.1935e-05 - acc: 0.0000e+00 - val_loss: 1.7846e-04 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6712e-05 - acc: 0.0000e+00 - val_loss: 2.2576e-04 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5286e-05 - acc: 0.0000e+00 - val_loss: 2.2648e-04 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5477e-05 - acc: 0.0000e+00 - val_loss: 2.1367e-04 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6091e-05 - acc: 0.0000e+00 - val_loss: 1.9820e-04 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.1355e-05 - acc: 0.0000e+00 - val_loss: 3.4680e-04 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4002e-05 - acc: 0.0000e+00 - val_loss: 1.8448e-04 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.4998e-05 - acc: 0.0000e+00 - val_loss: 2.5581e-04 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3935e-05 - acc: 0.0000e+00 - val_loss: 1.5469e-04 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4605e-05 - acc: 0.0000e+00 - val_loss: 4.2348e-04 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.3398e-05 - acc: 0.0000e+00 - val_loss: 2.7493e-04 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8229e-05 - acc: 0.0000e+00 - val_loss: 1.8093e-04 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2976e-05 - acc: 0.0000e+00 - val_loss: 2.8494e-04 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0289e-05 - acc: 0.0000e+00 - val_loss: 2.7506e-04 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9997e-05 - acc: 0.0000e+00 - val_loss: 1.4458e-04 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7490e-05 - acc: 0.0000e+00 - val_loss: 1.6178e-04 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5040e-05 - acc: 0.0000e+00 - val_loss: 1.7008e-04 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.9983e-05 - acc: 0.0000e+00 - val_loss: 2.1438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7204e-05 - acc: 0.0000e+00 - val_loss: 1.9721e-04 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6172e-05 - acc: 0.0000e+00 - val_loss: 1.4535e-04 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8046e-05 - acc: 0.0000e+00 - val_loss: 2.2610e-04 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.0639e-05 - acc: 0.0000e+00 - val_loss: 1.6809e-04 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6883e-05 - acc: 0.0000e+00 - val_loss: 1.3198e-04 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2987e-05 - acc: 0.0000e+00 - val_loss: 4.9383e-04 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "13707/13707 [==============================] - 5s - loss: 1.0399e-04 - acc: 0.0000e+00 - val_loss: 4.8208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.2235e-05 - acc: 0.0000e+00 - val_loss: 1.3547e-04 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5444e-05 - acc: 0.0000e+00 - val_loss: 1.3129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1589e-05 - acc: 0.0000e+00 - val_loss: 2.2130e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9925e-05 - acc: 0.0000e+00 - val_loss: 1.5910e-04 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6165e-05 - acc: 0.0000e+00 - val_loss: 3.0870e-04 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.1203e-05 - acc: 0.0000e+00 - val_loss: 1.2229e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3808e-05 - acc: 0.0000e+00 - val_loss: 1.6088e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.2079e-05 - acc: 0.0000e+00 - val_loss: 1.4262e-04 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1734e-05 - acc: 0.0000e+00 - val_loss: 2.2540e-04 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.9984e-05 - acc: 0.0000e+00 - val_loss: 2.5313e-04 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "13707/13707 [==============================] - 5s - loss: 6.4694e-05 - acc: 0.0000e+00 - val_loss: 1.3746e-04 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2644e-05 - acc: 0.0000e+00 - val_loss: 1.1615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8698e-05 - acc: 0.0000e+00 - val_loss: 1.7441e-04 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2934e-05 - acc: 0.0000e+00 - val_loss: 1.8039e-04 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.5987e-05 - acc: 0.0000e+00 - val_loss: 1.4653e-04 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4255e-05 - acc: 0.0000e+00 - val_loss: 1.3370e-04 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0193e-05 - acc: 0.0000e+00 - val_loss: 1.5693e-04 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2163e-05 - acc: 0.0000e+00 - val_loss: 1.9438e-04 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.8123e-05 - acc: 0.0000e+00 - val_loss: 3.8878e-04 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.3870e-05 - acc: 0.0000e+00 - val_loss: 1.2966e-04 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.7672e-05 - acc: 0.0000e+00 - val_loss: 1.1231e-04 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1490e-05 - acc: 0.0000e+00 - val_loss: 1.1473e-04 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.6135e-05 - acc: 0.0000e+00 - val_loss: 1.8271e-04 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2570e-05 - acc: 0.0000e+00 - val_loss: 1.4970e-04 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6103e-05 - acc: 0.0000e+00 - val_loss: 1.0239e-04 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6905e-05 - acc: 0.0000e+00 - val_loss: 1.0734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.5542e-05 - acc: 0.0000e+00 - val_loss: 1.1453e-04 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0579e-05 - acc: 0.0000e+00 - val_loss: 2.1340e-04 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.4344e-05 - acc: 0.0000e+00 - val_loss: 2.5877e-04 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.8096e-05 - acc: 0.0000e+00 - val_loss: 1.3082e-04 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1058e-05 - acc: 0.0000e+00 - val_loss: 1.3139e-04 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.9520e-05 - acc: 0.0000e+00 - val_loss: 1.5584e-04 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.0933e-05 - acc: 0.0000e+00 - val_loss: 1.1102e-04 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.4266e-05 - acc: 0.0000e+00 - val_loss: 1.2612e-04 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6913e-05 - acc: 0.0000e+00 - val_loss: 1.1481e-04 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.1322e-05 - acc: 0.0000e+00 - val_loss: 3.3684e-04 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "13707/13707 [==============================] - 5s - loss: 5.6055e-05 - acc: 0.0000e+00 - val_loss: 3.4491e-04 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.5288e-05 - acc: 0.0000e+00 - val_loss: 1.2911e-04 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.6853e-05 - acc: 0.0000e+00 - val_loss: 1.0088e-04 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "13707/13707 [==============================] - 5s - loss: 3.5433e-05 - acc: 0.0000e+00 - val_loss: 1.4986e-04 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "13707/13707 [==============================] - 5s - loss: 4.2263e-05 - acc: 0.0000e+00 - val_loss: 4.1180e-04 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00009 MSE (0.01 RMSE)\n",
      "Test Score: 0.00176 MSE (0.04 RMSE)\n"
     ]
    }
   ],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "epochs = 90\n",
    "dropout = 0.3\n",
    "neuronlist1 = [32, 64, 128, 256, 512]\n",
    "neuronlist2 = [16, 32, 64]\n",
    "neurons_result = {}\n",
    "\n",
    "for neuron_lstm in neuronlist1:\n",
    "    neurons = [neuron_lstm, neuron_lstm]\n",
    "    for activation in neuronlist2:\n",
    "        neurons.append(activation)\n",
    "        neurons.append(1)\n",
    "        trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "        neurons_result[str(neurons)] = testScore\n",
    "        neurons = neurons[:2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neurons_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-6c062ca2d33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finding the best hyperparameter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neurons'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neurons_result' is not defined"
     ]
    }
   ],
   "source": [
    "lists = sorted(neurons_result.items())\n",
    "x,y = zip(*lists)\n",
    "\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('neurons')\n",
    "plt.ylabel('Mean Square Error')\n",
    "\n",
    "plt.bar(range(len(lists)), y, align='center')\n",
    "plt.xticks(range(len(lists)), x)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.4 Optimial Dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [256, 256, 32, 1]\n",
    "epochs = 90\n",
    "decaylist = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model3(layers, neurons, d, decay):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    adam = keras.optimizers.Adam(decay=decay)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay):\n",
    "    df = get_stock_data(stock_name)\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model3(shape, neurons, d, decay)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "    # model.save('LSTM_Stock_prediction-20170429.h5')\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decay_result = {}\n",
    "\n",
    "for decay in decaylist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
    "    decay_result[decay] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists = sorted(decay_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Decay')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "neurons = [256, 256, 32, 1]\n",
    "epochs = 90\n",
    "d = 0.3 #dropout\n",
    "decay = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len_list = [5, 10, 22, 60, 120, 180]\n",
    "\n",
    "seq_len_result = {}\n",
    "\n",
    "for seq_len in seq_len_list:\n",
    "    shape = [4, seq_len, 1]\n",
    "    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
    "    seq_len_result[seq_len] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists = sorted(seq_len_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
